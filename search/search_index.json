{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#roboflow-python-package","title":"Roboflow Python Package","text":"<p>Roboflow provides everything you need to build and deploy computer vision models. <code>roboflow-python</code> is the official Roboflow Python package. <code>roboflow-python</code> enables you to interact with models, datasets, and projects hosted on Roboflow.</p> <p>With this Python package, you can:</p> <ol> <li>Create and manage projects;</li> <li>Upload images, annotations, and datasets to manage in Roboflow;</li> <li>Start training vision models on Roboflow;</li> <li>Run inference on models hosted on Roboflow, or Roboflow models self-hosted via Roboflow Inference, and more.</li> </ol> <p>The Python package is documented on the official Roboflow documentation site. If you are developing a feature for this Python package, or need a full Python library reference, refer to the package developer documentation.</p>"},{"location":"#installation","title":"\ud83d\udcbb Installation","text":"<p>You will need to have <code>Python 3.8</code> or higher set up to use the Roboflow Python package.</p> <p>Run the following command to install the Roboflow Python package:</p> <pre><code>pip install roboflow\n</code></pre> Install from source    You can also install the Roboflow Python package from source using the following commands:    <pre><code>git clone https://github.com/roboflow-ai/roboflow-python.git\ncd roboflow-python\npython3 -m venv env\nsource env/bin/activate\npip3 install -r requirements.txt\n</code></pre>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>To use the Roboflow Python package, you first need to authenticate with your Roboflow account. You can do this by running the following command:</p> <pre><code>import roboflow\nroboflow.login()\n</code></pre> Authenticate with an API key  You can also authenticate with an API key by using the following code:  <pre><code>import roboflow\n\nrf = roboflow.Roboflow(api_key=\"\")\n</code></pre>  [Learn how to retrieve your Roboflow API key](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key)."},{"location":"#quickstart","title":"Quickstart","text":"<p>Below are some common methods used with the Roboflow Python package, presented concisely for reference. For a full library reference, refer to the Roboflow API reference documentation.</p> <pre><code>import roboflow\n\nroboflow.login()\n\nrf = roboflow.Roboflow()\n\n# create a project\nrf.create_project(\n    project_name=\"project name\",\n    project_type=\"project-type\",\n    license=\"project-license\" # \"private\" for private projects\n)\n\nworkspace = rf.workspace(\"WORKSPACE_URL\")\nproject = workspace.project(\"PROJECT_URL\")\nversion = project.version(\"VERSION_NUMBER\")\n\n# upload a dataset\nworkspace.upload_dataset(\n    dataset_path=\"./dataset/\",\n    num_workers=10,\n    dataset_format=\"yolov8\", # supports yolov8, yolov5, and Pascal VOC\n    project_license=\"MIT\",\n    project_type=\"object-detection\"\n)\n\n# upload model weights\nversion.deploy(model_type=\"yolov8\", model_path=f\u201d{HOME}/runs/detect/train/\u201d)\n\n# run inference\nmodel = version.model\n\nimg_url = \"https://media.roboflow.com/quickstart/aerial_drone.jpeg\"\n\npredictions = model.predict(img_url, hosted=True).json()\n\nprint(predictions)\n</code></pre>"},{"location":"#library-structure","title":"Library Structure","text":"<p>The Roboflow Python library is structured using the same Workspace, Project, and Version ontology that you will see in the Roboflow application.</p> <pre><code>import roboflow\n\nroboflow.login()\n\nrf = roboflow.Roboflow()\n\nworkspace = rf.workspace(\"WORKSPACE_URL\")\nproject = workspace.project(\"PROJECT_URL\")\nversion = project.version(\"VERSION_NUMBER\")\n</code></pre> <p>The workspace, project, and version parameters are the same as those you will find in the URL addresses at app.roboflow.com and universe.roboflow.com.</p> <p>Within the workspace object you can perform actions like making a new project, listing your projects, or performing active learning where you are using predictions from one project's model to upload images to a new project.</p> <p>Within the project object, you can retrieve metadata about the project, list versions, generate a new dataset version with preprocessing and augmentation settings, train a model in your project, and upload images and annotations to your project.</p> <p>Within the version object, you can download the dataset version in any model format, train the version on Roboflow, and deploy your own external model to Roboflow.</p>"},{"location":"#contributing","title":"\ud83c\udfc6 Contributing","text":"<p>We would love your input on how we can improve the Roboflow Python package! Please see our contributing guide to get started. Thank you \ud83d\ude4f to all our contributors!</p> <p></p>"},{"location":"core/dataset/","title":"Datasets","text":""},{"location":"core/dataset/#roboflow.core.dataset.Dataset","title":"<code>Dataset</code>","text":"<p>A Roboflow Dataset.</p> Source code in <code>roboflow/core/dataset.py</code> <pre><code>class Dataset:\n    \"\"\"\n    A Roboflow Dataset.\n    \"\"\"\n\n    def __init__(self, name, version, model_format, location):\n        self.name = name\n        self.version = version\n        self.model_format = model_format\n        self.location = location\n</code></pre>"},{"location":"core/model/","title":"Models","text":""},{"location":"core/model/#roboflow.core.model.Model","title":"<code>Model</code>","text":"<p>A Roboflow model.</p> Source code in <code>roboflow/core/model.py</code> <pre><code>class Model:\n    \"\"\"\n    A Roboflow model.\n    \"\"\"\n\n    def __init__(self, model):\n        self.id = model[\"id\"]\n        self.endpoint = model[\"endpoint\"]\n        self.duration = model[\"end\"] - model[\"start\"]\n        self.statistics = {\n            \"recall\": model[\"recall\"],\n            \"precision\": model[\"precision\"],\n            \"map\": model[\"map\"],\n        }\n</code></pre>"},{"location":"core/project/","title":"Projects","text":""},{"location":"core/project/#roboflow.core.project.Project","title":"<code>Project</code>","text":"<p>A Roboflow Project.</p> Source code in <code>roboflow/core/project.py</code> <pre><code>class Project:\n    \"\"\"\n    A Roboflow Project.\n    \"\"\"\n\n    def __init__(self, api_key: str, a_project: dict, model_format: Optional[str] = None):\n        \"\"\"\n        Create a Project object that represents a Project associated with a Workspace.\n\n        Args:\n            api_key (str): private roboflow api key\n            a_project (dict): the project information dictionary\n            model_format (str): the model format of the project\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n        \"\"\"\n\n        if api_key:\n            self.__api_key = api_key\n            self.annotation = a_project[\"annotation\"]\n            self.classes = a_project[\"classes\"]\n            self.colors = a_project[\"colors\"]\n            self.created = datetime.datetime.fromtimestamp(a_project[\"created\"])\n            self.id = a_project[\"id\"]\n            self.images = a_project[\"images\"]\n            self.name = a_project[\"name\"]\n            self.public = a_project[\"public\"]\n            self.splits = a_project[\"splits\"]\n            self.type = a_project[\"type\"]\n            self.multilabel = a_project.get(\"multilabel\", False)\n            self.unannotated = a_project[\"unannotated\"]\n            self.updated = datetime.datetime.fromtimestamp(a_project[\"updated\"])\n            self.model_format = model_format\n\n            temp = self.id.rsplit(\"/\")\n            self.__workspace = temp[0]\n            self.__project_name = temp[1]\n\n        elif DEMO_KEYS:\n            self.__api_key = DEMO_KEYS[0]\n            self.model_format = model_format\n\n        else:\n            raise ValueError(\"A valid API key must be provided.\")\n\n    def get_version_information(self):\n        \"\"\"\n        Retrieve all versions of a project.\n\n        Returns:\n            A list of all versions of the project.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; version_info = project.get_version_information()\n        \"\"\"\n        dataset_info = requests.get(\n            API_URL + \"/\" + self.__workspace + \"/\" + self.__project_name + \"?api_key=\" + self.__api_key\n        )\n\n        # Throw error if dataset isn't valid/user doesn't have permissions to access the dataset # noqa: E501 // docs\n        if dataset_info.status_code != 200:\n            raise RuntimeError(dataset_info.text)\n\n        dataset_info = dataset_info.json()\n        return dataset_info[\"versions\"]\n\n    def list_versions(self):\n        \"\"\"\n        Print out versions for that specific project.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; project.list_versions()\n        \"\"\"\n        version_info = self.get_version_information()\n        print(version_info)\n\n    def versions(self):\n        \"\"\"\n        Return all versions in the project as Version objects.\n\n        Returns:\n            A list of Version objects.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; versions = project.versions()\n        \"\"\"\n        version_info = self.get_version_information()\n        version_array = []\n        for a_version in version_info:\n            version_object = Version(\n                a_version,\n                (self.type if \"model\" in a_version else None),\n                self.__api_key,\n                self.name,\n                a_version[\"id\"],\n                self.model_format,\n                local=None,\n                workspace=self.__workspace,\n                project=self.__project_name,\n                public=self.public,\n                colors=self.colors,\n            )\n            version_array.append(version_object)\n        return version_array\n\n    def generate_version(self, settings):\n        \"\"\"\n        Generate a version of a dataset hosted on Roboflow.\n\n        Args:\n            settings: A Python dict with augmentation and preprocessing keys and specifications for generation. These settings mirror capabilities available via the Roboflow UI.\n                    For example:\n                        {\n                            \"augmentation\": {\n                                \"bbblur\": { \"pixels\": 1.5 },\n                                \"bbbrightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                                \"bbcrop\": { \"min\": 12, \"max\": 71 },\n                                \"bbexposure\": { \"percent\": 30 },\n                                \"bbflip\": { \"horizontal\": true, \"vertical\": false },\n                                \"bbnoise\": { \"percent\": 50 },\n                                \"bbninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                                \"bbrotate\": { \"degrees\": 45 },\n                                \"bbshear\": { \"horizontal\": 45, \"vertical\": 45 },\n                                \"blur\": { \"pixels\": 1.5 },\n                                \"brightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                                \"crop\": { \"min\": 12, \"max\": 71 },\n                                \"cutout\": { \"count\": 26, \"percent\": 71 },\n                                \"exposure\": { \"percent\": 30 },\n                                \"flip\": { \"horizontal\": true, \"vertical\": false },\n                                \"hue\": { \"degrees\": 180 },\n                                \"image\": { \"versions\": 32 },\n                                \"mosaic\": true,\n                                \"ninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                                \"noise\": { \"percent\": 50 },\n                                \"rgrayscale\": { \"percent\": 50 },\n                                \"rotate\": { \"degrees\": 45 },\n                                \"saturation\": { \"percent\": 50 },\n                                \"shear\": { \"horizontal\": 45, \"vertical\": 45 }\n                            },\n                            \"preprocessing\": {\n                                \"auto-orient\": true,\n                                \"contrast\": { \"type\": \"Contrast Stretching\" },\n                                \"filter-null\": { \"percent\": 50 },\n                                \"grayscale\": true,\n                                \"isolate\": true,\n                                \"remap\": { \"original_class_name\": \"new_class_name\" },\n                                \"resize\": { \"width\": 200, \"height\": 200, \"format\": \"Stretch to\" },\n                                \"static-crop\": { \"x_min\": 10, \"x_max\": 90, \"y_min\": 10, \"y_max\": 90 },\n                                \"tile\": { \"rows\": 2, \"columns\": 2 }\n                            }\n                        }\n\n        Returns:\n            int: The version number that is being generated.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; versions = project.generate_version(settings={...})\n        \"\"\"  # noqa: E501 // docs\n\n        if not {\"augmentation\", \"preprocessing\"} &lt;= settings.keys():\n            raise (\n                RuntimeError(\n                    \"augmentation and preprocessing keys are required to generate. If\"\n                    \" none are desired specify empty dict associated with that key.\"\n                )\n            )\n\n        r = requests.post(\n            f\"{API_URL}/{self.__workspace}/{self.__project_name}/generate?api_key={self.__api_key}\",\n            json=settings,\n        )\n\n        try:\n            r_json = r.json()\n        except Exception:\n            raise RuntimeError(\"Error when requesting to generate a new version for project.\")\n\n        # if the generation succeeds, return the version that is being generated\n        if r.status_code == 200:\n            sys.stdout.write(\"\\r\" + r_json[\"message\"] + \" for new version \" + str(r_json[\"version\"]) + \".\")\n            sys.stdout.write(\"\\n\")\n            sys.stdout.flush()\n            return int(r_json[\"version\"])\n        else:\n            if \"error\" in r_json.keys():\n                raise RuntimeError(r_json[\"error\"])\n            else:\n                raise RuntimeError(json.dumps(r_json))\n\n    def train(\n        self,\n        new_version_settings: Optional[Dict] = None,\n        speed=None,\n        checkpoint=None,\n        plot_in_notebook=False,\n    ):\n        \"\"\"\n        Ask the Roboflow API to train a previously exported version's dataset.\n\n        Args:\n            speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n            checkpoint: A string representing the checkpoint to use while training\n            plot: Whether to plot the training loss curve. Default is False.\n\n        Returns:\n            True\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; version = project.version(1)\n\n            &gt;&gt;&gt; version.train()\n        \"\"\"  # noqa: E501 // docs\n\n        if new_version_settings is None:\n            new_version_settings = {\n                \"preprocessing\": {\n                    \"auto-orient\": True,\n                    \"resize\": {\"width\": 640, \"height\": 640, \"format\": \"Stretch to\"},\n                },\n                \"augmentation\": {},\n            }\n\n        new_version = self.generate_version(settings=new_version_settings)\n        new_version = self.version(new_version)\n        new_model = new_version.train(speed=speed, checkpoint=checkpoint, plot_in_notebook=plot_in_notebook)\n\n        return new_model\n\n    def version(self, version_number: int, local: Optional[str] = None):\n        \"\"\"\n        Retrieves information about a specific version and returns a Version() object.\n\n        Args:\n            version_number (int): the version number that you want to retrieve\n            local (str): specifies the localhost address and port if pointing towards local inference engine\n\n        Returns:\n            Version() object\n        \"\"\"  # noqa: E501 // docs\n\n        if self.__api_key in DEMO_KEYS:\n            name = \"\"\n            if self.__api_key == \"coco-128-sample\":\n                name = \"coco-128\"\n            else:\n                name = \"chess-pieces-new\"\n            return Version(\n                {},\n                \"type\",\n                self.__api_key,\n                name,\n                version_number,\n                self.model_format,\n                local=None,\n                workspace=\"\",\n                project=\"\",\n                public=True,\n            )\n\n        version_info = self.get_version_information()\n\n        for version_object in version_info:\n            current_version_num = os.path.basename(version_object[\"id\"])\n            if current_version_num == str(version_number):\n                vers = Version(\n                    version_object,\n                    self.type,\n                    self.__api_key,\n                    self.name,\n                    current_version_num,\n                    self.model_format,\n                    local=local,\n                    workspace=self.__workspace,\n                    project=self.__project_name,\n                    public=self.public,\n                    colors=self.colors,\n                )\n                return vers\n\n        raise RuntimeError(f\"Version number {version_number} is not found.\")\n\n    def check_valid_image(self, image_path: str) -&gt; bool:\n        \"\"\"\n        Check if an image is valid. Useful before attempting to upload an image to Roboflow.\n\n        Args:\n            image_path (str): path to image you'd like to check\n\n        Returns:\n            bool: whether the image is valid or not\n        \"\"\"\n        kind = filetype.guess(image_path)\n\n        if kind is None:\n            return False\n\n        extension_mimetype, _ = mimetypes.guess_type(image_path)\n\n        if extension_mimetype and extension_mimetype != kind.mime:\n            print(f\"[{image_path}] file type ({kind.mime}) does not match filename extension.\")\n\n        return kind.mime in ACCEPTED_IMAGE_FORMATS\n\n    def upload(\n        self,\n        image_path: str,\n        annotation_path: Optional[str] = None,\n        hosted_image: bool = False,\n        image_id: Optional[str] = None,\n        split: str = \"train\",\n        num_retry_uploads: int = 0,\n        batch_name: Optional[str] = None,\n        tag_names: Optional[List[str]] = None,\n        is_prediction: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Upload an image or annotation to the Roboflow API.\n\n        Args:\n            image_path (str): path to image you'd like to upload\n            annotation_path (str): path to the annotation file. If not provided, the image will be uploaded without annotation.\n                Special case: in classification projects, this can instead be a class name. e.g. \"dog\".\n            hosted_image (bool): whether the image is hosted\n            image_id (str): id of the image\n            split (str): which split to upload to - \"train\", \"valid\" or \"test\"\n            num_retry_uploads (int): how many times to retry upload on failure\n            batch_name (str): name of batch to upload to within project\n            tag_names (list[str]): tags to be applied to an image\n            is_prediction (bool): whether the annotation data is a prediction rather than ground truth\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; project.upload(image_path=\"YOUR_IMAGE.jpg\")\n        \"\"\"  # noqa: E501 // docs\n\n        if tag_names is None:\n            tag_names = []\n\n        is_hosted = image_path.startswith(\"http://\") or image_path.startswith(\"https://\")\n\n        is_file = os.path.isfile(image_path) or is_hosted\n        is_dir = os.path.isdir(image_path)\n\n        if not is_file and not is_dir:\n            raise RuntimeError(\n                f\"The provided image path [ {image_path} ] is not a valid path. Please provide a\"\n                \" path to an image or a directory.\"\n            )\n\n        if is_file:\n            is_image = is_hosted or self.check_valid_image(image_path)\n\n            if not is_image:\n                raise RuntimeError(\n                    \"The image you provided {} is not a supported file format. We currently support: {}.\".format(\n                        image_path, \", \".join(ACCEPTED_IMAGE_FORMATS)\n                    )\n                )\n\n            self.single_upload(\n                image_path=image_path,\n                annotation_path=annotation_path,\n                hosted_image=hosted_image,\n                image_id=image_id,\n                split=split,\n                num_retry_uploads=num_retry_uploads,\n                batch_name=batch_name,\n                tag_names=tag_names,\n                is_prediction=is_prediction,\n                **kwargs,\n            )\n\n        else:\n            images = os.listdir(image_path)\n            for image in images:\n                path = image_path + \"/\" + image\n                if self.check_valid_image(path):\n                    self.single_upload(\n                        image_path=path,\n                        annotation_path=annotation_path,\n                        hosted_image=hosted_image,\n                        image_id=image_id,\n                        split=split,\n                        num_retry_uploads=num_retry_uploads,\n                        batch_name=batch_name,\n                        tag_names=tag_names,\n                        is_prediction=is_prediction,\n                        **kwargs,\n                    )\n                    print(\"[ \" + path + \" ] was uploaded succesfully.\")\n                else:\n                    print(\"[ \" + path + \" ] was skipped.\")\n                    continue\n\n    def upload_image(\n        self,\n        image_path=None,\n        hosted_image=False,\n        split=\"train\",\n        num_retry_uploads=0,\n        batch_name=None,\n        tag_names: Optional[List[str]] = None,\n        sequence_number=None,\n        sequence_size=None,\n        **kwargs,\n    ):\n        project_url = self.id.rsplit(\"/\")[1]\n\n        if tag_names is None:\n            tag_names = []\n\n        t0 = time.time()\n        upload_retry_attempts = 0\n        retry = Retry(num_retry_uploads, ImageUploadError)\n\n        try:\n            image = retry(\n                rfapi.upload_image,\n                self.__api_key,\n                project_url,\n                image_path,\n                hosted_image=hosted_image,\n                split=split,\n                batch_name=batch_name,\n                tag_names=tag_names,\n                sequence_number=sequence_number,\n                sequence_size=sequence_size,\n                **kwargs,\n            )\n            upload_retry_attempts = retry.retries\n        except ImageUploadError as e:\n            e.retries = upload_retry_attempts\n            raise e\n\n        upload_time = time.time() - t0\n\n        return image, upload_time, upload_retry_attempts\n\n    def save_annotation(\n        self,\n        annotation_path=None,\n        annotation_labelmap=None,\n        image_id=None,\n        job_name=None,\n        is_prediction: bool = False,\n        annotation_overwrite=False,\n        num_retry_uploads=0,\n    ):\n        project_url = self.id.rsplit(\"/\")[1]\n        annotation_name, annotation_str = self._annotation_params(annotation_path)\n        t0 = time.time()\n        upload_retry_attempts = 0\n        retry = Retry(num_retry_uploads, AnnotationSaveError)\n\n        try:\n            annotation = rfapi.save_annotation(\n                self.__api_key,\n                project_url,\n                annotation_name,  # type: ignore[type-var]\n                annotation_str,  # type: ignore[type-var]\n                image_id,\n                job_name=job_name,  # type: ignore[type-var]\n                is_prediction=is_prediction,\n                annotation_labelmap=annotation_labelmap,\n                overwrite=annotation_overwrite,\n            )\n            upload_retry_attempts = retry.retries\n        except AnnotationSaveError as e:\n            e.retries = upload_retry_attempts\n            raise\n\n        upload_time = time.time() - t0\n\n        return annotation, upload_time, upload_retry_attempts\n\n    def single_upload(\n        self,\n        image_path=None,\n        annotation_path=None,\n        annotation_labelmap=None,\n        hosted_image=False,\n        image_id=None,\n        split=\"train\",\n        num_retry_uploads=0,\n        batch_name=None,\n        tag_names: Optional[List[str]] = None,\n        is_prediction: bool = False,\n        annotation_overwrite=False,\n        sequence_number=None,\n        sequence_size=None,\n        **kwargs,\n    ):\n        if tag_names is None:\n            tag_names = []\n        if image_path and image_id:\n            raise Exception(\"You can't pass both image_id and image_path\")\n        if not (image_path or image_id):\n            raise Exception(\"You need to pass image_path or image_id\")\n        if isinstance(annotation_labelmap, str):\n            annotation_labelmap = load_labelmap(annotation_labelmap)\n\n        uploaded_image, uploaded_annotation = None, None\n        upload_time, annotation_time = None, None\n        upload_retry_attempts = 0\n        annotation_upload_retry_attempts = 0\n\n        if image_path:\n            uploaded_image, upload_time, upload_retry_attempts = self.upload_image(\n                image_path,\n                hosted_image,\n                split,\n                num_retry_uploads,\n                batch_name,\n                tag_names,\n                sequence_number,\n                sequence_size,\n                **kwargs,\n            )\n            image_id = uploaded_image[\"id\"]  # type: ignore[index]\n\n        if annotation_path and image_id:\n            uploaded_annotation, annotation_time, annotation_upload_retry_attempts = self.save_annotation(\n                annotation_path,\n                annotation_labelmap,\n                image_id,\n                batch_name,\n                is_prediction,\n                annotation_overwrite,\n                num_retry_uploads=num_retry_uploads,\n            )\n\n        return {\n            \"image\": uploaded_image,\n            \"annotation\": uploaded_annotation,\n            \"upload_time\": upload_time,\n            \"annotation_time\": annotation_time,\n            \"upload_retry_attempts\": upload_retry_attempts,\n            \"annotation_upload_retry_attempts\": annotation_upload_retry_attempts,\n        }\n\n    def _annotation_params(self, annotation_path):\n        annotation_name, annotation_string = None, None\n        if isinstance(annotation_path, dict) and annotation_path.get(\"rawText\"):\n            annotation_name = annotation_path[\"name\"]\n            annotation_string = annotation_path[\"rawText\"]\n        elif os.path.exists(annotation_path):  # type: ignore[arg-type]\n            with open(annotation_path):  # type: ignore[arg-type]\n                annotation_string = open(annotation_path).read()  # type: ignore[arg-type]\n            annotation_name = os.path.basename(annotation_path)  # type: ignore[arg-type]\n        elif self.type == \"classification\":\n            print(f\"-&gt; using {annotation_path} as classname for classification project\")\n            annotation_string = annotation_path\n            annotation_name = annotation_path\n        else:\n            raise Exception(\n                f\"File not found or uploading to non-classification \"\n                f\"type project with invalid string. - {annotation_path}\"\n            )\n        return annotation_name, annotation_string\n\n    def search(\n        self,\n        like_image: Optional[str] = None,\n        prompt: Optional[str] = None,\n        offset: int = 0,\n        limit: int = 100,\n        tag: Optional[str] = None,\n        class_name: Optional[str] = None,\n        in_dataset: Optional[str] = None,\n        batch: bool = False,\n        batch_id: Optional[str] = None,\n        fields: Optional[List[str]] = None,\n        *,\n        annotation_job: Optional[bool] = None,\n        annotation_job_id: Optional[str] = None,\n    ):\n        \"\"\"\n        Search for images in a project.\n\n        Args:\n            like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n            prompt (str): search prompt\n            offset (int): offset of results\n            limit (int): limit of results\n            tag (str): tag that an image must have\n            class_name (str): class name that an image must have\n            in_dataset (str): dataset that an image must be in\n            batch (bool): whether the image must be in a batch\n            batch_id (str): batch id that an image must be in\n            annotation_job (bool): whether the image must be in an annotation job\n            annotation_job_id (str): annotation job id that an image must be in\n            fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n        Returns:\n            A list of images that match the search criteria.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; results = project.search(query=\"cat\", limit=10)\n        \"\"\"  # noqa: E501 // docs\n        if fields is None:\n            fields = [\"id\", \"created\", \"name\", \"labels\"]\n\n        payload: Dict[str, Union[str, int, bool, List[str]]] = {}\n\n        if like_image is not None:\n            payload[\"like_image\"] = like_image\n\n        if prompt is not None:\n            payload[\"prompt\"] = prompt\n\n        if offset is not None:\n            payload[\"offset\"] = offset\n\n        if limit is not None:\n            payload[\"limit\"] = limit\n\n        if tag is not None:\n            payload[\"tag\"] = tag\n\n        if class_name is not None:\n            payload[\"class_name\"] = class_name\n\n        if in_dataset is not None:\n            payload[\"in_dataset\"] = in_dataset\n\n        if batch is not None:\n            payload[\"batch\"] = batch\n\n        if batch_id is not None:\n            payload[\"batch_id\"] = batch_id\n\n        if annotation_job is not None:\n            payload[\"annotation_job\"] = annotation_job\n\n        if annotation_job_id is not None:\n            payload[\"annotation_job_id\"] = annotation_job_id\n\n        payload[\"fields\"] = fields\n\n        data = requests.post(\n            API_URL + \"/\" + self.__workspace + \"/\" + self.__project_name + \"/search?api_key=\" + self.__api_key,\n            json=payload,\n        )\n\n        return data.json()[\"results\"]\n\n    def search_all(\n        self,\n        like_image: Optional[str] = None,\n        prompt: Optional[str] = None,\n        offset: int = 0,\n        limit: int = 100,\n        tag: Optional[str] = None,\n        class_name: Optional[str] = None,\n        in_dataset: Optional[str] = None,\n        batch: bool = False,\n        batch_id: Optional[str] = None,\n        fields: Optional[List[str]] = None,\n        *,\n        annotation_job: Optional[bool] = None,\n        annotation_job_id: Optional[str] = None,\n    ):\n        \"\"\"\n        Create a paginated list of search results for use in searching the images in a project.\n\n        Args:\n            like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n            prompt (str): search prompt\n            offset (int): offset of results\n            limit (int): limit of results\n            tag (str): tag that an image must have\n            class_name (str): class name that an image must have\n            in_dataset (str): dataset that an image must be in\n            batch (bool): whether the image must be in a batch\n            batch_id (str): batch id that an image must be in\n            annotation_job (bool): whether the image must be in an annotation job\n            annotation_job_id (str): annotation job id that an image must be in\n            fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n        Returns:\n            A list of images that match the search criteria.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; results = project.search_all(query=\"cat\", limit=10)\n\n            &gt;&gt;&gt; for result in results:\n\n            &gt;&gt;&gt;     print(result)\n        \"\"\"  # noqa: E501 // docs\n        if fields is None:\n            fields = [\"id\", \"created\"]\n\n        while True:\n            data = self.search(\n                like_image=like_image,\n                prompt=prompt,\n                offset=offset,\n                limit=limit,\n                tag=tag,\n                class_name=class_name,\n                in_dataset=in_dataset,\n                batch=batch,\n                batch_id=batch_id,\n                fields=fields,\n                annotation_job=annotation_job,\n                annotation_job_id=annotation_job_id,\n            )\n\n            yield data\n\n            if len(data) &lt; limit:\n                break\n\n            offset += limit\n\n    def __str__(self):\n        \"\"\"\n        Show a string representation of a Project object.\n        \"\"\"\n        # String representation of project\n        json_str = {\"name\": self.name, \"type\": self.type, \"workspace\": self.__workspace}\n\n        return json.dumps(json_str, indent=2)\n\n    def image(self, image_id: str) -&gt; Dict:\n        \"\"\"\n        Fetch the details of a specific image from the Roboflow API.\n\n        Args:\n            image_id (str): The ID of the image to fetch.\n\n        Returns:\n            Dict: A dictionary containing the image details.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; image_details = project.image(\"image-id\")\n        \"\"\"\n        url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/images/{image_id}?api_key={self.__api_key}\"\n\n        data = requests.get(url).json()\n\n        if \"error\" in data:\n            raise RuntimeError(data[\"error\"])\n\n        if \"image\" not in data:\n            print(data, image_id)\n            raise RuntimeError(\"Image not found\")\n\n        image_details = data[\"image\"]\n\n        return image_details\n\n    def create_annotation_job(\n        self, name: str, batch_id: str, num_images: int, labeler_email: str, reviewer_email: str\n    ) -&gt; Dict:\n        \"\"\"\n        Create a new annotation job in the project.\n\n        Args:\n            name (str): The name of the annotation job\n            batch_id (str): The ID of the batch that contains the images to annotate\n            num_images (int): The number of images to include in the job\n            labeler_email (str): The email of the user who will label the images\n            reviewer_email (str): The email of the user who will review the annotations\n\n        Returns:\n            Dict: A dictionary containing the created job details\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; job = project.create_annotation_job(\n            ...     name=\"Job created by API\",\n            ...     batch_id=\"batch123\",\n            ...     num_images=10,\n            ...     labeler_email=\"user@example.com\",\n            ...     reviewer_email=\"reviewer@example.com\"\n            ... )\n        \"\"\"\n        url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/jobs?api_key={self.__api_key}\"\n\n        payload = {\n            \"name\": name,\n            \"batch\": batch_id,\n            \"num_images\": num_images,\n            \"labelerEmail\": labeler_email,\n            \"reviewerEmail\": reviewer_email,\n        }\n\n        response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, json=payload)\n\n        if response.status_code != 200:\n            try:\n                error_data = response.json()\n                if \"error\" in error_data:\n                    raise RuntimeError(error_data[\"error\"])\n                raise RuntimeError(response.text)\n            except ValueError:\n                raise RuntimeError(f\"Failed to create annotation job: {response.text}\")\n\n        return response.json()\n\n    def get_batches(self) -&gt; Dict:\n        \"\"\"\n        Get a list of all batches in the project.\n\n        Returns:\n            Dict: A dictionary containing the list of batches\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; batches = project.get_batches()\n        \"\"\"\n        url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/batches?api_key={self.__api_key}\"\n\n        response = requests.get(url)\n\n        if response.status_code != 200:\n            try:\n                error_data = response.json()\n                if \"error\" in error_data:\n                    raise RuntimeError(error_data[\"error\"])\n                raise RuntimeError(response.text)\n            except ValueError:\n                raise RuntimeError(f\"Failed to get batches: {response.text}\")\n\n        return response.json()\n\n    def get_batch(self, batch_id: str) -&gt; Dict:\n        \"\"\"\n        Get information for a specific batch in the project.\n\n        Args:\n            batch_id (str): The ID of the batch to retrieve\n\n        Returns:\n            Dict: A dictionary containing the batch details\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; batch = project.get_batch(\"batch123\")\n        \"\"\"\n        url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/batches/{batch_id}?api_key={self.__api_key}\"\n\n        response = requests.get(url)\n\n        if response.status_code != 200:\n            try:\n                error_data = response.json()\n                if \"error\" in error_data:\n                    raise RuntimeError(error_data[\"error\"])\n                raise RuntimeError(response.text)\n            except ValueError:\n                raise RuntimeError(f\"Failed to get batch {batch_id}: {response.text}\")\n\n        return response.json()\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.__init__","title":"<code>__init__(api_key, a_project, model_format=None)</code>","text":"<p>Create a Project object that represents a Project associated with a Workspace.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>a_project</code> <code>dict</code> <p>the project information dictionary</p> required <code>model_format</code> <code>str</code> <p>the model format of the project</p> <code>None</code> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def __init__(self, api_key: str, a_project: dict, model_format: Optional[str] = None):\n    \"\"\"\n    Create a Project object that represents a Project associated with a Workspace.\n\n    Args:\n        api_key (str): private roboflow api key\n        a_project (dict): the project information dictionary\n        model_format (str): the model format of the project\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n    \"\"\"\n\n    if api_key:\n        self.__api_key = api_key\n        self.annotation = a_project[\"annotation\"]\n        self.classes = a_project[\"classes\"]\n        self.colors = a_project[\"colors\"]\n        self.created = datetime.datetime.fromtimestamp(a_project[\"created\"])\n        self.id = a_project[\"id\"]\n        self.images = a_project[\"images\"]\n        self.name = a_project[\"name\"]\n        self.public = a_project[\"public\"]\n        self.splits = a_project[\"splits\"]\n        self.type = a_project[\"type\"]\n        self.multilabel = a_project.get(\"multilabel\", False)\n        self.unannotated = a_project[\"unannotated\"]\n        self.updated = datetime.datetime.fromtimestamp(a_project[\"updated\"])\n        self.model_format = model_format\n\n        temp = self.id.rsplit(\"/\")\n        self.__workspace = temp[0]\n        self.__project_name = temp[1]\n\n    elif DEMO_KEYS:\n        self.__api_key = DEMO_KEYS[0]\n        self.model_format = model_format\n\n    else:\n        raise ValueError(\"A valid API key must be provided.\")\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.__str__","title":"<code>__str__()</code>","text":"<p>Show a string representation of a Project object.</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def __str__(self):\n    \"\"\"\n    Show a string representation of a Project object.\n    \"\"\"\n    # String representation of project\n    json_str = {\"name\": self.name, \"type\": self.type, \"workspace\": self.__workspace}\n\n    return json.dumps(json_str, indent=2)\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.check_valid_image","title":"<code>check_valid_image(image_path)</code>","text":"<p>Check if an image is valid. Useful before attempting to upload an image to Roboflow.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to image you'd like to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>whether the image is valid or not</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def check_valid_image(self, image_path: str) -&gt; bool:\n    \"\"\"\n    Check if an image is valid. Useful before attempting to upload an image to Roboflow.\n\n    Args:\n        image_path (str): path to image you'd like to check\n\n    Returns:\n        bool: whether the image is valid or not\n    \"\"\"\n    kind = filetype.guess(image_path)\n\n    if kind is None:\n        return False\n\n    extension_mimetype, _ = mimetypes.guess_type(image_path)\n\n    if extension_mimetype and extension_mimetype != kind.mime:\n        print(f\"[{image_path}] file type ({kind.mime}) does not match filename extension.\")\n\n    return kind.mime in ACCEPTED_IMAGE_FORMATS\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.create_annotation_job","title":"<code>create_annotation_job(name, batch_id, num_images, labeler_email, reviewer_email)</code>","text":"<p>Create a new annotation job in the project.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the annotation job</p> required <code>batch_id</code> <code>str</code> <p>The ID of the batch that contains the images to annotate</p> required <code>num_images</code> <code>int</code> <p>The number of images to include in the job</p> required <code>labeler_email</code> <code>str</code> <p>The email of the user who will label the images</p> required <code>reviewer_email</code> <code>str</code> <p>The email of the user who will review the annotations</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary containing the created job details</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>job = project.create_annotation_job( ...     name=\"Job created by API\", ...     batch_id=\"batch123\", ...     num_images=10, ...     labeler_email=\"user@example.com\", ...     reviewer_email=\"reviewer@example.com\" ... )</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def create_annotation_job(\n    self, name: str, batch_id: str, num_images: int, labeler_email: str, reviewer_email: str\n) -&gt; Dict:\n    \"\"\"\n    Create a new annotation job in the project.\n\n    Args:\n        name (str): The name of the annotation job\n        batch_id (str): The ID of the batch that contains the images to annotate\n        num_images (int): The number of images to include in the job\n        labeler_email (str): The email of the user who will label the images\n        reviewer_email (str): The email of the user who will review the annotations\n\n    Returns:\n        Dict: A dictionary containing the created job details\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; job = project.create_annotation_job(\n        ...     name=\"Job created by API\",\n        ...     batch_id=\"batch123\",\n        ...     num_images=10,\n        ...     labeler_email=\"user@example.com\",\n        ...     reviewer_email=\"reviewer@example.com\"\n        ... )\n    \"\"\"\n    url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/jobs?api_key={self.__api_key}\"\n\n    payload = {\n        \"name\": name,\n        \"batch\": batch_id,\n        \"num_images\": num_images,\n        \"labelerEmail\": labeler_email,\n        \"reviewerEmail\": reviewer_email,\n    }\n\n    response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, json=payload)\n\n    if response.status_code != 200:\n        try:\n            error_data = response.json()\n            if \"error\" in error_data:\n                raise RuntimeError(error_data[\"error\"])\n            raise RuntimeError(response.text)\n        except ValueError:\n            raise RuntimeError(f\"Failed to create annotation job: {response.text}\")\n\n    return response.json()\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.generate_version","title":"<code>generate_version(settings)</code>","text":"<p>Generate a version of a dataset hosted on Roboflow.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <p>A Python dict with augmentation and preprocessing keys and specifications for generation. These settings mirror capabilities available via the Roboflow UI.     For example:         {             \"augmentation\": {                 \"bbblur\": { \"pixels\": 1.5 },                 \"bbbrightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },                 \"bbcrop\": { \"min\": 12, \"max\": 71 },                 \"bbexposure\": { \"percent\": 30 },                 \"bbflip\": { \"horizontal\": true, \"vertical\": false },                 \"bbnoise\": { \"percent\": 50 },                 \"bbninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },                 \"bbrotate\": { \"degrees\": 45 },                 \"bbshear\": { \"horizontal\": 45, \"vertical\": 45 },                 \"blur\": { \"pixels\": 1.5 },                 \"brightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },                 \"crop\": { \"min\": 12, \"max\": 71 },                 \"cutout\": { \"count\": 26, \"percent\": 71 },                 \"exposure\": { \"percent\": 30 },                 \"flip\": { \"horizontal\": true, \"vertical\": false },                 \"hue\": { \"degrees\": 180 },                 \"image\": { \"versions\": 32 },                 \"mosaic\": true,                 \"ninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },                 \"noise\": { \"percent\": 50 },                 \"rgrayscale\": { \"percent\": 50 },                 \"rotate\": { \"degrees\": 45 },                 \"saturation\": { \"percent\": 50 },                 \"shear\": { \"horizontal\": 45, \"vertical\": 45 }             },             \"preprocessing\": {                 \"auto-orient\": true,                 \"contrast\": { \"type\": \"Contrast Stretching\" },                 \"filter-null\": { \"percent\": 50 },                 \"grayscale\": true,                 \"isolate\": true,                 \"remap\": { \"original_class_name\": \"new_class_name\" },                 \"resize\": { \"width\": 200, \"height\": 200, \"format\": \"Stretch to\" },                 \"static-crop\": { \"x_min\": 10, \"x_max\": 90, \"y_min\": 10, \"y_max\": 90 },                 \"tile\": { \"rows\": 2, \"columns\": 2 }             }         }</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The version number that is being generated.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>versions = project.generate_version(settings={...})</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def generate_version(self, settings):\n    \"\"\"\n    Generate a version of a dataset hosted on Roboflow.\n\n    Args:\n        settings: A Python dict with augmentation and preprocessing keys and specifications for generation. These settings mirror capabilities available via the Roboflow UI.\n                For example:\n                    {\n                        \"augmentation\": {\n                            \"bbblur\": { \"pixels\": 1.5 },\n                            \"bbbrightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                            \"bbcrop\": { \"min\": 12, \"max\": 71 },\n                            \"bbexposure\": { \"percent\": 30 },\n                            \"bbflip\": { \"horizontal\": true, \"vertical\": false },\n                            \"bbnoise\": { \"percent\": 50 },\n                            \"bbninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                            \"bbrotate\": { \"degrees\": 45 },\n                            \"bbshear\": { \"horizontal\": 45, \"vertical\": 45 },\n                            \"blur\": { \"pixels\": 1.5 },\n                            \"brightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                            \"crop\": { \"min\": 12, \"max\": 71 },\n                            \"cutout\": { \"count\": 26, \"percent\": 71 },\n                            \"exposure\": { \"percent\": 30 },\n                            \"flip\": { \"horizontal\": true, \"vertical\": false },\n                            \"hue\": { \"degrees\": 180 },\n                            \"image\": { \"versions\": 32 },\n                            \"mosaic\": true,\n                            \"ninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                            \"noise\": { \"percent\": 50 },\n                            \"rgrayscale\": { \"percent\": 50 },\n                            \"rotate\": { \"degrees\": 45 },\n                            \"saturation\": { \"percent\": 50 },\n                            \"shear\": { \"horizontal\": 45, \"vertical\": 45 }\n                        },\n                        \"preprocessing\": {\n                            \"auto-orient\": true,\n                            \"contrast\": { \"type\": \"Contrast Stretching\" },\n                            \"filter-null\": { \"percent\": 50 },\n                            \"grayscale\": true,\n                            \"isolate\": true,\n                            \"remap\": { \"original_class_name\": \"new_class_name\" },\n                            \"resize\": { \"width\": 200, \"height\": 200, \"format\": \"Stretch to\" },\n                            \"static-crop\": { \"x_min\": 10, \"x_max\": 90, \"y_min\": 10, \"y_max\": 90 },\n                            \"tile\": { \"rows\": 2, \"columns\": 2 }\n                        }\n                    }\n\n    Returns:\n        int: The version number that is being generated.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; versions = project.generate_version(settings={...})\n    \"\"\"  # noqa: E501 // docs\n\n    if not {\"augmentation\", \"preprocessing\"} &lt;= settings.keys():\n        raise (\n            RuntimeError(\n                \"augmentation and preprocessing keys are required to generate. If\"\n                \" none are desired specify empty dict associated with that key.\"\n            )\n        )\n\n    r = requests.post(\n        f\"{API_URL}/{self.__workspace}/{self.__project_name}/generate?api_key={self.__api_key}\",\n        json=settings,\n    )\n\n    try:\n        r_json = r.json()\n    except Exception:\n        raise RuntimeError(\"Error when requesting to generate a new version for project.\")\n\n    # if the generation succeeds, return the version that is being generated\n    if r.status_code == 200:\n        sys.stdout.write(\"\\r\" + r_json[\"message\"] + \" for new version \" + str(r_json[\"version\"]) + \".\")\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()\n        return int(r_json[\"version\"])\n    else:\n        if \"error\" in r_json.keys():\n            raise RuntimeError(r_json[\"error\"])\n        else:\n            raise RuntimeError(json.dumps(r_json))\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.get_batch","title":"<code>get_batch(batch_id)</code>","text":"<p>Get information for a specific batch in the project.</p> <p>Parameters:</p> Name Type Description Default <code>batch_id</code> <code>str</code> <p>The ID of the batch to retrieve</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary containing the batch details</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>batch = project.get_batch(\"batch123\")</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def get_batch(self, batch_id: str) -&gt; Dict:\n    \"\"\"\n    Get information for a specific batch in the project.\n\n    Args:\n        batch_id (str): The ID of the batch to retrieve\n\n    Returns:\n        Dict: A dictionary containing the batch details\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; batch = project.get_batch(\"batch123\")\n    \"\"\"\n    url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/batches/{batch_id}?api_key={self.__api_key}\"\n\n    response = requests.get(url)\n\n    if response.status_code != 200:\n        try:\n            error_data = response.json()\n            if \"error\" in error_data:\n                raise RuntimeError(error_data[\"error\"])\n            raise RuntimeError(response.text)\n        except ValueError:\n            raise RuntimeError(f\"Failed to get batch {batch_id}: {response.text}\")\n\n    return response.json()\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.get_batches","title":"<code>get_batches()</code>","text":"<p>Get a list of all batches in the project.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary containing the list of batches</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>batches = project.get_batches()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def get_batches(self) -&gt; Dict:\n    \"\"\"\n    Get a list of all batches in the project.\n\n    Returns:\n        Dict: A dictionary containing the list of batches\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; batches = project.get_batches()\n    \"\"\"\n    url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/batches?api_key={self.__api_key}\"\n\n    response = requests.get(url)\n\n    if response.status_code != 200:\n        try:\n            error_data = response.json()\n            if \"error\" in error_data:\n                raise RuntimeError(error_data[\"error\"])\n            raise RuntimeError(response.text)\n        except ValueError:\n            raise RuntimeError(f\"Failed to get batches: {response.text}\")\n\n    return response.json()\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.get_version_information","title":"<code>get_version_information()</code>","text":"<p>Retrieve all versions of a project.</p> <p>Returns:</p> Type Description <p>A list of all versions of the project.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>version_info = project.get_version_information()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def get_version_information(self):\n    \"\"\"\n    Retrieve all versions of a project.\n\n    Returns:\n        A list of all versions of the project.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; version_info = project.get_version_information()\n    \"\"\"\n    dataset_info = requests.get(\n        API_URL + \"/\" + self.__workspace + \"/\" + self.__project_name + \"?api_key=\" + self.__api_key\n    )\n\n    # Throw error if dataset isn't valid/user doesn't have permissions to access the dataset # noqa: E501 // docs\n    if dataset_info.status_code != 200:\n        raise RuntimeError(dataset_info.text)\n\n    dataset_info = dataset_info.json()\n    return dataset_info[\"versions\"]\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.image","title":"<code>image(image_id)</code>","text":"<p>Fetch the details of a specific image from the Roboflow API.</p> <p>Parameters:</p> Name Type Description Default <code>image_id</code> <code>str</code> <p>The ID of the image to fetch.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary containing the image details.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>image_details = project.image(\"image-id\")</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def image(self, image_id: str) -&gt; Dict:\n    \"\"\"\n    Fetch the details of a specific image from the Roboflow API.\n\n    Args:\n        image_id (str): The ID of the image to fetch.\n\n    Returns:\n        Dict: A dictionary containing the image details.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"YOUR_API_KEY\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; image_details = project.image(\"image-id\")\n    \"\"\"\n    url = f\"{API_URL}/{self.__workspace}/{self.__project_name}/images/{image_id}?api_key={self.__api_key}\"\n\n    data = requests.get(url).json()\n\n    if \"error\" in data:\n        raise RuntimeError(data[\"error\"])\n\n    if \"image\" not in data:\n        print(data, image_id)\n        raise RuntimeError(\"Image not found\")\n\n    image_details = data[\"image\"]\n\n    return image_details\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.list_versions","title":"<code>list_versions()</code>","text":"<p>Print out versions for that specific project.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>project.list_versions()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def list_versions(self):\n    \"\"\"\n    Print out versions for that specific project.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; project.list_versions()\n    \"\"\"\n    version_info = self.get_version_information()\n    print(version_info)\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.search","title":"<code>search(like_image=None, prompt=None, offset=0, limit=100, tag=None, class_name=None, in_dataset=None, batch=False, batch_id=None, fields=None, *, annotation_job=None, annotation_job_id=None)</code>","text":"<p>Search for images in a project.</p> <p>Parameters:</p> Name Type Description Default <code>like_image</code> <code>str</code> <p>name of an image in your dataset to use if you want to find images similar to that one</p> <code>None</code> <code>prompt</code> <code>str</code> <p>search prompt</p> <code>None</code> <code>offset</code> <code>int</code> <p>offset of results</p> <code>0</code> <code>limit</code> <code>int</code> <p>limit of results</p> <code>100</code> <code>tag</code> <code>str</code> <p>tag that an image must have</p> <code>None</code> <code>class_name</code> <code>str</code> <p>class name that an image must have</p> <code>None</code> <code>in_dataset</code> <code>str</code> <p>dataset that an image must be in</p> <code>None</code> <code>batch</code> <code>bool</code> <p>whether the image must be in a batch</p> <code>False</code> <code>batch_id</code> <code>str</code> <p>batch id that an image must be in</p> <code>None</code> <code>annotation_job</code> <code>bool</code> <p>whether the image must be in an annotation job</p> <code>None</code> <code>annotation_job_id</code> <code>str</code> <p>annotation job id that an image must be in</p> <code>None</code> <code>fields</code> <code>list</code> <p>fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])</p> <code>None</code> <p>Returns:</p> Type Description <p>A list of images that match the search criteria.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>results = project.search(query=\"cat\", limit=10)</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def search(\n    self,\n    like_image: Optional[str] = None,\n    prompt: Optional[str] = None,\n    offset: int = 0,\n    limit: int = 100,\n    tag: Optional[str] = None,\n    class_name: Optional[str] = None,\n    in_dataset: Optional[str] = None,\n    batch: bool = False,\n    batch_id: Optional[str] = None,\n    fields: Optional[List[str]] = None,\n    *,\n    annotation_job: Optional[bool] = None,\n    annotation_job_id: Optional[str] = None,\n):\n    \"\"\"\n    Search for images in a project.\n\n    Args:\n        like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n        prompt (str): search prompt\n        offset (int): offset of results\n        limit (int): limit of results\n        tag (str): tag that an image must have\n        class_name (str): class name that an image must have\n        in_dataset (str): dataset that an image must be in\n        batch (bool): whether the image must be in a batch\n        batch_id (str): batch id that an image must be in\n        annotation_job (bool): whether the image must be in an annotation job\n        annotation_job_id (str): annotation job id that an image must be in\n        fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n    Returns:\n        A list of images that match the search criteria.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; results = project.search(query=\"cat\", limit=10)\n    \"\"\"  # noqa: E501 // docs\n    if fields is None:\n        fields = [\"id\", \"created\", \"name\", \"labels\"]\n\n    payload: Dict[str, Union[str, int, bool, List[str]]] = {}\n\n    if like_image is not None:\n        payload[\"like_image\"] = like_image\n\n    if prompt is not None:\n        payload[\"prompt\"] = prompt\n\n    if offset is not None:\n        payload[\"offset\"] = offset\n\n    if limit is not None:\n        payload[\"limit\"] = limit\n\n    if tag is not None:\n        payload[\"tag\"] = tag\n\n    if class_name is not None:\n        payload[\"class_name\"] = class_name\n\n    if in_dataset is not None:\n        payload[\"in_dataset\"] = in_dataset\n\n    if batch is not None:\n        payload[\"batch\"] = batch\n\n    if batch_id is not None:\n        payload[\"batch_id\"] = batch_id\n\n    if annotation_job is not None:\n        payload[\"annotation_job\"] = annotation_job\n\n    if annotation_job_id is not None:\n        payload[\"annotation_job_id\"] = annotation_job_id\n\n    payload[\"fields\"] = fields\n\n    data = requests.post(\n        API_URL + \"/\" + self.__workspace + \"/\" + self.__project_name + \"/search?api_key=\" + self.__api_key,\n        json=payload,\n    )\n\n    return data.json()[\"results\"]\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.search_all","title":"<code>search_all(like_image=None, prompt=None, offset=0, limit=100, tag=None, class_name=None, in_dataset=None, batch=False, batch_id=None, fields=None, *, annotation_job=None, annotation_job_id=None)</code>","text":"<p>Create a paginated list of search results for use in searching the images in a project.</p> <p>Parameters:</p> Name Type Description Default <code>like_image</code> <code>str</code> <p>name of an image in your dataset to use if you want to find images similar to that one</p> <code>None</code> <code>prompt</code> <code>str</code> <p>search prompt</p> <code>None</code> <code>offset</code> <code>int</code> <p>offset of results</p> <code>0</code> <code>limit</code> <code>int</code> <p>limit of results</p> <code>100</code> <code>tag</code> <code>str</code> <p>tag that an image must have</p> <code>None</code> <code>class_name</code> <code>str</code> <p>class name that an image must have</p> <code>None</code> <code>in_dataset</code> <code>str</code> <p>dataset that an image must be in</p> <code>None</code> <code>batch</code> <code>bool</code> <p>whether the image must be in a batch</p> <code>False</code> <code>batch_id</code> <code>str</code> <p>batch id that an image must be in</p> <code>None</code> <code>annotation_job</code> <code>bool</code> <p>whether the image must be in an annotation job</p> <code>None</code> <code>annotation_job_id</code> <code>str</code> <p>annotation job id that an image must be in</p> <code>None</code> <code>fields</code> <code>list</code> <p>fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])</p> <code>None</code> <p>Returns:</p> Type Description <p>A list of images that match the search criteria.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>results = project.search_all(query=\"cat\", limit=10)</p> <p>for result in results:</p> <pre><code>print(result)\n</code></pre> Source code in <code>roboflow/core/project.py</code> <pre><code>def search_all(\n    self,\n    like_image: Optional[str] = None,\n    prompt: Optional[str] = None,\n    offset: int = 0,\n    limit: int = 100,\n    tag: Optional[str] = None,\n    class_name: Optional[str] = None,\n    in_dataset: Optional[str] = None,\n    batch: bool = False,\n    batch_id: Optional[str] = None,\n    fields: Optional[List[str]] = None,\n    *,\n    annotation_job: Optional[bool] = None,\n    annotation_job_id: Optional[str] = None,\n):\n    \"\"\"\n    Create a paginated list of search results for use in searching the images in a project.\n\n    Args:\n        like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n        prompt (str): search prompt\n        offset (int): offset of results\n        limit (int): limit of results\n        tag (str): tag that an image must have\n        class_name (str): class name that an image must have\n        in_dataset (str): dataset that an image must be in\n        batch (bool): whether the image must be in a batch\n        batch_id (str): batch id that an image must be in\n        annotation_job (bool): whether the image must be in an annotation job\n        annotation_job_id (str): annotation job id that an image must be in\n        fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n    Returns:\n        A list of images that match the search criteria.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; results = project.search_all(query=\"cat\", limit=10)\n\n        &gt;&gt;&gt; for result in results:\n\n        &gt;&gt;&gt;     print(result)\n    \"\"\"  # noqa: E501 // docs\n    if fields is None:\n        fields = [\"id\", \"created\"]\n\n    while True:\n        data = self.search(\n            like_image=like_image,\n            prompt=prompt,\n            offset=offset,\n            limit=limit,\n            tag=tag,\n            class_name=class_name,\n            in_dataset=in_dataset,\n            batch=batch,\n            batch_id=batch_id,\n            fields=fields,\n            annotation_job=annotation_job,\n            annotation_job_id=annotation_job_id,\n        )\n\n        yield data\n\n        if len(data) &lt; limit:\n            break\n\n        offset += limit\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.train","title":"<code>train(new_version_settings=None, speed=None, checkpoint=None, plot_in_notebook=False)</code>","text":"<p>Ask the Roboflow API to train a previously exported version's dataset.</p> <p>Parameters:</p> Name Type Description Default <code>speed</code> <p>Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is <code>fast</code>.</p> <code>None</code> <code>checkpoint</code> <p>A string representing the checkpoint to use while training</p> <code>None</code> <code>plot</code> <p>Whether to plot the training loss curve. Default is False.</p> required <p>Returns:</p> Type Description <p>True</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>version = project.version(1)</p> <p>version.train()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def train(\n    self,\n    new_version_settings: Optional[Dict] = None,\n    speed=None,\n    checkpoint=None,\n    plot_in_notebook=False,\n):\n    \"\"\"\n    Ask the Roboflow API to train a previously exported version's dataset.\n\n    Args:\n        speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n        checkpoint: A string representing the checkpoint to use while training\n        plot: Whether to plot the training loss curve. Default is False.\n\n    Returns:\n        True\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; version = project.version(1)\n\n        &gt;&gt;&gt; version.train()\n    \"\"\"  # noqa: E501 // docs\n\n    if new_version_settings is None:\n        new_version_settings = {\n            \"preprocessing\": {\n                \"auto-orient\": True,\n                \"resize\": {\"width\": 640, \"height\": 640, \"format\": \"Stretch to\"},\n            },\n            \"augmentation\": {},\n        }\n\n    new_version = self.generate_version(settings=new_version_settings)\n    new_version = self.version(new_version)\n    new_model = new_version.train(speed=speed, checkpoint=checkpoint, plot_in_notebook=plot_in_notebook)\n\n    return new_model\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.upload","title":"<code>upload(image_path, annotation_path=None, hosted_image=False, image_id=None, split='train', num_retry_uploads=0, batch_name=None, tag_names=None, is_prediction=False, **kwargs)</code>","text":"<p>Upload an image or annotation to the Roboflow API.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to image you'd like to upload</p> required <code>annotation_path</code> <code>str</code> <p>path to the annotation file. If not provided, the image will be uploaded without annotation. Special case: in classification projects, this can instead be a class name. e.g. \"dog\".</p> <code>None</code> <code>hosted_image</code> <code>bool</code> <p>whether the image is hosted</p> <code>False</code> <code>image_id</code> <code>str</code> <p>id of the image</p> <code>None</code> <code>split</code> <code>str</code> <p>which split to upload to - \"train\", \"valid\" or \"test\"</p> <code>'train'</code> <code>num_retry_uploads</code> <code>int</code> <p>how many times to retry upload on failure</p> <code>0</code> <code>batch_name</code> <code>str</code> <p>name of batch to upload to within project</p> <code>None</code> <code>tag_names</code> <code>list[str]</code> <p>tags to be applied to an image</p> <code>None</code> <code>is_prediction</code> <code>bool</code> <p>whether the annotation data is a prediction rather than ground truth</p> <code>False</code> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>project.upload(image_path=\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def upload(\n    self,\n    image_path: str,\n    annotation_path: Optional[str] = None,\n    hosted_image: bool = False,\n    image_id: Optional[str] = None,\n    split: str = \"train\",\n    num_retry_uploads: int = 0,\n    batch_name: Optional[str] = None,\n    tag_names: Optional[List[str]] = None,\n    is_prediction: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Upload an image or annotation to the Roboflow API.\n\n    Args:\n        image_path (str): path to image you'd like to upload\n        annotation_path (str): path to the annotation file. If not provided, the image will be uploaded without annotation.\n            Special case: in classification projects, this can instead be a class name. e.g. \"dog\".\n        hosted_image (bool): whether the image is hosted\n        image_id (str): id of the image\n        split (str): which split to upload to - \"train\", \"valid\" or \"test\"\n        num_retry_uploads (int): how many times to retry upload on failure\n        batch_name (str): name of batch to upload to within project\n        tag_names (list[str]): tags to be applied to an image\n        is_prediction (bool): whether the annotation data is a prediction rather than ground truth\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; project.upload(image_path=\"YOUR_IMAGE.jpg\")\n    \"\"\"  # noqa: E501 // docs\n\n    if tag_names is None:\n        tag_names = []\n\n    is_hosted = image_path.startswith(\"http://\") or image_path.startswith(\"https://\")\n\n    is_file = os.path.isfile(image_path) or is_hosted\n    is_dir = os.path.isdir(image_path)\n\n    if not is_file and not is_dir:\n        raise RuntimeError(\n            f\"The provided image path [ {image_path} ] is not a valid path. Please provide a\"\n            \" path to an image or a directory.\"\n        )\n\n    if is_file:\n        is_image = is_hosted or self.check_valid_image(image_path)\n\n        if not is_image:\n            raise RuntimeError(\n                \"The image you provided {} is not a supported file format. We currently support: {}.\".format(\n                    image_path, \", \".join(ACCEPTED_IMAGE_FORMATS)\n                )\n            )\n\n        self.single_upload(\n            image_path=image_path,\n            annotation_path=annotation_path,\n            hosted_image=hosted_image,\n            image_id=image_id,\n            split=split,\n            num_retry_uploads=num_retry_uploads,\n            batch_name=batch_name,\n            tag_names=tag_names,\n            is_prediction=is_prediction,\n            **kwargs,\n        )\n\n    else:\n        images = os.listdir(image_path)\n        for image in images:\n            path = image_path + \"/\" + image\n            if self.check_valid_image(path):\n                self.single_upload(\n                    image_path=path,\n                    annotation_path=annotation_path,\n                    hosted_image=hosted_image,\n                    image_id=image_id,\n                    split=split,\n                    num_retry_uploads=num_retry_uploads,\n                    batch_name=batch_name,\n                    tag_names=tag_names,\n                    is_prediction=is_prediction,\n                    **kwargs,\n                )\n                print(\"[ \" + path + \" ] was uploaded succesfully.\")\n            else:\n                print(\"[ \" + path + \" ] was skipped.\")\n                continue\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.version","title":"<code>version(version_number, local=None)</code>","text":"<p>Retrieves information about a specific version and returns a Version() object.</p> <p>Parameters:</p> Name Type Description Default <code>version_number</code> <code>int</code> <p>the version number that you want to retrieve</p> required <code>local</code> <code>str</code> <p>specifies the localhost address and port if pointing towards local inference engine</p> <code>None</code> <p>Returns:</p> Type Description <p>Version() object</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def version(self, version_number: int, local: Optional[str] = None):\n    \"\"\"\n    Retrieves information about a specific version and returns a Version() object.\n\n    Args:\n        version_number (int): the version number that you want to retrieve\n        local (str): specifies the localhost address and port if pointing towards local inference engine\n\n    Returns:\n        Version() object\n    \"\"\"  # noqa: E501 // docs\n\n    if self.__api_key in DEMO_KEYS:\n        name = \"\"\n        if self.__api_key == \"coco-128-sample\":\n            name = \"coco-128\"\n        else:\n            name = \"chess-pieces-new\"\n        return Version(\n            {},\n            \"type\",\n            self.__api_key,\n            name,\n            version_number,\n            self.model_format,\n            local=None,\n            workspace=\"\",\n            project=\"\",\n            public=True,\n        )\n\n    version_info = self.get_version_information()\n\n    for version_object in version_info:\n        current_version_num = os.path.basename(version_object[\"id\"])\n        if current_version_num == str(version_number):\n            vers = Version(\n                version_object,\n                self.type,\n                self.__api_key,\n                self.name,\n                current_version_num,\n                self.model_format,\n                local=local,\n                workspace=self.__workspace,\n                project=self.__project_name,\n                public=self.public,\n                colors=self.colors,\n            )\n            return vers\n\n    raise RuntimeError(f\"Version number {version_number} is not found.\")\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.versions","title":"<code>versions()</code>","text":"<p>Return all versions in the project as Version objects.</p> <p>Returns:</p> Type Description <p>A list of Version objects.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>versions = project.versions()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def versions(self):\n    \"\"\"\n    Return all versions in the project as Version objects.\n\n    Returns:\n        A list of Version objects.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; versions = project.versions()\n    \"\"\"\n    version_info = self.get_version_information()\n    version_array = []\n    for a_version in version_info:\n        version_object = Version(\n            a_version,\n            (self.type if \"model\" in a_version else None),\n            self.__api_key,\n            self.name,\n            a_version[\"id\"],\n            self.model_format,\n            local=None,\n            workspace=self.__workspace,\n            project=self.__project_name,\n            public=self.public,\n            colors=self.colors,\n        )\n        version_array.append(version_object)\n    return version_array\n</code></pre>"},{"location":"core/version/","title":"Versions","text":""},{"location":"core/version/#roboflow.core.version.Version","title":"<code>Version</code>","text":"<p>Class representing a Roboflow dataset version.</p> Source code in <code>roboflow/core/version.py</code> <pre><code>class Version:\n    \"\"\"\n    Class representing a Roboflow dataset version.\n    \"\"\"\n\n    model: Optional[InferenceModel]\n\n    def __init__(\n        self,\n        version_dict,\n        type,\n        api_key,\n        name,\n        version,\n        model_format,\n        local: Optional[str],\n        workspace,\n        project,\n        public,\n        colors=None,\n    ):\n        \"\"\"\n        Initialize a Version object.\n        \"\"\"\n        if api_key:\n            self.__api_key = api_key\n            self.name = name\n            self.version = unwrap_version_id(version_id=version)\n            self.type = type\n            self.augmentation = version_dict[\"augmentation\"]\n            self.created = version_dict[\"created\"]\n            self.id = version_dict[\"id\"]\n            self.images = version_dict[\"images\"]\n            self.preprocessing = version_dict[\"preprocessing\"]\n            self.splits = version_dict[\"splits\"]\n            self.model_format = model_format\n            self.workspace = workspace\n            self.project = project\n            self.public = public\n            self.colors = {} if colors is None else colors\n\n            self.colors = colors\n            if \"exports\" in version_dict.keys():\n                self.exports = version_dict[\"exports\"]\n            else:\n                self.exports = []\n\n            version_without_workspace = os.path.basename(str(version))\n\n            try:\n                version_response = rfapi.get_version(self.__api_key, workspace, project, self.version)\n                version_info = version_response.get(\"version\", {})\n                has_model = bool(version_info.get(\"train\", {}).get(\"model\"))\n            except rfapi.RoboflowError:\n                has_model = False\n\n            if not has_model:\n                self.model = None\n            elif self.type == TYPE_OBJECT_DETECTION:\n                self.model = ObjectDetectionModel(\n                    self.__api_key,\n                    self.id,\n                    self.name,\n                    version_without_workspace,\n                    local=local,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                )\n            elif self.type == TYPE_CLASSICATION:\n                self.model = ClassificationModel(\n                    self.__api_key,\n                    self.id,\n                    self.name,\n                    version_without_workspace,\n                    local=local,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                )\n            elif self.type == TYPE_INSTANCE_SEGMENTATION:\n                self.model = InstanceSegmentationModel(\n                    self.__api_key,\n                    self.id,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                    local=local,\n                )\n            elif self.type == TYPE_SEMANTIC_SEGMENTATION:\n                self.model = SemanticSegmentationModel(self.__api_key, self.id)\n            elif self.type == TYPE_KEYPOINT_DETECTION:\n                self.model = KeypointDetectionModel(self.__api_key, self.id, version=version_without_workspace)\n            else:\n                self.model = None\n\n        elif DEMO_KEYS:\n            api_key = DEMO_KEYS[0]\n            if api_key == \"coco-128-sample\":\n                self.__api_key = api_key\n                self.model_format = model_format\n                self.name = \"coco-128\"\n                self.version = \"1\"\n            else:\n                self.__api_key = api_key\n                self.model_format = model_format\n                self.name = \"chess-pieces-new\"\n                self.version = \"23\"\n                self.id = \"joseph-nelson/chess-pieces-new\"\n\n    def __check_if_generating(self):\n        # check Roboflow API to see if this version is still generating\n        versiondict = rfapi.get_version(\n            api_key=self.__api_key,\n            workspace_url=self.workspace,\n            project_url=self.project,\n            version=self.version,\n            nocache=True,\n        )\n        version_obj = versiondict.get(\"version\", {})\n        progress = 0.0 if version_obj.get(\"progress\") is None else float(version_obj.get(\"progress\"))\n        generating = bool(version_obj.get(\"generating\") or version_obj.get(\"images\", 0) == 0)\n        return generating, progress\n\n    def __wait_if_generating(self, recurse=False):\n        # checks if a given version is still in the progress of generating\n\n        still_generating, progress = self.__check_if_generating()\n\n        if still_generating:\n            progress_message = \"Generating version still in progress. Progress: \" + str(round(progress * 100, 2)) + \"%\"\n            sys.stdout.write(\"\\r\" + progress_message)\n            sys.stdout.flush()\n            time.sleep(5)\n            return self.__wait_if_generating(recurse=True)\n\n        else:\n            if recurse:\n                sys.stdout.write(\"\\n\")\n                sys.stdout.flush()\n            return\n\n    def download(self, model_format=None, location=None, overwrite: bool = False):\n        \"\"\"\n        Download and extract a ZIP of a version's dataset in a given format\n\n        :param model_format: A format to use for downloading\n        :param location: An optional path for saving the file\n        :param overwrite: An optional flag to prevent dataset overwrite when dataset is already downloaded\n\n        Args:\n            model_format (str): A format to use for downloading\n            location (str): An optional path for saving the file\n            overwrite (bool): An optional flag to overwrite an existing dataset if the dataset has already downloaded\n\n        Returns:\n            Dataset Object\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n        \"\"\"  # noqa: E501 // docs\n\n        self.__wait_if_generating()\n\n        model_format = self.__get_format_identifier(model_format)\n\n        if model_format not in self.exports:\n            self.export(model_format)\n\n        # if model_format is not in\n\n        if location is None:\n            location = self.__get_download_location()\n        if os.path.exists(location) and not overwrite:\n            return Dataset(self.name, self.version, model_format, os.path.abspath(location))\n\n        if self.__api_key == \"coco-128-sample\":\n            link = \"https://app.roboflow.com/ds/n9QwXwUK42?key=NnVCe2yMxP\"\n        else:\n            workspace, project, *_ = self.id.rsplit(\"/\")\n            try:\n                export_info = rfapi.get_version_export(\n                    api_key=self.__api_key,\n                    workspace_url=workspace,\n                    project_url=project,\n                    version=self.version,\n                    format=model_format,\n                )\n            except rfapi.RoboflowError as e:\n                raise RuntimeError(str(e))\n\n            if \"ready\" in export_info and export_info.get(\"ready\") is False:\n                raise RuntimeError(export_info)\n\n            link = export_info[\"export\"][\"link\"]\n\n        self.__download_zip(link, location, model_format)\n        self.__extract_zip(location, model_format)\n        self.__reformat_yaml(location, model_format)  # TODO: is roboflow-python a place to be munging yaml files?\n\n        return Dataset(self.name, self.version, model_format, os.path.abspath(location))\n\n    def export(self, model_format=None) -&gt; bool | None:\n        \"\"\"\n        Ask the Roboflow API to generate a version's dataset in a given format so that it can be downloaded via the `download()` method.\n\n        The export will be asynchronously generated and available for download after some amount of seconds - depending on dataset size.\n\n        Args:\n            model_format (str): A format to use for downloading\n\n        Returns:\n            True if the export was successful, RuntimeError if the export failed\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n        \"\"\"  # noqa: E501 // docs\n\n        model_format = self.__get_format_identifier(model_format)\n\n        self.__wait_if_generating()\n\n        workspace, project, *_ = self.id.rsplit(\"/\")\n        export_info = rfapi.get_version_export(\n            api_key=self.__api_key,\n            workspace_url=workspace,\n            project_url=project,\n            version=self.version,\n            format=model_format,\n        )\n        while \"ready\" in export_info and export_info.get(\"ready\") is False:\n            progress = export_info.get(\"progress\", 0.0)\n            progress_message = (\n                \"Exporting format \" + model_format + \" in progress : \" + str(round(progress * 100, 2)) + \"%\"\n            )\n            sys.stdout.write(\"\\r\" + progress_message)\n            sys.stdout.flush()\n            time.sleep(1)\n            export_info = rfapi.get_version_export(\n                api_key=self.__api_key,\n                workspace_url=workspace,\n                project_url=project,\n                version=self.version,\n                format=model_format,\n            )\n        if \"export\" in export_info:\n            sys.stdout.write(\"\\n\")\n            print(\"\\r\" + \"Version export complete for \" + model_format + \" format\")\n            sys.stdout.flush()\n            return True\n        else:\n            raise RuntimeError(f\"Unexpected export {export_info}\")\n\n    def train(self, speed=None, model_type=None, checkpoint=None, plot_in_notebook=False) -&gt; InferenceModel:\n        \"\"\"\n        Ask the Roboflow API to train a previously exported version's dataset.\n\n        Args:\n            speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n            model_type: The type of model to train. Default depends on kind of project. It takes precedence over speed. You can check the list of model ids by sending an invalid parameter in this argument.\n            checkpoint: A string representing the checkpoint to use while training\n            plot: Whether to plot the training results. Default is `False`.\n\n        Returns:\n            An instance of the trained model class\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n        \"\"\"  # noqa: E501 // docs\n\n        self.__wait_if_generating()\n\n        train_model_format = get_model_format(model_type)\n        if train_model_format not in self.exports:\n            self.export(train_model_format)\n\n        workspace, project, *_ = self.id.rsplit(\"/\")\n\n        payload_speed = speed if speed else None\n        payload_checkpoint = checkpoint if checkpoint else None\n        payload_model_type = model_type if model_type else None\n\n        write_line(\"Reaching out to Roboflow to start training...\")\n\n        rfapi.start_version_training(\n            api_key=self.__api_key,\n            workspace_url=workspace,\n            project_url=project,\n            version=self.version,\n            speed=payload_speed,\n            checkpoint=payload_checkpoint,\n            model_type=payload_model_type,\n        )\n\n        status = \"training\"\n\n        if plot_in_notebook:\n            from IPython.display import clear_output\n            from matplotlib import pyplot as plt\n\n            def live_plot(epochs, mAP, loss, title=\"\"):\n                clear_output(wait=True)\n\n                plt.subplot(2, 1, 1)\n                plt.plot(epochs, mAP, \"#00FFCE\")\n                plt.title(title)\n                plt.ylabel(\"mAP\")\n\n                plt.subplot(2, 1, 2)\n                plt.plot(epochs, loss, \"#A351FB\")\n                plt.xlabel(\"epochs\")\n                plt.ylabel(\"loss\")\n                plt.show()\n\n        first_graph_write = False\n        previous_epochs: Union[np.ndarray, list] = []\n        num_machine_spin_dots = []\n\n        while status == \"training\" or status == \"running\":\n            version_response = rfapi.get_version(\n                api_key=self.__api_key,\n                workspace_url=self.workspace,\n                project_url=self.project,\n                version=self.version,\n                nocache=True,\n            )\n            version = version_response.get(\"version\", {})\n            if \"models\" in version.keys():\n                models = version[\"models\"]\n            else:\n                models = {}\n\n            if \"train\" in version.keys():\n                if \"results\" in version[\"train\"].keys():\n                    status = \"finished\"\n                    break\n                if \"status\" in version[\"train\"].keys():\n                    if version[\"train\"][\"status\"] == \"failed\":\n                        write_line(line=\"Training failed\")\n                        break\n\n            epochs: Union[np.ndarray, list]\n            mAP: Union[np.ndarray, list]\n            loss: Union[np.ndarray, list]\n\n            if \"roboflow-train\" in models.keys():\n                import numpy as np\n\n                # training has started\n                epochs = np.array([int(epoch[\"epoch\"]) for epoch in models[\"roboflow-train\"][\"epochs\"]])\n                mAP = np.array([float(epoch[\"mAP\"]) for epoch in models[\"roboflow-train\"][\"epochs\"]])\n                loss = np.array(\n                    [\n                        sum(float(epoch[key]) for key in [\"box_loss\", \"class_loss\", \"obj_loss\"] if key in epoch)\n                        for epoch in models[\"roboflow-train\"][\"epochs\"]\n                    ]\n                )\n\n                title = \"Training in Progress\"\n                # plottling logic\n            else:\n                num_machine_spin_dots.append(\".\")\n                if len(num_machine_spin_dots) &gt; 5:\n                    num_machine_spin_dots = [\".\"]\n                title = \"Training Machine Spinning Up\" + \"\".join(num_machine_spin_dots)\n\n                epochs = []\n                mAP = []\n                loss = []\n\n            if (len(epochs) &gt; len(previous_epochs)) or (len(epochs) == 0):\n                if plot_in_notebook:\n                    live_plot(epochs, mAP, loss, title)\n                else:\n                    if len(epochs) &gt; 0:\n                        title = (\n                            title + \": Epoch: \" + str(epochs[-1]) + \" mAP: \" + str(mAP[-1]) + \" loss: \" + str(loss[-1])\n                        )\n                    if not first_graph_write:\n                        write_line(title)\n                        first_graph_write = True\n\n            previous_epochs = copy.deepcopy(epochs)\n\n            time.sleep(5)\n\n        if not self.model:\n            if self.type == TYPE_OBJECT_DETECTION:\n                self.model = ObjectDetectionModel(\n                    self.__api_key,\n                    self.id,\n                    self.name,\n                    self.version,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                )\n            elif self.type == TYPE_CLASSICATION:\n                self.model = ClassificationModel(\n                    self.__api_key,\n                    self.id,\n                    self.name,\n                    self.version,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                )\n            elif self.type == TYPE_INSTANCE_SEGMENTATION:\n                self.model = InstanceSegmentationModel(\n                    self.__api_key,\n                    self.id,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                )\n            elif self.type == TYPE_SEMANTIC_SEGMENTATION:\n                self.model = SemanticSegmentationModel(self.__api_key, self.id)\n            elif self.type == TYPE_KEYPOINT_DETECTION:\n                self.model = KeypointDetectionModel(self.__api_key, self.id, version=self.version)\n            else:\n                raise ValueError(f\"Unsupported model type: {self.type}\")\n\n        # return the model object\n        assert self.model\n        return self.model\n\n    # @warn_for_wrong_dependencies_versions([(\"ultralytics\", \"==\", \"8.0.196\")])\n    def deploy(self, model_type: str, model_path: str, filename: str = \"weights/best.pt\") -&gt; None:\n        \"\"\"Uploads provided weights file to Roboflow.\n\n        Args:\n            model_type (str): The type of the model to be deployed.\n            model_path (str): File path to the model weights to be uploaded.\n            filename (str, optional): The name of the weights file. Defaults to \"weights/best.pt\".\n        \"\"\"\n        model_type = normalize_yolo_model_type(model_type)\n        zip_file_name = process(model_type, model_path, filename)\n\n        if zip_file_name is None:\n            raise RuntimeError(\"Failed to process model\")\n\n        self._upload_zip(model_type, model_path, zip_file_name)\n\n    def _upload_zip(self, model_type: str, model_path: str, model_file_name: str):\n        res = requests.get(\n            f\"{API_URL}/{self.workspace}/{self.project}/{self.version}\"\n            f\"/uploadModel?api_key={self.__api_key}&amp;modelType={model_type}&amp;nocache=true\"\n        )\n        try:\n            if res.status_code == 429:\n                raise RuntimeError(\n                    \"This version already has a trained model. Please generate and\"\n                    \" train a new version in order to upload model to Roboflow.\"\n                )\n            else:\n                res.raise_for_status()\n        except Exception as e:\n            print(f\"An error occured when getting the model upload URL: {e}\")\n            return\n\n        res = requests.put(\n            res.json()[\"url\"],\n            data=open(os.path.join(model_path, model_file_name), \"rb\"),\n        )\n        try:\n            res.raise_for_status()\n\n            if self.public:\n                print(\n                    f\"View the status of your deployment at: {APP_URL}/{self.workspace}/{self.project}/{self.version}\"\n                )\n                print(\n                    \"Share your model with the world at:\"\n                    f\" {UNIVERSE_URL}/{self.workspace}/{self.project}/\"\n                    f\"model/{self.version}\"\n                )\n            else:\n                print(\n                    f\"View the status of your deployment at: {APP_URL}/{self.workspace}/{self.project}/{self.version}\"\n                )\n\n        except Exception as e:\n            print(f\"An error occured when uploading the model: {e}\")\n\n    def __download_zip(self, link, location, format):\n        \"\"\"\n        Download a dataset's zip file from the given URL and save it in the desired location\n\n        Args:\n            link (str): link the URL of the remote zip file\n            location (str): filepath of the data directory to save the zip file to\n            format (str): the format identifier string\n        \"\"\"  # noqa: E501 // docs\n        if not os.path.exists(location):\n            os.makedirs(location)\n\n        def bar_progress(current, total, width=80):\n            progress_message = (\n                f\"Downloading Dataset Version Zip in {location} to {format}: \"\n                f\"{current / total * 100:.0f}% [{current} / {total}] bytes\"\n            )\n            sys.stdout.write(\"\\r\" + progress_message)\n            sys.stdout.flush()\n\n        try:\n            response = requests.get(link, stream=True)\n\n            # write the zip file to the desired location\n            with open(location + \"/roboflow.zip\", \"wb\") as f:\n                total_length = int(response.headers.get(\"content-length\"))  # type: ignore[arg-type]\n                desc = None if TQDM_DISABLE else f\"Downloading Dataset Version Zip in {location} to {format}:\"\n                for chunk in tqdm(\n                    response.iter_content(chunk_size=1024),\n                    desc=desc,\n                    total=int(total_length / 1024) + 1,\n                ):\n                    if chunk:\n                        f.write(chunk)\n                        f.flush()\n\n        except Exception as e:\n            print(f\"Error when trying to download dataset @ {link}\")\n            raise e\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()\n\n    def __extract_zip(self, location, format):\n        \"\"\"\n        Extracts the contents of a downloaded ZIP file and then deletes the zipped file.\n\n        Args:\n            location (str): filepath of the data directory that contains the ZIP file\n            format (str): the format identifier string\n\n        Raises:\n            RuntimeError: If there is an error unzipping the file\n        \"\"\"  # noqa: E501 // docs\n        desc = None if TQDM_DISABLE else f\"Extracting Dataset Version Zip to {location} in {format}:\"\n        with zipfile.ZipFile(location + \"/roboflow.zip\", \"r\") as zip_ref:\n            for member in tqdm(\n                zip_ref.infolist(),\n                desc=desc,\n            ):\n                try:\n                    zip_ref.extract(member, location)\n                except zipfile.error:\n                    raise RuntimeError(\"Error unzipping download\")\n\n        os.remove(location + \"/roboflow.zip\")\n\n    def __get_download_location(self):\n        \"\"\"\n        Get the local path to save a downloaded dataset to\n\n        Returns:\n            str: the local path\n        \"\"\"\n        version_slug = self.name.replace(\" \", \"-\")\n        filename = f\"{version_slug}-{self.version}\"\n\n        directory = os.environ.get(\"DATASET_DIRECTORY\")\n        if directory:\n            return f\"{directory}/{filename}\"\n\n        return filename\n\n    def __get_download_url(self, format):\n        \"\"\"\n        Get the Roboflow API URL for downloading (and exporting downloadable zips)\n\n        Args:\n            format (str): the format identifier string\n\n        Returns:\n            str: the Roboflow API URL\n        \"\"\"\n        workspace, project, *_ = self.id.rsplit(\"/\")\n        return f\"{API_URL}/{workspace}/{project}/{self.version}/{format}\"\n\n    def __get_format_identifier(self, format):\n        \"\"\"\n        If `format` is none, fall back to the instance's `model_format` value.\n\n        If a human readable format name was passed, return the identifier that should be used for Roboflow API calls\n\n        Otherwise, assume that the passed in format is also the identifier\n\n        Args:\n            format (str): a human readable format string\n\n        Returns:\n            str: format identifier string\n        \"\"\"  # noqa: E501 // docs\n        if not format:\n            format = self.model_format\n\n        if not format:\n            raise RuntimeError(\n                \"You must pass a format argument to version.download() or define a model in your Roboflow object\"\n            )\n\n        friendly_formats = {\"yolov5\": \"yolov5pytorch\", \"yolov7\": \"yolov7pytorch\"}\n\n        return friendly_formats.get(format, format)\n\n    def __reformat_yaml(self, location: str, format: str):\n        \"\"\"\n        Certain formats seem to require reformatting the downloaded YAML.\n\n        Args:\n            location (str): filepath of the data directory that contains the yaml file\n            format (str): the format identifier string\n        \"\"\"  # noqa: E501 // docs\n        data_path = os.path.join(location, \"data.yaml\")\n\n        def data_yaml_callback(content: dict) -&gt; dict:\n            if format == \"mt-yolov6\":\n                content[\"train\"] = location + content[\"train\"].lstrip(\".\")\n                content[\"val\"] = location + content[\"val\"].lstrip(\".\")\n                content[\"test\"] = location + content[\"test\"].lstrip(\".\")\n            if format in [\"yolov5pytorch\", \"yolov7pytorch\"]:\n                content[\"train\"] = location + content[\"train\"].lstrip(\"..\")\n                content[\"val\"] = location + content[\"val\"].lstrip(\"..\")\n            try:\n                # get_wrong_dependencies_versions raises exception if ultralytics is not installed at all  # noqa: E501 // docs\n                if format == \"yolov8\" and not get_wrong_dependencies_versions(\n                    dependencies_versions=[(\"ultralytics\", \"==\", \"8.0.196\")]\n                ):\n                    content[\"train\"] = \"train/images\"\n                    content[\"val\"] = \"valid/images\"\n                    content[\"test\"] = \"test/images\"\n            except ModuleNotFoundError:\n                pass\n            return content\n\n        if format in [\"yolov5pytorch\", \"mt-yolov6\", \"yolov7pytorch\", \"yolov8\", \"yolov9\"]:\n            amend_data_yaml(path=data_path, callback=data_yaml_callback)\n\n    def __str__(self):\n        \"\"\"\n        String representation of version object.\n        \"\"\"\n        json_value = {\n            \"name\": self.name,\n            \"type\": self.type,\n            \"version\": self.version,\n            \"augmentation\": self.augmentation,\n            \"created\": self.created,\n            \"preprocessing\": self.preprocessing,\n            \"splits\": self.splits,\n            \"workspace\": self.workspace,\n        }\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__download_zip","title":"<code>__download_zip(link, location, format)</code>","text":"<p>Download a dataset's zip file from the given URL and save it in the desired location</p> <p>Parameters:</p> Name Type Description Default <code>link</code> <code>str</code> <p>link the URL of the remote zip file</p> required <code>location</code> <code>str</code> <p>filepath of the data directory to save the zip file to</p> required <code>format</code> <code>str</code> <p>the format identifier string</p> required Source code in <code>roboflow/core/version.py</code> <pre><code>def __download_zip(self, link, location, format):\n    \"\"\"\n    Download a dataset's zip file from the given URL and save it in the desired location\n\n    Args:\n        link (str): link the URL of the remote zip file\n        location (str): filepath of the data directory to save the zip file to\n        format (str): the format identifier string\n    \"\"\"  # noqa: E501 // docs\n    if not os.path.exists(location):\n        os.makedirs(location)\n\n    def bar_progress(current, total, width=80):\n        progress_message = (\n            f\"Downloading Dataset Version Zip in {location} to {format}: \"\n            f\"{current / total * 100:.0f}% [{current} / {total}] bytes\"\n        )\n        sys.stdout.write(\"\\r\" + progress_message)\n        sys.stdout.flush()\n\n    try:\n        response = requests.get(link, stream=True)\n\n        # write the zip file to the desired location\n        with open(location + \"/roboflow.zip\", \"wb\") as f:\n            total_length = int(response.headers.get(\"content-length\"))  # type: ignore[arg-type]\n            desc = None if TQDM_DISABLE else f\"Downloading Dataset Version Zip in {location} to {format}:\"\n            for chunk in tqdm(\n                response.iter_content(chunk_size=1024),\n                desc=desc,\n                total=int(total_length / 1024) + 1,\n            ):\n                if chunk:\n                    f.write(chunk)\n                    f.flush()\n\n    except Exception as e:\n        print(f\"Error when trying to download dataset @ {link}\")\n        raise e\n    sys.stdout.write(\"\\n\")\n    sys.stdout.flush()\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__extract_zip","title":"<code>__extract_zip(location, format)</code>","text":"<p>Extracts the contents of a downloaded ZIP file and then deletes the zipped file.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>filepath of the data directory that contains the ZIP file</p> required <code>format</code> <code>str</code> <p>the format identifier string</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If there is an error unzipping the file</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __extract_zip(self, location, format):\n    \"\"\"\n    Extracts the contents of a downloaded ZIP file and then deletes the zipped file.\n\n    Args:\n        location (str): filepath of the data directory that contains the ZIP file\n        format (str): the format identifier string\n\n    Raises:\n        RuntimeError: If there is an error unzipping the file\n    \"\"\"  # noqa: E501 // docs\n    desc = None if TQDM_DISABLE else f\"Extracting Dataset Version Zip to {location} in {format}:\"\n    with zipfile.ZipFile(location + \"/roboflow.zip\", \"r\") as zip_ref:\n        for member in tqdm(\n            zip_ref.infolist(),\n            desc=desc,\n        ):\n            try:\n                zip_ref.extract(member, location)\n            except zipfile.error:\n                raise RuntimeError(\"Error unzipping download\")\n\n    os.remove(location + \"/roboflow.zip\")\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__get_download_location","title":"<code>__get_download_location()</code>","text":"<p>Get the local path to save a downloaded dataset to</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the local path</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __get_download_location(self):\n    \"\"\"\n    Get the local path to save a downloaded dataset to\n\n    Returns:\n        str: the local path\n    \"\"\"\n    version_slug = self.name.replace(\" \", \"-\")\n    filename = f\"{version_slug}-{self.version}\"\n\n    directory = os.environ.get(\"DATASET_DIRECTORY\")\n    if directory:\n        return f\"{directory}/{filename}\"\n\n    return filename\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__get_download_url","title":"<code>__get_download_url(format)</code>","text":"<p>Get the Roboflow API URL for downloading (and exporting downloadable zips)</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>the format identifier string</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>the Roboflow API URL</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __get_download_url(self, format):\n    \"\"\"\n    Get the Roboflow API URL for downloading (and exporting downloadable zips)\n\n    Args:\n        format (str): the format identifier string\n\n    Returns:\n        str: the Roboflow API URL\n    \"\"\"\n    workspace, project, *_ = self.id.rsplit(\"/\")\n    return f\"{API_URL}/{workspace}/{project}/{self.version}/{format}\"\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__get_format_identifier","title":"<code>__get_format_identifier(format)</code>","text":"<p>If <code>format</code> is none, fall back to the instance's <code>model_format</code> value.</p> <p>If a human readable format name was passed, return the identifier that should be used for Roboflow API calls</p> <p>Otherwise, assume that the passed in format is also the identifier</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>a human readable format string</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>format identifier string</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __get_format_identifier(self, format):\n    \"\"\"\n    If `format` is none, fall back to the instance's `model_format` value.\n\n    If a human readable format name was passed, return the identifier that should be used for Roboflow API calls\n\n    Otherwise, assume that the passed in format is also the identifier\n\n    Args:\n        format (str): a human readable format string\n\n    Returns:\n        str: format identifier string\n    \"\"\"  # noqa: E501 // docs\n    if not format:\n        format = self.model_format\n\n    if not format:\n        raise RuntimeError(\n            \"You must pass a format argument to version.download() or define a model in your Roboflow object\"\n        )\n\n    friendly_formats = {\"yolov5\": \"yolov5pytorch\", \"yolov7\": \"yolov7pytorch\"}\n\n    return friendly_formats.get(format, format)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__init__","title":"<code>__init__(version_dict, type, api_key, name, version, model_format, local, workspace, project, public, colors=None)</code>","text":"<p>Initialize a Version object.</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __init__(\n    self,\n    version_dict,\n    type,\n    api_key,\n    name,\n    version,\n    model_format,\n    local: Optional[str],\n    workspace,\n    project,\n    public,\n    colors=None,\n):\n    \"\"\"\n    Initialize a Version object.\n    \"\"\"\n    if api_key:\n        self.__api_key = api_key\n        self.name = name\n        self.version = unwrap_version_id(version_id=version)\n        self.type = type\n        self.augmentation = version_dict[\"augmentation\"]\n        self.created = version_dict[\"created\"]\n        self.id = version_dict[\"id\"]\n        self.images = version_dict[\"images\"]\n        self.preprocessing = version_dict[\"preprocessing\"]\n        self.splits = version_dict[\"splits\"]\n        self.model_format = model_format\n        self.workspace = workspace\n        self.project = project\n        self.public = public\n        self.colors = {} if colors is None else colors\n\n        self.colors = colors\n        if \"exports\" in version_dict.keys():\n            self.exports = version_dict[\"exports\"]\n        else:\n            self.exports = []\n\n        version_without_workspace = os.path.basename(str(version))\n\n        try:\n            version_response = rfapi.get_version(self.__api_key, workspace, project, self.version)\n            version_info = version_response.get(\"version\", {})\n            has_model = bool(version_info.get(\"train\", {}).get(\"model\"))\n        except rfapi.RoboflowError:\n            has_model = False\n\n        if not has_model:\n            self.model = None\n        elif self.type == TYPE_OBJECT_DETECTION:\n            self.model = ObjectDetectionModel(\n                self.__api_key,\n                self.id,\n                self.name,\n                version_without_workspace,\n                local=local,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n            )\n        elif self.type == TYPE_CLASSICATION:\n            self.model = ClassificationModel(\n                self.__api_key,\n                self.id,\n                self.name,\n                version_without_workspace,\n                local=local,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n            )\n        elif self.type == TYPE_INSTANCE_SEGMENTATION:\n            self.model = InstanceSegmentationModel(\n                self.__api_key,\n                self.id,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n                local=local,\n            )\n        elif self.type == TYPE_SEMANTIC_SEGMENTATION:\n            self.model = SemanticSegmentationModel(self.__api_key, self.id)\n        elif self.type == TYPE_KEYPOINT_DETECTION:\n            self.model = KeypointDetectionModel(self.__api_key, self.id, version=version_without_workspace)\n        else:\n            self.model = None\n\n    elif DEMO_KEYS:\n        api_key = DEMO_KEYS[0]\n        if api_key == \"coco-128-sample\":\n            self.__api_key = api_key\n            self.model_format = model_format\n            self.name = \"coco-128\"\n            self.version = \"1\"\n        else:\n            self.__api_key = api_key\n            self.model_format = model_format\n            self.name = \"chess-pieces-new\"\n            self.version = \"23\"\n            self.id = \"joseph-nelson/chess-pieces-new\"\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__reformat_yaml","title":"<code>__reformat_yaml(location, format)</code>","text":"<p>Certain formats seem to require reformatting the downloaded YAML.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>filepath of the data directory that contains the yaml file</p> required <code>format</code> <code>str</code> <p>the format identifier string</p> required Source code in <code>roboflow/core/version.py</code> <pre><code>def __reformat_yaml(self, location: str, format: str):\n    \"\"\"\n    Certain formats seem to require reformatting the downloaded YAML.\n\n    Args:\n        location (str): filepath of the data directory that contains the yaml file\n        format (str): the format identifier string\n    \"\"\"  # noqa: E501 // docs\n    data_path = os.path.join(location, \"data.yaml\")\n\n    def data_yaml_callback(content: dict) -&gt; dict:\n        if format == \"mt-yolov6\":\n            content[\"train\"] = location + content[\"train\"].lstrip(\".\")\n            content[\"val\"] = location + content[\"val\"].lstrip(\".\")\n            content[\"test\"] = location + content[\"test\"].lstrip(\".\")\n        if format in [\"yolov5pytorch\", \"yolov7pytorch\"]:\n            content[\"train\"] = location + content[\"train\"].lstrip(\"..\")\n            content[\"val\"] = location + content[\"val\"].lstrip(\"..\")\n        try:\n            # get_wrong_dependencies_versions raises exception if ultralytics is not installed at all  # noqa: E501 // docs\n            if format == \"yolov8\" and not get_wrong_dependencies_versions(\n                dependencies_versions=[(\"ultralytics\", \"==\", \"8.0.196\")]\n            ):\n                content[\"train\"] = \"train/images\"\n                content[\"val\"] = \"valid/images\"\n                content[\"test\"] = \"test/images\"\n        except ModuleNotFoundError:\n            pass\n        return content\n\n    if format in [\"yolov5pytorch\", \"mt-yolov6\", \"yolov7pytorch\", \"yolov8\", \"yolov9\"]:\n        amend_data_yaml(path=data_path, callback=data_yaml_callback)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__str__","title":"<code>__str__()</code>","text":"<p>String representation of version object.</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __str__(self):\n    \"\"\"\n    String representation of version object.\n    \"\"\"\n    json_value = {\n        \"name\": self.name,\n        \"type\": self.type,\n        \"version\": self.version,\n        \"augmentation\": self.augmentation,\n        \"created\": self.created,\n        \"preprocessing\": self.preprocessing,\n        \"splits\": self.splits,\n        \"workspace\": self.workspace,\n    }\n    return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.deploy","title":"<code>deploy(model_type, model_path, filename='weights/best.pt')</code>","text":"<p>Uploads provided weights file to Roboflow.</p> <p>Parameters:</p> Name Type Description Default <code>model_type</code> <code>str</code> <p>The type of the model to be deployed.</p> required <code>model_path</code> <code>str</code> <p>File path to the model weights to be uploaded.</p> required <code>filename</code> <code>str</code> <p>The name of the weights file. Defaults to \"weights/best.pt\".</p> <code>'weights/best.pt'</code> Source code in <code>roboflow/core/version.py</code> <pre><code>def deploy(self, model_type: str, model_path: str, filename: str = \"weights/best.pt\") -&gt; None:\n    \"\"\"Uploads provided weights file to Roboflow.\n\n    Args:\n        model_type (str): The type of the model to be deployed.\n        model_path (str): File path to the model weights to be uploaded.\n        filename (str, optional): The name of the weights file. Defaults to \"weights/best.pt\".\n    \"\"\"\n    model_type = normalize_yolo_model_type(model_type)\n    zip_file_name = process(model_type, model_path, filename)\n\n    if zip_file_name is None:\n        raise RuntimeError(\"Failed to process model\")\n\n    self._upload_zip(model_type, model_path, zip_file_name)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.download","title":"<code>download(model_format=None, location=None, overwrite=False)</code>","text":"<p>Download and extract a ZIP of a version's dataset in a given format</p> <p>:param model_format: A format to use for downloading :param location: An optional path for saving the file :param overwrite: An optional flag to prevent dataset overwrite when dataset is already downloaded</p> <p>Parameters:</p> Name Type Description Default <code>model_format</code> <code>str</code> <p>A format to use for downloading</p> <code>None</code> <code>location</code> <code>str</code> <p>An optional path for saving the file</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>An optional flag to overwrite an existing dataset if the dataset has already downloaded</p> <code>False</code> <p>Returns:</p> Type Description <p>Dataset Object</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def download(self, model_format=None, location=None, overwrite: bool = False):\n    \"\"\"\n    Download and extract a ZIP of a version's dataset in a given format\n\n    :param model_format: A format to use for downloading\n    :param location: An optional path for saving the file\n    :param overwrite: An optional flag to prevent dataset overwrite when dataset is already downloaded\n\n    Args:\n        model_format (str): A format to use for downloading\n        location (str): An optional path for saving the file\n        overwrite (bool): An optional flag to overwrite an existing dataset if the dataset has already downloaded\n\n    Returns:\n        Dataset Object\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n    \"\"\"  # noqa: E501 // docs\n\n    self.__wait_if_generating()\n\n    model_format = self.__get_format_identifier(model_format)\n\n    if model_format not in self.exports:\n        self.export(model_format)\n\n    # if model_format is not in\n\n    if location is None:\n        location = self.__get_download_location()\n    if os.path.exists(location) and not overwrite:\n        return Dataset(self.name, self.version, model_format, os.path.abspath(location))\n\n    if self.__api_key == \"coco-128-sample\":\n        link = \"https://app.roboflow.com/ds/n9QwXwUK42?key=NnVCe2yMxP\"\n    else:\n        workspace, project, *_ = self.id.rsplit(\"/\")\n        try:\n            export_info = rfapi.get_version_export(\n                api_key=self.__api_key,\n                workspace_url=workspace,\n                project_url=project,\n                version=self.version,\n                format=model_format,\n            )\n        except rfapi.RoboflowError as e:\n            raise RuntimeError(str(e))\n\n        if \"ready\" in export_info and export_info.get(\"ready\") is False:\n            raise RuntimeError(export_info)\n\n        link = export_info[\"export\"][\"link\"]\n\n    self.__download_zip(link, location, model_format)\n    self.__extract_zip(location, model_format)\n    self.__reformat_yaml(location, model_format)  # TODO: is roboflow-python a place to be munging yaml files?\n\n    return Dataset(self.name, self.version, model_format, os.path.abspath(location))\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.export","title":"<code>export(model_format=None)</code>","text":"<p>Ask the Roboflow API to generate a version's dataset in a given format so that it can be downloaded via the <code>download()</code> method.</p> <p>The export will be asynchronously generated and available for download after some amount of seconds - depending on dataset size.</p> <p>Parameters:</p> Name Type Description Default <code>model_format</code> <code>str</code> <p>A format to use for downloading</p> <code>None</code> <p>Returns:</p> Type Description <code>bool | None</code> <p>True if the export was successful, RuntimeError if the export failed</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def export(self, model_format=None) -&gt; bool | None:\n    \"\"\"\n    Ask the Roboflow API to generate a version's dataset in a given format so that it can be downloaded via the `download()` method.\n\n    The export will be asynchronously generated and available for download after some amount of seconds - depending on dataset size.\n\n    Args:\n        model_format (str): A format to use for downloading\n\n    Returns:\n        True if the export was successful, RuntimeError if the export failed\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n    \"\"\"  # noqa: E501 // docs\n\n    model_format = self.__get_format_identifier(model_format)\n\n    self.__wait_if_generating()\n\n    workspace, project, *_ = self.id.rsplit(\"/\")\n    export_info = rfapi.get_version_export(\n        api_key=self.__api_key,\n        workspace_url=workspace,\n        project_url=project,\n        version=self.version,\n        format=model_format,\n    )\n    while \"ready\" in export_info and export_info.get(\"ready\") is False:\n        progress = export_info.get(\"progress\", 0.0)\n        progress_message = (\n            \"Exporting format \" + model_format + \" in progress : \" + str(round(progress * 100, 2)) + \"%\"\n        )\n        sys.stdout.write(\"\\r\" + progress_message)\n        sys.stdout.flush()\n        time.sleep(1)\n        export_info = rfapi.get_version_export(\n            api_key=self.__api_key,\n            workspace_url=workspace,\n            project_url=project,\n            version=self.version,\n            format=model_format,\n        )\n    if \"export\" in export_info:\n        sys.stdout.write(\"\\n\")\n        print(\"\\r\" + \"Version export complete for \" + model_format + \" format\")\n        sys.stdout.flush()\n        return True\n    else:\n        raise RuntimeError(f\"Unexpected export {export_info}\")\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.train","title":"<code>train(speed=None, model_type=None, checkpoint=None, plot_in_notebook=False)</code>","text":"<p>Ask the Roboflow API to train a previously exported version's dataset.</p> <p>Parameters:</p> Name Type Description Default <code>speed</code> <p>Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is <code>fast</code>.</p> <code>None</code> <code>model_type</code> <p>The type of model to train. Default depends on kind of project. It takes precedence over speed. You can check the list of model ids by sending an invalid parameter in this argument.</p> <code>None</code> <code>checkpoint</code> <p>A string representing the checkpoint to use while training</p> <code>None</code> <code>plot</code> <p>Whether to plot the training results. Default is <code>False</code>.</p> required <p>Returns:</p> Type Description <code>InferenceModel</code> <p>An instance of the trained model class</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def train(self, speed=None, model_type=None, checkpoint=None, plot_in_notebook=False) -&gt; InferenceModel:\n    \"\"\"\n    Ask the Roboflow API to train a previously exported version's dataset.\n\n    Args:\n        speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n        model_type: The type of model to train. Default depends on kind of project. It takes precedence over speed. You can check the list of model ids by sending an invalid parameter in this argument.\n        checkpoint: A string representing the checkpoint to use while training\n        plot: Whether to plot the training results. Default is `False`.\n\n    Returns:\n        An instance of the trained model class\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n    \"\"\"  # noqa: E501 // docs\n\n    self.__wait_if_generating()\n\n    train_model_format = get_model_format(model_type)\n    if train_model_format not in self.exports:\n        self.export(train_model_format)\n\n    workspace, project, *_ = self.id.rsplit(\"/\")\n\n    payload_speed = speed if speed else None\n    payload_checkpoint = checkpoint if checkpoint else None\n    payload_model_type = model_type if model_type else None\n\n    write_line(\"Reaching out to Roboflow to start training...\")\n\n    rfapi.start_version_training(\n        api_key=self.__api_key,\n        workspace_url=workspace,\n        project_url=project,\n        version=self.version,\n        speed=payload_speed,\n        checkpoint=payload_checkpoint,\n        model_type=payload_model_type,\n    )\n\n    status = \"training\"\n\n    if plot_in_notebook:\n        from IPython.display import clear_output\n        from matplotlib import pyplot as plt\n\n        def live_plot(epochs, mAP, loss, title=\"\"):\n            clear_output(wait=True)\n\n            plt.subplot(2, 1, 1)\n            plt.plot(epochs, mAP, \"#00FFCE\")\n            plt.title(title)\n            plt.ylabel(\"mAP\")\n\n            plt.subplot(2, 1, 2)\n            plt.plot(epochs, loss, \"#A351FB\")\n            plt.xlabel(\"epochs\")\n            plt.ylabel(\"loss\")\n            plt.show()\n\n    first_graph_write = False\n    previous_epochs: Union[np.ndarray, list] = []\n    num_machine_spin_dots = []\n\n    while status == \"training\" or status == \"running\":\n        version_response = rfapi.get_version(\n            api_key=self.__api_key,\n            workspace_url=self.workspace,\n            project_url=self.project,\n            version=self.version,\n            nocache=True,\n        )\n        version = version_response.get(\"version\", {})\n        if \"models\" in version.keys():\n            models = version[\"models\"]\n        else:\n            models = {}\n\n        if \"train\" in version.keys():\n            if \"results\" in version[\"train\"].keys():\n                status = \"finished\"\n                break\n            if \"status\" in version[\"train\"].keys():\n                if version[\"train\"][\"status\"] == \"failed\":\n                    write_line(line=\"Training failed\")\n                    break\n\n        epochs: Union[np.ndarray, list]\n        mAP: Union[np.ndarray, list]\n        loss: Union[np.ndarray, list]\n\n        if \"roboflow-train\" in models.keys():\n            import numpy as np\n\n            # training has started\n            epochs = np.array([int(epoch[\"epoch\"]) for epoch in models[\"roboflow-train\"][\"epochs\"]])\n            mAP = np.array([float(epoch[\"mAP\"]) for epoch in models[\"roboflow-train\"][\"epochs\"]])\n            loss = np.array(\n                [\n                    sum(float(epoch[key]) for key in [\"box_loss\", \"class_loss\", \"obj_loss\"] if key in epoch)\n                    for epoch in models[\"roboflow-train\"][\"epochs\"]\n                ]\n            )\n\n            title = \"Training in Progress\"\n            # plottling logic\n        else:\n            num_machine_spin_dots.append(\".\")\n            if len(num_machine_spin_dots) &gt; 5:\n                num_machine_spin_dots = [\".\"]\n            title = \"Training Machine Spinning Up\" + \"\".join(num_machine_spin_dots)\n\n            epochs = []\n            mAP = []\n            loss = []\n\n        if (len(epochs) &gt; len(previous_epochs)) or (len(epochs) == 0):\n            if plot_in_notebook:\n                live_plot(epochs, mAP, loss, title)\n            else:\n                if len(epochs) &gt; 0:\n                    title = (\n                        title + \": Epoch: \" + str(epochs[-1]) + \" mAP: \" + str(mAP[-1]) + \" loss: \" + str(loss[-1])\n                    )\n                if not first_graph_write:\n                    write_line(title)\n                    first_graph_write = True\n\n        previous_epochs = copy.deepcopy(epochs)\n\n        time.sleep(5)\n\n    if not self.model:\n        if self.type == TYPE_OBJECT_DETECTION:\n            self.model = ObjectDetectionModel(\n                self.__api_key,\n                self.id,\n                self.name,\n                self.version,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n            )\n        elif self.type == TYPE_CLASSICATION:\n            self.model = ClassificationModel(\n                self.__api_key,\n                self.id,\n                self.name,\n                self.version,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n            )\n        elif self.type == TYPE_INSTANCE_SEGMENTATION:\n            self.model = InstanceSegmentationModel(\n                self.__api_key,\n                self.id,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n            )\n        elif self.type == TYPE_SEMANTIC_SEGMENTATION:\n            self.model = SemanticSegmentationModel(self.__api_key, self.id)\n        elif self.type == TYPE_KEYPOINT_DETECTION:\n            self.model = KeypointDetectionModel(self.__api_key, self.id, version=self.version)\n        else:\n            raise ValueError(f\"Unsupported model type: {self.type}\")\n\n    # return the model object\n    assert self.model\n    return self.model\n</code></pre>"},{"location":"core/workspace/","title":"Workspaces","text":""},{"location":"core/workspace/#roboflow.core.workspace.Workspace","title":"<code>Workspace</code>","text":"<p>Manage a Roboflow workspace.</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>class Workspace:\n    \"\"\"\n    Manage a Roboflow workspace.\n    \"\"\"\n\n    def __init__(self, info, api_key, default_workspace, model_format):\n        if api_key:\n            self.__api_key = api_key\n\n            workspace_info = info[\"workspace\"]\n            self.name = workspace_info[\"name\"]\n            self.project_list = workspace_info[\"projects\"]\n            if \"members\" in workspace_info.keys():\n                self.members = workspace_info[\"members\"]\n            self.url = workspace_info[\"url\"]\n            self.model_format = model_format\n\n        elif DEMO_KEYS:\n            self.__api_key = DEMO_KEYS[0]\n            self.model_format = model_format\n            self.project_list = []\n\n        else:\n            raise ValueError(\"A valid API key must be provided.\")\n\n    def list_projects(self):\n        \"\"\"\n        Print all projects in the workspace to the console.\n        \"\"\"\n        print(self.project_list)\n\n    def projects(self):\n        \"\"\"\n        Retrieve all projects in the workspace.\n\n        Returns:\n            List of Project objects.\n        \"\"\"\n        projects_array = []\n        for a_project in self.project_list:\n            proj = Project(self.__api_key, a_project, self.model_format)\n            projects_array.append(proj.id)\n\n        return projects_array\n\n    def project(self, project_id):\n        \"\"\"\n        Retrieve a Project() object that represents a project in the workspace.\n\n        This object can be used to retrieve the model through which to run inference.\n\n        Args:\n            project_id (str): id of the project\n\n        Returns:\n            Project Object\n        \"\"\"\n        sys.stdout.write(\"\\r\" + \"loading Roboflow project...\")\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()\n\n        if self.__api_key in DEMO_KEYS:\n            return Project(self.__api_key, {}, self.model_format)\n\n        # project_id = project_id.replace(self.url + \"/\", \"\")\n\n        if \"/\" in project_id:\n            raise RuntimeError(f\"The {project_id} project is not available in this ({self.url}) workspace\")\n\n        dataset_info = rfapi.get_project(self.__api_key, self.url, project_id)\n        dataset_info = dataset_info[\"project\"]\n\n        return Project(self.__api_key, dataset_info, self.model_format)\n\n    def create_project(self, project_name, project_type, project_license, annotation):\n        \"\"\"\n        Create a project in a Roboflow workspace.\n\n        Args:\n            project_name (str): name of the project\n            project_type (str): type of the project\n            project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n            annotation (str): annotation of the project\n\n        Returns:\n            Project Object\n        \"\"\"  # noqa: E501 // docs\n        data = {\n            \"name\": project_name,\n            \"type\": project_type,\n            \"license\": project_license,\n            \"annotation\": annotation,\n        }\n\n        r = requests.post(API_URL + \"/\" + self.url + \"/projects?api_key=\" + self.__api_key, json=data)\n\n        r.raise_for_status()\n\n        if \"error\" in r.json().keys():\n            raise RuntimeError(r.json()[\"error\"])\n\n        return self.project(r.json()[\"id\"].split(\"/\")[-1])\n\n    def clip_compare(self, dir: str = \"\", image_ext: str = \".png\", target_image: str = \"\") -&gt; List[dict]:\n        \"\"\"\n        Compare all images in a directory to a target image using CLIP\n\n        Args:\n            dir (str): name reference to a directory of images for comparison\n            image_ext (str): file format for expected images (don't include the . before the file type name)\n            target_image (str): name reference for target image to compare individual images from directory against\n\n        Returns:\n            # TODO: fix docs\n            dict: a key:value mapping of image_name:comparison_score_to_target\n        \"\"\"  # noqa: E501 // docs\n\n        # list to store comparison results in\n        comparisons = []\n        # grab all images in a given directory with ext type\n        for image in glob.glob(f\"./{dir}/*{image_ext}\"):\n            # compare image\n            similarity = clip_encode(image, target_image, CLIP_FEATURIZE_URL)\n            # map image name to similarity score\n            comparisons.append({image: similarity})\n            comparisons = sorted(comparisons, key=lambda item: -list(item.values())[0])\n        return comparisons\n\n    def two_stage(\n        self,\n        image: str = \"\",\n        first_stage_model_name: str = \"\",\n        first_stage_model_version: int = 0,\n        second_stage_model_name: str = \"\",\n        second_stage_model_version: int = 0,\n    ) -&gt; List[dict]:\n        \"\"\"\n        For each prediction in a first stage detection, perform detection with the second stage model\n\n        Args:\n            image (str): name of the image to be processed\n            first_stage_model_name (str): name of the first stage detection model\n            first_stage_model_version (int): version number for the first stage model\n            second_stage_mode (str): name of the second stage detection model\n            second_stage_model_version (int): version number for the second stage model\n\n        Returns:\n            # TODO: fix docs\n            dict: a json obj containing the results of the second stage detection\n        \"\"\"  # noqa: E501 // docs\n        results = []\n\n        # create PIL image for cropping\n        pil_image = Image.open(image).convert(\"RGB\")\n\n        # grab first and second stage model from project\n        stage_one_project = self.project(first_stage_model_name)\n        stage_one_model = stage_one_project.version(first_stage_model_version).model\n        stage_two_project = self.project(second_stage_model_name)\n        stage_two_model = stage_two_project.version(second_stage_model_version).model\n\n        print(self.project(first_stage_model_name))\n\n        # perform first inference\n        predictions = stage_one_model.predict(image)  # type: ignore[attribute-error]\n\n        if stage_one_project.type == \"object-detection\" and stage_two_project == \"classification\":\n            # interact with each detected object from stage one inference results\n            for boundingbox in predictions:\n                # rip bounding box coordinates from json1\n                # note: infer returns center points of box as (x,y) and width, height\n                # ----- but pillow crop requires the top left and bottom right points to crop  # noqa: E501 // docs\n                box = (\n                    boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                    boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n                )\n\n                # create a new cropped image using the first stage prediction coordinates (for each box!)  # noqa: E501 // docs\n                croppedImg = pil_image.crop(box)\n                croppedImg.save(\"./temp.png\")\n\n                # capture results of second stage inference from cropped image\n                results.append(stage_two_model.predict(\"./temp.png\")[0])  # type: ignore[attribute-error]\n\n            # delete the written image artifact\n            try:\n                os.remove(\"./temp.png\")\n            except FileNotFoundError:\n                print(\"no detections\")\n\n        else:\n            print(\n                \"please use an object detection model for the first stage--can only\"\n                \" perform two stage with bounding box results\",\n                \"please use a classification model for the second stage\",\n            )\n\n        return results\n\n    def two_stage_ocr(\n        self,\n        image: str = \"\",\n        first_stage_model_name: str = \"\",\n        first_stage_model_version: int = 0,\n    ) -&gt; List[dict]:\n        \"\"\"\n        For each prediction in the first stage object detection, perform OCR as second stage.\n\n        Args:\n            image (str): name of the image to be processed\n            first_stage_model_name (str): name of the first stage detection model\n            first_stage_model_version (int): version number for the first stage model\n\n        Returns:\n            # TODO: fix docs\n            dict: a json obj containing the results of the second stage detection\n        \"\"\"  # noqa: E501 // docs\n        results = []\n\n        # create PIL image for cropping\n        pil_image = Image.open(image).convert(\"RGB\")\n\n        # grab first and second stage model from project\n        stage_one_project = self.project(first_stage_model_name)\n        stage_one_model = stage_one_project.version(first_stage_model_version).model\n\n        # perform first inference\n        predictions = stage_one_model.predict(image)  # type: ignore[attribute-error]\n\n        # interact with each detected object from stage one inference results\n        if stage_one_project.type == \"object-detection\":\n            for boundingbox in predictions:\n                # rip bounding box coordinates from json1\n                # note: infer returns center points of box as (x,y) and width, height\n                # but pillow crop requires the top left and bottom right points to crop\n                box = (\n                    boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                    boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n                )\n\n                # create a new cropped image using the first stage\n                # prediction coordinates (for each box!)\n                croppedImg = pil_image.crop(box)\n\n                # capture OCR results from cropped image\n                results.append(ocr_infer(croppedImg)[\"results\"])\n        else:\n            print(\"please use an object detection model--can only perform two stage with bounding box results\")\n\n        return results\n\n    def upload_dataset(\n        self,\n        dataset_path: str,\n        project_name: str,\n        num_workers: int = 10,\n        dataset_format: str = \"NOT_USED\",  # deprecated. keep for backward compatibility\n        project_license: str = \"MIT\",\n        project_type: str = \"object-detection\",\n        batch_name=None,\n        num_retries=0,\n    ):\n        \"\"\"\n        Upload a dataset to Roboflow.\n\n        Args:\n            dataset_path (str): path to the dataset\n            project_name (str): name of the project\n            num_workers (int): number of workers to use for parallel uploads\n            dataset_format (str): format of the dataset (`voc`, `yolov8`, `yolov5`)\n            project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n            project_type (str): type of the project (only `object-detection` is supported)\n        \"\"\"  # noqa: E501 // docs\n        if dataset_format != \"NOT_USED\":\n            print(\"Warning: parameter 'dataset_format' is deprecated and will be removed in a future release\")\n        project, created = self._get_or_create_project(\n            project_id=project_name, license=project_license, type=project_type\n        )\n        is_classification = project.type == \"classification\"\n        parsed_dataset = folderparser.parsefolder(dataset_path, is_classification=is_classification)\n        if created:\n            print(f\"Created project {project.id}\")\n        else:\n            print(f\"Uploading to existing project {project.id}\")\n        images = parsed_dataset[\"images\"]\n\n        location = parsed_dataset[\"location\"]\n\n        def _log_img_upload(\n            image_path, image, annotation, image_upload_time, image_upload_retry_attempts, annotation_time\n        ):\n            image_id = image.get(\"id\")\n            img_success = image.get(\"success\")\n            img_duplicate = image.get(\"duplicate\")\n\n            upload_time_str = f\"[{image_upload_time:.1f}s]\"\n            annotation_time_str = f\"[{annotation_time:.1f}s]\" if annotation_time else \"\"\n            retry_attempts = f\" (with {image_upload_retry_attempts} retries)\" if image_upload_retry_attempts &gt; 0 else \"\"\n\n            if img_duplicate:\n                msg = f\"[DUPLICATE]{retry_attempts} {image_path} ({image_id}) {upload_time_str}\"\n            elif img_success:\n                msg = f\"[UPLOADED]{retry_attempts} {image_path} ({image_id}) {upload_time_str}\"\n            else:\n                msg = f\"[LOG ERROR]: Unrecognized image upload status ({image_id=})\"\n            if annotation:\n                if annotation.get(\"success\"):\n                    msg += f\" / annotations = OK {annotation_time_str}\"\n                elif annotation.get(\"warn\"):\n                    msg += f\" / annotations = WARN: {annotation['warn']} {annotation_time_str}\"\n                else:\n                    msg += \" / annotations = ERR: Unrecognized annotation upload status\"\n\n            print(msg)\n\n        def _upload_image(imagedesc):\n            image_path = f\"{location}{imagedesc['file']}\"\n            split = imagedesc[\"split\"]\n\n            image, upload_time, upload_retry_attempts = project.upload_image(\n                image_path=image_path,\n                split=split,\n                batch_name=batch_name,\n                sequence_number=imagedesc.get(\"index\"),\n                sequence_size=len(images),\n                num_retry_uploads=num_retries,\n            )\n\n            return image, upload_time, upload_retry_attempts\n\n        def _save_annotation(image_id, imagedesc):\n            labelmap = None\n            annotation_path = None\n\n            annotationdesc = imagedesc.get(\"annotationfile\")\n            if isinstance(annotationdesc, dict):\n                if annotationdesc.get(\"type\") == \"classification_folder\":\n                    annotation_path = annotationdesc.get(\"classification_label\")\n                elif annotationdesc.get(\"type\") == \"classification_multilabel\":\n                    annotation_path = json.dumps(annotationdesc.get(\"labels\", []))\n                elif annotationdesc.get(\"rawText\"):\n                    annotation_path = annotationdesc\n                elif annotationdesc.get(\"file\"):\n                    annotation_path = f\"{location}{annotationdesc['file']}\"\n                    labelmap = annotationdesc.get(\"labelmap\")\n\n                if isinstance(labelmap, str):\n                    labelmap = load_labelmap(labelmap)\n\n            # If annotation_path is still None at this point, then no annotation will be saved.\n            if annotation_path is None:\n                return None, None\n\n            annotation, upload_time, _retry_attempts = project.save_annotation(\n                annotation_path=annotation_path,\n                annotation_labelmap=labelmap,\n                image_id=image_id,\n                job_name=batch_name,\n                num_retry_uploads=num_retries,\n            )\n\n            return annotation, upload_time\n\n        def _upload(imagedesc):\n            image_path = f\"{location}{imagedesc['file']}\"\n\n            image_id = None\n            image_upload_time = None\n            image_retry_attempts = None\n\n            try:\n                image, image_upload_time, image_retry_attempts = _upload_image(imagedesc)\n                image_id = image[\"id\"]\n                annotation, annotation_time = _save_annotation(image_id, imagedesc)\n                _log_img_upload(image_path, image, annotation, image_upload_time, image_retry_attempts, annotation_time)\n            except ImageUploadError as e:\n                retry_attempts = f\" (with {e.retries} retries)\" if e.retries &gt; 0 else \"\"\n                print(f\"[ERR]{retry_attempts} {image_path} ({e.message})\")\n            except AnnotationSaveError as e:\n                upload_time_str = f\"[{image_upload_time:.1f}s]\"\n                retry_attempts = f\" (with {image_retry_attempts} retries)\" if image_retry_attempts &gt; 0 else \"\"\n                image_msg = f\"[UPLOADED]{retry_attempts} {image_path} ({image_id}) {upload_time_str}\"\n                annotation_msg = f\"annotations = ERR: {e.message}\"\n                print(f\"{image_msg} / {annotation_msg}\")\n            except Exception as e:\n                print(f\"[ERR] {image_path} ({e})\")\n\n        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n            list(executor.map(_upload, images))\n\n    def _get_or_create_project(self, project_id, license: str = \"MIT\", type: str = \"object-detection\"):\n        try:\n            existing_project = self.project(project_id)\n            return existing_project, False\n        except RoboflowError:\n            return (\n                self.create_project(\n                    project_name=project_id,\n                    project_license=license,\n                    annotation=project_id,\n                    project_type=type,\n                ),\n                True,\n            )\n\n    def active_learning(\n        self,\n        raw_data_location: str = \"\",\n        raw_data_extension: str = \"\",\n        inference_endpoint: Optional[List[str]] = None,\n        upload_destination: str = \"\",\n        conditionals: Optional[Dict] = None,\n        use_localhost: bool = False,\n        local_server=\"http://localhost:9001/\",\n    ) -&gt; Any:\n        \"\"\"perform inference on each image in directory and upload based on conditions\n        @params:\n            raw_data_location: (str) = folder of frames to be processed\n            raw_data_extension: (str) = extension of frames to be processed\n            inference_endpoint: (List[str, int]) = name of the project\n            upload_destination: (str) = name of the upload project\n            conditionals: (dict) = dictionary of upload conditions\n            use_localhost: (bool) = determines if local http format used or remote endpoint\n            local_server: (str) = local http address for inference server, use_localhost must be True for this to be used\n        \"\"\"  # noqa: E501 // docs\n        if inference_endpoint is None:\n            inference_endpoint = []\n        if conditionals is None:\n            conditionals = {}\n\n        import numpy as np\n\n        prediction_results = []\n\n        # ensure that all fields of conditionals have a key:value pair\n        conditionals[\"target_classes\"] = [] if \"target_classes\" not in conditionals else conditionals[\"target_classes\"]\n        conditionals[\"confidence_interval\"] = (\n            [30, 99] if \"confidence_interval\" not in conditionals else conditionals[\"confidence_interval\"]\n        )\n        conditionals[\"required_class_variance_count\"] = (\n            1 if \"required_class_variance_count\" not in conditionals else conditionals[\"required_class_variance_count\"]\n        )\n        conditionals[\"required_objects_count\"] = (\n            1 if \"required_objects_count\" not in conditionals else conditionals[\"required_objects_count\"]\n        )\n        conditionals[\"required_class_count\"] = (\n            0 if \"required_class_count\" not in conditionals else conditionals[\"required_class_count\"]\n        )\n        conditionals[\"minimum_size_requirement\"] = (\n            float(\"-inf\")\n            if \"minimum_size_requirement\" not in conditionals\n            else conditionals[\"minimum_size_requirement\"]\n        )\n        conditionals[\"maximum_size_requirement\"] = (\n            float(\"inf\") if \"maximum_size_requirement\" not in conditionals else conditionals[\"maximum_size_requirement\"]\n        )\n\n        # check if inference_model references endpoint or local\n        if use_localhost:\n            local = local_server\n        else:\n            local = None\n\n        inference_model = (\n            self.project(inference_endpoint[0]).version(version_number=inference_endpoint[1], local=local).model\n        )\n        upload_project = self.project(upload_destination)\n\n        print(\"inference reference point: \", inference_model)\n        print(\"upload destination: \", upload_project)\n\n        # check if raw data type is cv2 frame\n        if issubclass(type(raw_data_location), np.ndarray):\n            globbed_files = [raw_data_location]\n        else:\n            globbed_files = glob.glob(raw_data_location + \"/*\" + raw_data_extension)\n\n        image1 = globbed_files[0]\n        similarity_timeout_counter = 0\n\n        for index, image in enumerate(globbed_files):\n            try:\n                print(\n                    \"*** Processing image [\" + str(index + 1) + \"/\" + str(len(globbed_files)) + \"] - \" + image + \" ***\"\n                )\n            except Exception:\n                pass\n\n            if \"similarity_confidence_threshold\" in conditionals.keys():\n                image2 = image\n                # measure the similarity of two images using CLIP (hits an endpoint hosted by Roboflow)   # noqa: E501 // docs\n                similarity = clip_encode(image1, image2, CLIP_FEATURIZE_URL)\n                similarity_timeout_counter += 1\n\n                if (\n                    similarity &lt;= conditionals[\"similarity_confidence_threshold\"]\n                    or similarity_timeout_counter == conditionals[\"similarity_timeout_limit\"]\n                ):\n                    image1 = image\n                    similarity_timeout_counter = 0\n                else:\n                    print(image2 + \" --&gt; similarity too high to --&gt; \" + image1)\n                    continue  # skip this image if too similar or counter hits limit\n\n            predictions = inference_model.predict(image).json()[\"predictions\"]  # type: ignore[attribute-error]\n            # collect all predictions to return to user at end\n            prediction_results.append({\"image\": image, \"predictions\": predictions})\n\n            # compare object and class count of predictions if enabled,\n            # continue if not enough occurrences\n            if not count_comparisons(\n                predictions,\n                conditionals[\"required_objects_count\"],\n                conditionals[\"required_class_count\"],\n                conditionals[\"target_classes\"],\n            ):\n                print(\" [X] image failed count cases\")\n                continue\n\n            # iterate through all predictions\n            for i, prediction in enumerate(predictions):\n                print(i)\n\n                # check if box size of detection fits requirements\n                if not check_box_size(\n                    prediction,\n                    conditionals[\"minimum_size_requirement\"],\n                    conditionals[\"maximum_size_requirement\"],\n                ):\n                    print(\" [X] prediction failed box size cases\")\n                    continue\n\n                # compare confidence of detected object to confidence thresholds\n                # confidence comes in as a .XXX instead of XXX%\n                if (\n                    prediction[\"confidence\"] * 100 &gt;= conditionals[\"confidence_interval\"][0]\n                    and prediction[\"confidence\"] * 100 &lt;= conditionals[\"confidence_interval\"][1]\n                ):\n                    # filter out non-target_class uploads if enabled\n                    if (\n                        len(conditionals[\"target_classes\"]) &gt; 0\n                        and prediction[\"class\"] not in conditionals[\"target_classes\"]\n                    ):\n                        print(\" [X] prediction failed target_classes\")\n                        continue\n\n                    # upload on success!\n                    print(\" &gt;&gt; image uploaded!\")\n                    upload_project.upload(image, num_retry_uploads=3)\n                    break\n\n        # return predictions with filenames if globbed images from dir,\n        # otherwise return latest prediction result\n        return (\n            prediction_results if type(raw_data_location) is not np.ndarray else prediction_results[-1][\"predictions\"]\n        )\n\n    def deploy_model(\n        self,\n        model_type: str,\n        model_path: str,\n        project_ids: list[str],\n        model_name: str,\n        filename: str = \"weights/best.pt\",\n    ):\n        \"\"\"Uploads provided weights file to Roboflow.\n        Args:\n            model_type (str): The type of the model to be deployed.\n            model_path (str): File path to the model weights to be uploaded.\n            project_ids (list[str]): List of project IDs to deploy the model to.\n            filename (str, optional): The name of the weights file. Defaults to \"weights/best.pt\".\n        \"\"\"\n\n        if not project_ids:\n            raise ValueError(\"At least one project ID must be provided\")\n\n        # Validate if provided project URLs belong to user's projects\n        user_projects = set(project.split(\"/\")[-1] for project in self.projects())\n        for project_id in project_ids:\n            if project_id not in user_projects:\n                raise ValueError(f\"Project {project_id} is not accessible in this workspace\")\n\n        model_type = normalize_yolo_model_type(model_type)\n        zip_file_name = process(model_type, model_path, filename)\n\n        if zip_file_name is None:\n            raise RuntimeError(\"Failed to process model\")\n\n        self._upload_zip(model_type, model_path, project_ids, model_name, zip_file_name)\n\n    def _upload_zip(\n        self,\n        model_type: str,\n        model_path: str,\n        project_ids: list[str],\n        model_name: str,\n        model_file_name: str,\n    ):\n        # This endpoint returns a signed URL to upload the model\n        res = requests.post(\n            f\"{API_URL}/{self.url}/models/prepareUpload?api_key={self.__api_key}&amp;modelType={model_type}&amp;modelName={model_name}&amp;projectIds={','.join(project_ids)}&amp;nocache=true\"\n        )\n        try:\n            res.raise_for_status()\n        except Exception as e:\n            error_message = str(e)\n            status_code = str(res.status_code)\n\n            print(\"\\n\\033[91m\u274c ERROR\\033[0m: Failed to get model deployment URL\")\n            print(\"\\033[93mDetails\\033[0m:\", error_message)\n            print(\"\\033[93mStatus\\033[0m:\", status_code)\n            print(f\"\\033[93mResponse\\033[0m:\\n{res.text}\\n\")\n            return\n\n        # Upload the model to the signed URL\n        res = requests.put(\n            res.json()[\"url\"],\n            data=open(os.path.join(model_path, model_file_name), \"rb\"),\n        )\n        try:\n            res.raise_for_status()\n\n            for project_id in project_ids:\n                print(\n                    f\"View the status of your deployment for project {project_id} at:\"\n                    f\" {APP_URL}/{self.url}/{project_id}/models\"\n                )\n\n        except Exception as e:\n            print(f\"An error occured when uploading the model: {e}\")\n\n    def __str__(self):\n        projects = self.projects()\n        json_value = {\"name\": self.name, \"url\": self.url, \"projects\": projects}\n\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.active_learning","title":"<code>active_learning(raw_data_location='', raw_data_extension='', inference_endpoint=None, upload_destination='', conditionals=None, use_localhost=False, local_server='http://localhost:9001/')</code>","text":"<p>perform inference on each image in directory and upload based on conditions @params:     raw_data_location: (str) = folder of frames to be processed     raw_data_extension: (str) = extension of frames to be processed     inference_endpoint: (List[str, int]) = name of the project     upload_destination: (str) = name of the upload project     conditionals: (dict) = dictionary of upload conditions     use_localhost: (bool) = determines if local http format used or remote endpoint     local_server: (str) = local http address for inference server, use_localhost must be True for this to be used</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def active_learning(\n    self,\n    raw_data_location: str = \"\",\n    raw_data_extension: str = \"\",\n    inference_endpoint: Optional[List[str]] = None,\n    upload_destination: str = \"\",\n    conditionals: Optional[Dict] = None,\n    use_localhost: bool = False,\n    local_server=\"http://localhost:9001/\",\n) -&gt; Any:\n    \"\"\"perform inference on each image in directory and upload based on conditions\n    @params:\n        raw_data_location: (str) = folder of frames to be processed\n        raw_data_extension: (str) = extension of frames to be processed\n        inference_endpoint: (List[str, int]) = name of the project\n        upload_destination: (str) = name of the upload project\n        conditionals: (dict) = dictionary of upload conditions\n        use_localhost: (bool) = determines if local http format used or remote endpoint\n        local_server: (str) = local http address for inference server, use_localhost must be True for this to be used\n    \"\"\"  # noqa: E501 // docs\n    if inference_endpoint is None:\n        inference_endpoint = []\n    if conditionals is None:\n        conditionals = {}\n\n    import numpy as np\n\n    prediction_results = []\n\n    # ensure that all fields of conditionals have a key:value pair\n    conditionals[\"target_classes\"] = [] if \"target_classes\" not in conditionals else conditionals[\"target_classes\"]\n    conditionals[\"confidence_interval\"] = (\n        [30, 99] if \"confidence_interval\" not in conditionals else conditionals[\"confidence_interval\"]\n    )\n    conditionals[\"required_class_variance_count\"] = (\n        1 if \"required_class_variance_count\" not in conditionals else conditionals[\"required_class_variance_count\"]\n    )\n    conditionals[\"required_objects_count\"] = (\n        1 if \"required_objects_count\" not in conditionals else conditionals[\"required_objects_count\"]\n    )\n    conditionals[\"required_class_count\"] = (\n        0 if \"required_class_count\" not in conditionals else conditionals[\"required_class_count\"]\n    )\n    conditionals[\"minimum_size_requirement\"] = (\n        float(\"-inf\")\n        if \"minimum_size_requirement\" not in conditionals\n        else conditionals[\"minimum_size_requirement\"]\n    )\n    conditionals[\"maximum_size_requirement\"] = (\n        float(\"inf\") if \"maximum_size_requirement\" not in conditionals else conditionals[\"maximum_size_requirement\"]\n    )\n\n    # check if inference_model references endpoint or local\n    if use_localhost:\n        local = local_server\n    else:\n        local = None\n\n    inference_model = (\n        self.project(inference_endpoint[0]).version(version_number=inference_endpoint[1], local=local).model\n    )\n    upload_project = self.project(upload_destination)\n\n    print(\"inference reference point: \", inference_model)\n    print(\"upload destination: \", upload_project)\n\n    # check if raw data type is cv2 frame\n    if issubclass(type(raw_data_location), np.ndarray):\n        globbed_files = [raw_data_location]\n    else:\n        globbed_files = glob.glob(raw_data_location + \"/*\" + raw_data_extension)\n\n    image1 = globbed_files[0]\n    similarity_timeout_counter = 0\n\n    for index, image in enumerate(globbed_files):\n        try:\n            print(\n                \"*** Processing image [\" + str(index + 1) + \"/\" + str(len(globbed_files)) + \"] - \" + image + \" ***\"\n            )\n        except Exception:\n            pass\n\n        if \"similarity_confidence_threshold\" in conditionals.keys():\n            image2 = image\n            # measure the similarity of two images using CLIP (hits an endpoint hosted by Roboflow)   # noqa: E501 // docs\n            similarity = clip_encode(image1, image2, CLIP_FEATURIZE_URL)\n            similarity_timeout_counter += 1\n\n            if (\n                similarity &lt;= conditionals[\"similarity_confidence_threshold\"]\n                or similarity_timeout_counter == conditionals[\"similarity_timeout_limit\"]\n            ):\n                image1 = image\n                similarity_timeout_counter = 0\n            else:\n                print(image2 + \" --&gt; similarity too high to --&gt; \" + image1)\n                continue  # skip this image if too similar or counter hits limit\n\n        predictions = inference_model.predict(image).json()[\"predictions\"]  # type: ignore[attribute-error]\n        # collect all predictions to return to user at end\n        prediction_results.append({\"image\": image, \"predictions\": predictions})\n\n        # compare object and class count of predictions if enabled,\n        # continue if not enough occurrences\n        if not count_comparisons(\n            predictions,\n            conditionals[\"required_objects_count\"],\n            conditionals[\"required_class_count\"],\n            conditionals[\"target_classes\"],\n        ):\n            print(\" [X] image failed count cases\")\n            continue\n\n        # iterate through all predictions\n        for i, prediction in enumerate(predictions):\n            print(i)\n\n            # check if box size of detection fits requirements\n            if not check_box_size(\n                prediction,\n                conditionals[\"minimum_size_requirement\"],\n                conditionals[\"maximum_size_requirement\"],\n            ):\n                print(\" [X] prediction failed box size cases\")\n                continue\n\n            # compare confidence of detected object to confidence thresholds\n            # confidence comes in as a .XXX instead of XXX%\n            if (\n                prediction[\"confidence\"] * 100 &gt;= conditionals[\"confidence_interval\"][0]\n                and prediction[\"confidence\"] * 100 &lt;= conditionals[\"confidence_interval\"][1]\n            ):\n                # filter out non-target_class uploads if enabled\n                if (\n                    len(conditionals[\"target_classes\"]) &gt; 0\n                    and prediction[\"class\"] not in conditionals[\"target_classes\"]\n                ):\n                    print(\" [X] prediction failed target_classes\")\n                    continue\n\n                # upload on success!\n                print(\" &gt;&gt; image uploaded!\")\n                upload_project.upload(image, num_retry_uploads=3)\n                break\n\n    # return predictions with filenames if globbed images from dir,\n    # otherwise return latest prediction result\n    return (\n        prediction_results if type(raw_data_location) is not np.ndarray else prediction_results[-1][\"predictions\"]\n    )\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.clip_compare","title":"<code>clip_compare(dir='', image_ext='.png', target_image='')</code>","text":"<p>Compare all images in a directory to a target image using CLIP</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>name reference to a directory of images for comparison</p> <code>''</code> <code>image_ext</code> <code>str</code> <p>file format for expected images (don't include the . before the file type name)</p> <code>'.png'</code> <code>target_image</code> <code>str</code> <p>name reference for target image to compare individual images from directory against</p> <code>''</code> <p>Returns:</p> Name Type Description <code>List[dict]</code> <code>dict</code> <code>List[dict]</code> <p>a key:value mapping of image_name:comparison_score_to_target</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def clip_compare(self, dir: str = \"\", image_ext: str = \".png\", target_image: str = \"\") -&gt; List[dict]:\n    \"\"\"\n    Compare all images in a directory to a target image using CLIP\n\n    Args:\n        dir (str): name reference to a directory of images for comparison\n        image_ext (str): file format for expected images (don't include the . before the file type name)\n        target_image (str): name reference for target image to compare individual images from directory against\n\n    Returns:\n        # TODO: fix docs\n        dict: a key:value mapping of image_name:comparison_score_to_target\n    \"\"\"  # noqa: E501 // docs\n\n    # list to store comparison results in\n    comparisons = []\n    # grab all images in a given directory with ext type\n    for image in glob.glob(f\"./{dir}/*{image_ext}\"):\n        # compare image\n        similarity = clip_encode(image, target_image, CLIP_FEATURIZE_URL)\n        # map image name to similarity score\n        comparisons.append({image: similarity})\n        comparisons = sorted(comparisons, key=lambda item: -list(item.values())[0])\n    return comparisons\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.clip_compare--todo-fix-docs","title":"TODO: fix docs","text":""},{"location":"core/workspace/#roboflow.core.workspace.Workspace.create_project","title":"<code>create_project(project_name, project_type, project_license, annotation)</code>","text":"<p>Create a project in a Roboflow workspace.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>name of the project</p> required <code>project_type</code> <code>str</code> <p>type of the project</p> required <code>project_license</code> <code>str</code> <p>license of the project (set to <code>private</code> for private projects, only available for paid customers)</p> required <code>annotation</code> <code>str</code> <p>annotation of the project</p> required <p>Returns:</p> Type Description <p>Project Object</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def create_project(self, project_name, project_type, project_license, annotation):\n    \"\"\"\n    Create a project in a Roboflow workspace.\n\n    Args:\n        project_name (str): name of the project\n        project_type (str): type of the project\n        project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n        annotation (str): annotation of the project\n\n    Returns:\n        Project Object\n    \"\"\"  # noqa: E501 // docs\n    data = {\n        \"name\": project_name,\n        \"type\": project_type,\n        \"license\": project_license,\n        \"annotation\": annotation,\n    }\n\n    r = requests.post(API_URL + \"/\" + self.url + \"/projects?api_key=\" + self.__api_key, json=data)\n\n    r.raise_for_status()\n\n    if \"error\" in r.json().keys():\n        raise RuntimeError(r.json()[\"error\"])\n\n    return self.project(r.json()[\"id\"].split(\"/\")[-1])\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.deploy_model","title":"<code>deploy_model(model_type, model_path, project_ids, model_name, filename='weights/best.pt')</code>","text":"<p>Uploads provided weights file to Roboflow. Args:     model_type (str): The type of the model to be deployed.     model_path (str): File path to the model weights to be uploaded.     project_ids (list[str]): List of project IDs to deploy the model to.     filename (str, optional): The name of the weights file. Defaults to \"weights/best.pt\".</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def deploy_model(\n    self,\n    model_type: str,\n    model_path: str,\n    project_ids: list[str],\n    model_name: str,\n    filename: str = \"weights/best.pt\",\n):\n    \"\"\"Uploads provided weights file to Roboflow.\n    Args:\n        model_type (str): The type of the model to be deployed.\n        model_path (str): File path to the model weights to be uploaded.\n        project_ids (list[str]): List of project IDs to deploy the model to.\n        filename (str, optional): The name of the weights file. Defaults to \"weights/best.pt\".\n    \"\"\"\n\n    if not project_ids:\n        raise ValueError(\"At least one project ID must be provided\")\n\n    # Validate if provided project URLs belong to user's projects\n    user_projects = set(project.split(\"/\")[-1] for project in self.projects())\n    for project_id in project_ids:\n        if project_id not in user_projects:\n            raise ValueError(f\"Project {project_id} is not accessible in this workspace\")\n\n    model_type = normalize_yolo_model_type(model_type)\n    zip_file_name = process(model_type, model_path, filename)\n\n    if zip_file_name is None:\n        raise RuntimeError(\"Failed to process model\")\n\n    self._upload_zip(model_type, model_path, project_ids, model_name, zip_file_name)\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.list_projects","title":"<code>list_projects()</code>","text":"<p>Print all projects in the workspace to the console.</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def list_projects(self):\n    \"\"\"\n    Print all projects in the workspace to the console.\n    \"\"\"\n    print(self.project_list)\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.project","title":"<code>project(project_id)</code>","text":"<p>Retrieve a Project() object that represents a project in the workspace.</p> <p>This object can be used to retrieve the model through which to run inference.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str</code> <p>id of the project</p> required <p>Returns:</p> Type Description <p>Project Object</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def project(self, project_id):\n    \"\"\"\n    Retrieve a Project() object that represents a project in the workspace.\n\n    This object can be used to retrieve the model through which to run inference.\n\n    Args:\n        project_id (str): id of the project\n\n    Returns:\n        Project Object\n    \"\"\"\n    sys.stdout.write(\"\\r\" + \"loading Roboflow project...\")\n    sys.stdout.write(\"\\n\")\n    sys.stdout.flush()\n\n    if self.__api_key in DEMO_KEYS:\n        return Project(self.__api_key, {}, self.model_format)\n\n    # project_id = project_id.replace(self.url + \"/\", \"\")\n\n    if \"/\" in project_id:\n        raise RuntimeError(f\"The {project_id} project is not available in this ({self.url}) workspace\")\n\n    dataset_info = rfapi.get_project(self.__api_key, self.url, project_id)\n    dataset_info = dataset_info[\"project\"]\n\n    return Project(self.__api_key, dataset_info, self.model_format)\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.projects","title":"<code>projects()</code>","text":"<p>Retrieve all projects in the workspace.</p> <p>Returns:</p> Type Description <p>List of Project objects.</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def projects(self):\n    \"\"\"\n    Retrieve all projects in the workspace.\n\n    Returns:\n        List of Project objects.\n    \"\"\"\n    projects_array = []\n    for a_project in self.project_list:\n        proj = Project(self.__api_key, a_project, self.model_format)\n        projects_array.append(proj.id)\n\n    return projects_array\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.two_stage","title":"<code>two_stage(image='', first_stage_model_name='', first_stage_model_version=0, second_stage_model_name='', second_stage_model_version=0)</code>","text":"<p>For each prediction in a first stage detection, perform detection with the second stage model</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>name of the image to be processed</p> <code>''</code> <code>first_stage_model_name</code> <code>str</code> <p>name of the first stage detection model</p> <code>''</code> <code>first_stage_model_version</code> <code>int</code> <p>version number for the first stage model</p> <code>0</code> <code>second_stage_mode</code> <code>str</code> <p>name of the second stage detection model</p> required <code>second_stage_model_version</code> <code>int</code> <p>version number for the second stage model</p> <code>0</code> <p>Returns:</p> Name Type Description <code>List[dict]</code> <code>dict</code> <code>List[dict]</code> <p>a json obj containing the results of the second stage detection</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def two_stage(\n    self,\n    image: str = \"\",\n    first_stage_model_name: str = \"\",\n    first_stage_model_version: int = 0,\n    second_stage_model_name: str = \"\",\n    second_stage_model_version: int = 0,\n) -&gt; List[dict]:\n    \"\"\"\n    For each prediction in a first stage detection, perform detection with the second stage model\n\n    Args:\n        image (str): name of the image to be processed\n        first_stage_model_name (str): name of the first stage detection model\n        first_stage_model_version (int): version number for the first stage model\n        second_stage_mode (str): name of the second stage detection model\n        second_stage_model_version (int): version number for the second stage model\n\n    Returns:\n        # TODO: fix docs\n        dict: a json obj containing the results of the second stage detection\n    \"\"\"  # noqa: E501 // docs\n    results = []\n\n    # create PIL image for cropping\n    pil_image = Image.open(image).convert(\"RGB\")\n\n    # grab first and second stage model from project\n    stage_one_project = self.project(first_stage_model_name)\n    stage_one_model = stage_one_project.version(first_stage_model_version).model\n    stage_two_project = self.project(second_stage_model_name)\n    stage_two_model = stage_two_project.version(second_stage_model_version).model\n\n    print(self.project(first_stage_model_name))\n\n    # perform first inference\n    predictions = stage_one_model.predict(image)  # type: ignore[attribute-error]\n\n    if stage_one_project.type == \"object-detection\" and stage_two_project == \"classification\":\n        # interact with each detected object from stage one inference results\n        for boundingbox in predictions:\n            # rip bounding box coordinates from json1\n            # note: infer returns center points of box as (x,y) and width, height\n            # ----- but pillow crop requires the top left and bottom right points to crop  # noqa: E501 // docs\n            box = (\n                boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n            )\n\n            # create a new cropped image using the first stage prediction coordinates (for each box!)  # noqa: E501 // docs\n            croppedImg = pil_image.crop(box)\n            croppedImg.save(\"./temp.png\")\n\n            # capture results of second stage inference from cropped image\n            results.append(stage_two_model.predict(\"./temp.png\")[0])  # type: ignore[attribute-error]\n\n        # delete the written image artifact\n        try:\n            os.remove(\"./temp.png\")\n        except FileNotFoundError:\n            print(\"no detections\")\n\n    else:\n        print(\n            \"please use an object detection model for the first stage--can only\"\n            \" perform two stage with bounding box results\",\n            \"please use a classification model for the second stage\",\n        )\n\n    return results\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.two_stage--todo-fix-docs","title":"TODO: fix docs","text":""},{"location":"core/workspace/#roboflow.core.workspace.Workspace.two_stage_ocr","title":"<code>two_stage_ocr(image='', first_stage_model_name='', first_stage_model_version=0)</code>","text":"<p>For each prediction in the first stage object detection, perform OCR as second stage.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>name of the image to be processed</p> <code>''</code> <code>first_stage_model_name</code> <code>str</code> <p>name of the first stage detection model</p> <code>''</code> <code>first_stage_model_version</code> <code>int</code> <p>version number for the first stage model</p> <code>0</code> <p>Returns:</p> Name Type Description <code>List[dict]</code> <code>dict</code> <code>List[dict]</code> <p>a json obj containing the results of the second stage detection</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def two_stage_ocr(\n    self,\n    image: str = \"\",\n    first_stage_model_name: str = \"\",\n    first_stage_model_version: int = 0,\n) -&gt; List[dict]:\n    \"\"\"\n    For each prediction in the first stage object detection, perform OCR as second stage.\n\n    Args:\n        image (str): name of the image to be processed\n        first_stage_model_name (str): name of the first stage detection model\n        first_stage_model_version (int): version number for the first stage model\n\n    Returns:\n        # TODO: fix docs\n        dict: a json obj containing the results of the second stage detection\n    \"\"\"  # noqa: E501 // docs\n    results = []\n\n    # create PIL image for cropping\n    pil_image = Image.open(image).convert(\"RGB\")\n\n    # grab first and second stage model from project\n    stage_one_project = self.project(first_stage_model_name)\n    stage_one_model = stage_one_project.version(first_stage_model_version).model\n\n    # perform first inference\n    predictions = stage_one_model.predict(image)  # type: ignore[attribute-error]\n\n    # interact with each detected object from stage one inference results\n    if stage_one_project.type == \"object-detection\":\n        for boundingbox in predictions:\n            # rip bounding box coordinates from json1\n            # note: infer returns center points of box as (x,y) and width, height\n            # but pillow crop requires the top left and bottom right points to crop\n            box = (\n                boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n            )\n\n            # create a new cropped image using the first stage\n            # prediction coordinates (for each box!)\n            croppedImg = pil_image.crop(box)\n\n            # capture OCR results from cropped image\n            results.append(ocr_infer(croppedImg)[\"results\"])\n    else:\n        print(\"please use an object detection model--can only perform two stage with bounding box results\")\n\n    return results\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.two_stage_ocr--todo-fix-docs","title":"TODO: fix docs","text":""},{"location":"core/workspace/#roboflow.core.workspace.Workspace.upload_dataset","title":"<code>upload_dataset(dataset_path, project_name, num_workers=10, dataset_format='NOT_USED', project_license='MIT', project_type='object-detection', batch_name=None, num_retries=0)</code>","text":"<p>Upload a dataset to Roboflow.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>path to the dataset</p> required <code>project_name</code> <code>str</code> <p>name of the project</p> required <code>num_workers</code> <code>int</code> <p>number of workers to use for parallel uploads</p> <code>10</code> <code>dataset_format</code> <code>str</code> <p>format of the dataset (<code>voc</code>, <code>yolov8</code>, <code>yolov5</code>)</p> <code>'NOT_USED'</code> <code>project_license</code> <code>str</code> <p>license of the project (set to <code>private</code> for private projects, only available for paid customers)</p> <code>'MIT'</code> <code>project_type</code> <code>str</code> <p>type of the project (only <code>object-detection</code> is supported)</p> <code>'object-detection'</code> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def upload_dataset(\n    self,\n    dataset_path: str,\n    project_name: str,\n    num_workers: int = 10,\n    dataset_format: str = \"NOT_USED\",  # deprecated. keep for backward compatibility\n    project_license: str = \"MIT\",\n    project_type: str = \"object-detection\",\n    batch_name=None,\n    num_retries=0,\n):\n    \"\"\"\n    Upload a dataset to Roboflow.\n\n    Args:\n        dataset_path (str): path to the dataset\n        project_name (str): name of the project\n        num_workers (int): number of workers to use for parallel uploads\n        dataset_format (str): format of the dataset (`voc`, `yolov8`, `yolov5`)\n        project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n        project_type (str): type of the project (only `object-detection` is supported)\n    \"\"\"  # noqa: E501 // docs\n    if dataset_format != \"NOT_USED\":\n        print(\"Warning: parameter 'dataset_format' is deprecated and will be removed in a future release\")\n    project, created = self._get_or_create_project(\n        project_id=project_name, license=project_license, type=project_type\n    )\n    is_classification = project.type == \"classification\"\n    parsed_dataset = folderparser.parsefolder(dataset_path, is_classification=is_classification)\n    if created:\n        print(f\"Created project {project.id}\")\n    else:\n        print(f\"Uploading to existing project {project.id}\")\n    images = parsed_dataset[\"images\"]\n\n    location = parsed_dataset[\"location\"]\n\n    def _log_img_upload(\n        image_path, image, annotation, image_upload_time, image_upload_retry_attempts, annotation_time\n    ):\n        image_id = image.get(\"id\")\n        img_success = image.get(\"success\")\n        img_duplicate = image.get(\"duplicate\")\n\n        upload_time_str = f\"[{image_upload_time:.1f}s]\"\n        annotation_time_str = f\"[{annotation_time:.1f}s]\" if annotation_time else \"\"\n        retry_attempts = f\" (with {image_upload_retry_attempts} retries)\" if image_upload_retry_attempts &gt; 0 else \"\"\n\n        if img_duplicate:\n            msg = f\"[DUPLICATE]{retry_attempts} {image_path} ({image_id}) {upload_time_str}\"\n        elif img_success:\n            msg = f\"[UPLOADED]{retry_attempts} {image_path} ({image_id}) {upload_time_str}\"\n        else:\n            msg = f\"[LOG ERROR]: Unrecognized image upload status ({image_id=})\"\n        if annotation:\n            if annotation.get(\"success\"):\n                msg += f\" / annotations = OK {annotation_time_str}\"\n            elif annotation.get(\"warn\"):\n                msg += f\" / annotations = WARN: {annotation['warn']} {annotation_time_str}\"\n            else:\n                msg += \" / annotations = ERR: Unrecognized annotation upload status\"\n\n        print(msg)\n\n    def _upload_image(imagedesc):\n        image_path = f\"{location}{imagedesc['file']}\"\n        split = imagedesc[\"split\"]\n\n        image, upload_time, upload_retry_attempts = project.upload_image(\n            image_path=image_path,\n            split=split,\n            batch_name=batch_name,\n            sequence_number=imagedesc.get(\"index\"),\n            sequence_size=len(images),\n            num_retry_uploads=num_retries,\n        )\n\n        return image, upload_time, upload_retry_attempts\n\n    def _save_annotation(image_id, imagedesc):\n        labelmap = None\n        annotation_path = None\n\n        annotationdesc = imagedesc.get(\"annotationfile\")\n        if isinstance(annotationdesc, dict):\n            if annotationdesc.get(\"type\") == \"classification_folder\":\n                annotation_path = annotationdesc.get(\"classification_label\")\n            elif annotationdesc.get(\"type\") == \"classification_multilabel\":\n                annotation_path = json.dumps(annotationdesc.get(\"labels\", []))\n            elif annotationdesc.get(\"rawText\"):\n                annotation_path = annotationdesc\n            elif annotationdesc.get(\"file\"):\n                annotation_path = f\"{location}{annotationdesc['file']}\"\n                labelmap = annotationdesc.get(\"labelmap\")\n\n            if isinstance(labelmap, str):\n                labelmap = load_labelmap(labelmap)\n\n        # If annotation_path is still None at this point, then no annotation will be saved.\n        if annotation_path is None:\n            return None, None\n\n        annotation, upload_time, _retry_attempts = project.save_annotation(\n            annotation_path=annotation_path,\n            annotation_labelmap=labelmap,\n            image_id=image_id,\n            job_name=batch_name,\n            num_retry_uploads=num_retries,\n        )\n\n        return annotation, upload_time\n\n    def _upload(imagedesc):\n        image_path = f\"{location}{imagedesc['file']}\"\n\n        image_id = None\n        image_upload_time = None\n        image_retry_attempts = None\n\n        try:\n            image, image_upload_time, image_retry_attempts = _upload_image(imagedesc)\n            image_id = image[\"id\"]\n            annotation, annotation_time = _save_annotation(image_id, imagedesc)\n            _log_img_upload(image_path, image, annotation, image_upload_time, image_retry_attempts, annotation_time)\n        except ImageUploadError as e:\n            retry_attempts = f\" (with {e.retries} retries)\" if e.retries &gt; 0 else \"\"\n            print(f\"[ERR]{retry_attempts} {image_path} ({e.message})\")\n        except AnnotationSaveError as e:\n            upload_time_str = f\"[{image_upload_time:.1f}s]\"\n            retry_attempts = f\" (with {image_retry_attempts} retries)\" if image_retry_attempts &gt; 0 else \"\"\n            image_msg = f\"[UPLOADED]{retry_attempts} {image_path} ({image_id}) {upload_time_str}\"\n            annotation_msg = f\"annotations = ERR: {e.message}\"\n            print(f\"{image_msg} / {annotation_msg}\")\n        except Exception as e:\n            print(f\"[ERR] {image_path} ({e})\")\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n        list(executor.map(_upload, images))\n</code></pre>"},{"location":"models/classification/","title":"Classification","text":""},{"location":"models/classification/#roboflow.models.classification.ClassificationModel","title":"<code>ClassificationModel</code>","text":"<p>               Bases: <code>InferenceModel</code></p> <p>Run inference on a classification model hosted on Roboflow or served through     Roboflow Inference.</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>class ClassificationModel(InferenceModel):\n    \"\"\"\n    Run inference on a classification model hosted on Roboflow or served through\n        Roboflow Inference.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        id: str,\n        name: Optional[str] = None,\n        version: Optional[str] = None,\n        local: Optional[str] = None,\n        colors: Optional[dict] = None,\n        preprocessing: Optional[dict] = None,\n    ):\n        \"\"\"\n        Create a ClassificationModel object through which you can run inference.\n\n        Args:\n            api_key (str): private roboflow api key\n            id (str): the workspace/project id\n            name (str): is the name of the project\n            version (str): version number\n            local (str): localhost address and port if pointing towards local inference engine\n            colors (dict): colors to use for the image\n            preprocessing (dict): preprocessing to use for the image\n\n        Returns:\n            ClassificationModel Object\n        \"\"\"\n        # Instantiate different API URL parameters\n        super().__init__(api_key, id, version=version)\n        self.__api_key = api_key\n        self.id = id\n        self.name = name\n        self.version = version\n        self.base_url = \"https://classify.roboflow.com/\"\n\n        if self.name is not None and version is not None:\n            self.__generate_url()\n\n        self.colors = {} if colors is None else colors\n        self.preprocessing = {} if preprocessing is None else preprocessing\n\n        if local:\n            print(f\"initalizing local classification model hosted at : {local}\")\n            self.base_url = local\n\n    def predict(self, image_path, hosted=False):  # type: ignore[override]\n        \"\"\"\n        Run inference on an image.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            hosted (bool): whether the image you're providing is hosted on Roboflow\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"\n        self.__generate_url()\n        self.__exception_check(image_path_check=image_path)\n        # If image is local image\n        if not hosted:\n            # Open Image in RGB Format\n            image = Image.open(image_path).convert(\"RGB\")\n            # Create buffer\n            buffered = io.BytesIO()\n            image.save(buffered, quality=90, format=\"JPEG\")\n            img_dims = image.size\n            # Base64 encode image\n            img_str = base64.b64encode(buffered.getvalue())\n            img_str = img_str.decode(\"ascii\")\n            # Post to API and return response\n            resp = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n        else:\n            # Create API URL for hosted image (slightly different)\n            self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n            # POST to the API\n            resp = requests.post(self.api_url)\n            img_dims = {\"width\": \"0\", \"height\": \"0\"}\n\n        if resp.status_code != 200:\n            raise Exception(resp.text)\n\n        return PredictionGroup.create_prediction_group(\n            resp.json(),\n            image_dims=img_dims,\n            image_path=image_path,\n            prediction_type=CLASSIFICATION_MODEL,\n            colors=self.colors,\n        )\n\n    def load_model(self, name, version):\n        \"\"\"\n        Load a model.\n\n        Args:\n            name (str): is the name of the model you'd like to load\n            version (int): version number\n        \"\"\"\n        # Load model based on user defined characteristics\n        self.name = name\n        self.version = version\n        self.__generate_url()\n\n    def __generate_url(self):\n        \"\"\"\n        Generate a Roboflow API URL on which to run inference.\n\n        Returns:\n            url (str): the url on which to run inference\n        \"\"\"\n\n        # Generates URL based on all parameters\n        splitted = self.id.rsplit(\"/\")\n        without_workspace = splitted[1]\n        version = self.version\n        if not version and len(splitted) &gt; 2:\n            version = splitted[2]\n\n        self.api_url = \"\".join(\n            [\n                self.base_url + without_workspace + \"/\" + str(version),\n                \"?api_key=\" + self.__api_key,\n                \"&amp;name=YOUR_IMAGE.jpg\",\n            ]\n        )\n\n    def __exception_check(self, image_path_check=None):\n        \"\"\"\n        Check to see if an image exists.\n\n        Args:\n            image_path_check (str): path to the image to check\n\n        Raises:\n            Exception: if image does not exist\n        \"\"\"\n        # Checks if image exists\n        if image_path_check is not None:\n            if not os.path.exists(image_path_check) and not check_image_url(image_path_check):\n                raise Exception(\"Image does not exist at \" + image_path_check + \"!\")\n\n    def __str__(self):\n        \"\"\"\n        String representation of classification object\n        \"\"\"\n        json_value = {\n            \"name\": self.name,\n            \"version\": self.version,\n            \"base_url\": self.base_url,\n        }\n\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__exception_check","title":"<code>__exception_check(image_path_check=None)</code>","text":"<p>Check to see if an image exists.</p> <p>Parameters:</p> Name Type Description Default <code>image_path_check</code> <code>str</code> <p>path to the image to check</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>if image does not exist</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __exception_check(self, image_path_check=None):\n    \"\"\"\n    Check to see if an image exists.\n\n    Args:\n        image_path_check (str): path to the image to check\n\n    Raises:\n        Exception: if image does not exist\n    \"\"\"\n    # Checks if image exists\n    if image_path_check is not None:\n        if not os.path.exists(image_path_check) and not check_image_url(image_path_check):\n            raise Exception(\"Image does not exist at \" + image_path_check + \"!\")\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__generate_url","title":"<code>__generate_url()</code>","text":"<p>Generate a Roboflow API URL on which to run inference.</p> <p>Returns:</p> Name Type Description <code>url</code> <code>str</code> <p>the url on which to run inference</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __generate_url(self):\n    \"\"\"\n    Generate a Roboflow API URL on which to run inference.\n\n    Returns:\n        url (str): the url on which to run inference\n    \"\"\"\n\n    # Generates URL based on all parameters\n    splitted = self.id.rsplit(\"/\")\n    without_workspace = splitted[1]\n    version = self.version\n    if not version and len(splitted) &gt; 2:\n        version = splitted[2]\n\n    self.api_url = \"\".join(\n        [\n            self.base_url + without_workspace + \"/\" + str(version),\n            \"?api_key=\" + self.__api_key,\n            \"&amp;name=YOUR_IMAGE.jpg\",\n        ]\n    )\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__init__","title":"<code>__init__(api_key, id, name=None, version=None, local=None, colors=None, preprocessing=None)</code>","text":"<p>Create a ClassificationModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>id</code> <code>str</code> <p>the workspace/project id</p> required <code>name</code> <code>str</code> <p>is the name of the project</p> <code>None</code> <code>version</code> <code>str</code> <p>version number</p> <code>None</code> <code>local</code> <code>str</code> <p>localhost address and port if pointing towards local inference engine</p> <code>None</code> <code>colors</code> <code>dict</code> <p>colors to use for the image</p> <code>None</code> <code>preprocessing</code> <code>dict</code> <p>preprocessing to use for the image</p> <code>None</code> <p>Returns:</p> Type Description <p>ClassificationModel Object</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __init__(\n    self,\n    api_key: str,\n    id: str,\n    name: Optional[str] = None,\n    version: Optional[str] = None,\n    local: Optional[str] = None,\n    colors: Optional[dict] = None,\n    preprocessing: Optional[dict] = None,\n):\n    \"\"\"\n    Create a ClassificationModel object through which you can run inference.\n\n    Args:\n        api_key (str): private roboflow api key\n        id (str): the workspace/project id\n        name (str): is the name of the project\n        version (str): version number\n        local (str): localhost address and port if pointing towards local inference engine\n        colors (dict): colors to use for the image\n        preprocessing (dict): preprocessing to use for the image\n\n    Returns:\n        ClassificationModel Object\n    \"\"\"\n    # Instantiate different API URL parameters\n    super().__init__(api_key, id, version=version)\n    self.__api_key = api_key\n    self.id = id\n    self.name = name\n    self.version = version\n    self.base_url = \"https://classify.roboflow.com/\"\n\n    if self.name is not None and version is not None:\n        self.__generate_url()\n\n    self.colors = {} if colors is None else colors\n    self.preprocessing = {} if preprocessing is None else preprocessing\n\n    if local:\n        print(f\"initalizing local classification model hosted at : {local}\")\n        self.base_url = local\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation of classification object</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __str__(self):\n    \"\"\"\n    String representation of classification object\n    \"\"\"\n    json_value = {\n        \"name\": self.name,\n        \"version\": self.version,\n        \"base_url\": self.base_url,\n    }\n\n    return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.load_model","title":"<code>load_model(name, version)</code>","text":"<p>Load a model.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>is the name of the model you'd like to load</p> required <code>version</code> <code>int</code> <p>version number</p> required Source code in <code>roboflow/models/classification.py</code> <pre><code>def load_model(self, name, version):\n    \"\"\"\n    Load a model.\n\n    Args:\n        name (str): is the name of the model you'd like to load\n        version (int): version number\n    \"\"\"\n    # Load model based on user defined characteristics\n    self.name = name\n    self.version = version\n    self.__generate_url()\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.predict","title":"<code>predict(image_path, hosted=False)</code>","text":"<p>Run inference on an image.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>hosted</code> <code>bool</code> <p>whether the image you're providing is hosted on Roboflow</p> <code>False</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def predict(self, image_path, hosted=False):  # type: ignore[override]\n    \"\"\"\n    Run inference on an image.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        hosted (bool): whether the image you're providing is hosted on Roboflow\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"\n    self.__generate_url()\n    self.__exception_check(image_path_check=image_path)\n    # If image is local image\n    if not hosted:\n        # Open Image in RGB Format\n        image = Image.open(image_path).convert(\"RGB\")\n        # Create buffer\n        buffered = io.BytesIO()\n        image.save(buffered, quality=90, format=\"JPEG\")\n        img_dims = image.size\n        # Base64 encode image\n        img_str = base64.b64encode(buffered.getvalue())\n        img_str = img_str.decode(\"ascii\")\n        # Post to API and return response\n        resp = requests.post(\n            self.api_url,\n            data=img_str,\n            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n        )\n    else:\n        # Create API URL for hosted image (slightly different)\n        self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n        # POST to the API\n        resp = requests.post(self.api_url)\n        img_dims = {\"width\": \"0\", \"height\": \"0\"}\n\n    if resp.status_code != 200:\n        raise Exception(resp.text)\n\n    return PredictionGroup.create_prediction_group(\n        resp.json(),\n        image_dims=img_dims,\n        image_path=image_path,\n        prediction_type=CLASSIFICATION_MODEL,\n        colors=self.colors,\n    )\n</code></pre>"},{"location":"models/instance-segmentation/","title":"Instance Segmentation","text":""},{"location":"models/instance-segmentation/#roboflow.models.instance_segmentation.InstanceSegmentationModel","title":"<code>InstanceSegmentationModel</code>","text":"<p>               Bases: <code>InferenceModel</code></p> <p>Run inference on a instance segmentation model hosted on     Roboflow or served through Roboflow Inference.</p> Source code in <code>roboflow/models/instance_segmentation.py</code> <pre><code>class InstanceSegmentationModel(InferenceModel):\n    \"\"\"\n    Run inference on a instance segmentation model hosted on\n        Roboflow or served through Roboflow Inference.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        version_id: str,\n        colors: Optional[dict] = None,\n        preprocessing: Optional[dict] = None,\n        local: Optional[str] = None,\n    ):\n        \"\"\"\n        Create a InstanceSegmentationModel object through which you can run inference.\n\n        Args:\n            api_key (str): private roboflow api key\n            version_id (str): the workspace/project id\n            colors (dict): colors to use for the image\n            preprocessing (dict): preprocessing to use for the image\n            local (str): localhost address and port if pointing towards local inference engine\n        \"\"\"\n        super().__init__(api_key, version_id)\n\n        base_url = local or INSTANCE_SEGMENTATION_URL\n        self.api_url = f\"{base_url}/{self.dataset_id}/{self.version}\"\n        self.colors = {} if colors is None else colors\n        self.preprocessing = {} if preprocessing is None else preprocessing\n\n    def predict(self, image_path, confidence=40):  # type: ignore[override]\n        \"\"\"\n        Infers detections based on image from a specified model and image path.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"  # noqa: E501\n        return super().predict(\n            image_path,\n            confidence=confidence,\n            prediction_type=INSTANCE_SEGMENTATION_MODEL,\n        )\n\n    def __str__(self):\n        return f\"&lt;{type(self).__name__} id={self.id}, api_url={self.api_url}&gt;\"\n</code></pre>"},{"location":"models/instance-segmentation/#roboflow.models.instance_segmentation.InstanceSegmentationModel.__init__","title":"<code>__init__(api_key, version_id, colors=None, preprocessing=None, local=None)</code>","text":"<p>Create a InstanceSegmentationModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>version_id</code> <code>str</code> <p>the workspace/project id</p> required <code>colors</code> <code>dict</code> <p>colors to use for the image</p> <code>None</code> <code>preprocessing</code> <code>dict</code> <p>preprocessing to use for the image</p> <code>None</code> <code>local</code> <code>str</code> <p>localhost address and port if pointing towards local inference engine</p> <code>None</code> Source code in <code>roboflow/models/instance_segmentation.py</code> <pre><code>def __init__(\n    self,\n    api_key: str,\n    version_id: str,\n    colors: Optional[dict] = None,\n    preprocessing: Optional[dict] = None,\n    local: Optional[str] = None,\n):\n    \"\"\"\n    Create a InstanceSegmentationModel object through which you can run inference.\n\n    Args:\n        api_key (str): private roboflow api key\n        version_id (str): the workspace/project id\n        colors (dict): colors to use for the image\n        preprocessing (dict): preprocessing to use for the image\n        local (str): localhost address and port if pointing towards local inference engine\n    \"\"\"\n    super().__init__(api_key, version_id)\n\n    base_url = local or INSTANCE_SEGMENTATION_URL\n    self.api_url = f\"{base_url}/{self.dataset_id}/{self.version}\"\n    self.colors = {} if colors is None else colors\n    self.preprocessing = {} if preprocessing is None else preprocessing\n</code></pre>"},{"location":"models/instance-segmentation/#roboflow.models.instance_segmentation.InstanceSegmentationModel.predict","title":"<code>predict(image_path, confidence=40)</code>","text":"<p>Infers detections based on image from a specified model and image path.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>confidence</code> <code>int</code> <p>confidence threshold for predictions, on a scale from 0-100</p> <code>40</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/instance_segmentation.py</code> <pre><code>def predict(self, image_path, confidence=40):  # type: ignore[override]\n    \"\"\"\n    Infers detections based on image from a specified model and image path.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"  # noqa: E501\n    return super().predict(\n        image_path,\n        confidence=confidence,\n        prediction_type=INSTANCE_SEGMENTATION_MODEL,\n    )\n</code></pre>"},{"location":"models/object-detection/","title":"Object Detection","text":""},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel","title":"<code>ObjectDetectionModel</code>","text":"<p>               Bases: <code>InferenceModel</code></p> <p>Run inference on an object detection model hosted on Roboflow or served through Roboflow Inference.</p> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>class ObjectDetectionModel(InferenceModel):\n    \"\"\"\n    Run inference on an object detection model hosted on Roboflow or served through Roboflow Inference.\n    \"\"\"  # noqa: E501 // docs\n\n    def __init__(\n        self,\n        api_key,\n        id,\n        name=None,\n        version=None,\n        local=None,\n        classes=None,\n        overlap=30,\n        confidence=40,\n        stroke=1,\n        labels=False,\n        format=\"json\",\n        colors=None,\n        preprocessing=None,\n    ):\n        \"\"\"\n        Create a ObjectDetectionModel object through which you can run inference.\n\n        Args:\n            api_key (str): Your API key (obtained via your workspace API settings page).\n            name (str): The url-safe version of the dataset name. You can find it in the web UI by looking at\n                        the URL on the main project view or by clicking the \"Get curl command\" button in the train\n                        results section of your dataset version after training your model.\n            local (str): Address of the local server address if running a local Roboflow deployment server.\n                        Ex. http://localhost:9001/\n            version (str): The version number identifying the version of your dataset.\n            classes (str): Restrict the predictions to only those of certain classes. Provide as a comma-separated string.\n            overlap (int): The maximum percentage (on a scale of 0-100) that bounding box predictions of the same class are\n                        allowed to overlap before being combined into a single box.\n            confidence (int): A threshold for the returned predictions on a scale of 0-100. A lower number will return\n                            more predictions. A higher number will return fewer high-certainty predictions.\n            stroke (int): The width (in pixels) of the bounding box displayed around predictions (only has an effect when\n                        format is image).\n            labels (bool): Whether or not to display text labels on the predictions (only has an effect when format is\n                        image).\n            format (str): The format of the output.\n                        - 'json': returns an array of JSON predictions (See response format tab).\n                        - 'image': returns an image with annotated predictions as a binary blob with a Content-Type\n                                    of image/jpeg.\n        \"\"\"  # noqa: E501 // docs\n        # Instantiate different API URL parameters\n        # To be moved to predict\n        super().__init__(api_key, id)\n        self.__api_key = api_key\n        self.id = id\n        self.name = name\n        self.version = version or self.version\n        self.classes = classes\n        self.overlap = overlap\n        self.confidence = confidence\n        self.stroke = stroke\n        self.labels = labels\n        self.format = format\n        self.colors = {} if colors is None else colors\n        self.preprocessing = {} if preprocessing is None else preprocessing\n\n        # local needs to be passed from Project\n        if local is None:\n            self.base_url = OBJECT_DETECTION_URL + \"/\"\n        else:\n            print(\"initalizing local object detection model hosted at :\" + local)\n            self.base_url = local\n\n        # If dataset slug not none, instantiate API URL\n        if name is not None and version is not None:\n            self.__generate_url()\n\n    def load_model(\n        self,\n        name,\n        version,\n        local=None,\n        classes=None,\n        overlap=None,\n        confidence=None,\n        stroke=None,\n        labels=None,\n        format=None,\n    ):\n        \"\"\"\n        Loads a Model from on a model endpoint.\n\n        Args:\n            name (str): The url-safe version of the dataset name\n            version (str): The version number identifying the version of your dataset.\n            local (bool): Whether the model is hosted locally or on Roboflow\n        \"\"\"\n        # To load a model manually, they must specify a dataset slug\n        self.name = name\n        self.version = version\n        # Generate URL based on parameters\n        self.__generate_url(\n            local=local,\n            classes=classes,\n            overlap=overlap,\n            confidence=confidence,\n            stroke=stroke,\n            labels=labels,\n            format=format,\n        )\n\n    def predict(  # type: ignore[override]\n        self,\n        image_path,\n        hosted=False,\n        format=None,\n        classes=None,\n        overlap=30,\n        confidence=40,\n        stroke=1,\n        labels=False,\n    ):\n        \"\"\"\n        Infers detections based on image from specified model and image path.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            hosted (bool): whether the image you're providing is hosted on Roboflow\n            format (str): The format of the output.\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"\n        # Generate url before predicting\n        self.__generate_url(\n            format=format,\n            classes=classes,\n            overlap=overlap,\n            confidence=confidence,\n            stroke=stroke,\n            labels=labels,\n        )\n\n        # Check if image exists at specified path or URL or is an array\n        if hasattr(image_path, \"__len__\") is True:\n            pass\n        else:\n            self.__exception_check(image_path_check=image_path)\n\n        original_dimensions = None\n        should_resize = False\n        # If image is local image\n        if not hosted:\n            import cv2\n            import numpy as np\n\n            should_resize = (\n                \"resize\" in self.preprocessing.keys() and \"Stretch\" in self.preprocessing[\"resize\"][\"format\"]\n            )\n\n            if isinstance(image_path, str):\n                image = Image.open(image_path).convert(\"RGB\")\n                dimensions = image.size\n                original_dimensions = copy.deepcopy(dimensions)\n\n                # Here we resize the image to the preprocessing settings\n                # before sending it over the wire\n                if should_resize:\n                    if dimensions[0] &gt; int(self.preprocessing[\"resize\"][\"width\"]) or dimensions[1] &gt; int(\n                        self.preprocessing[\"resize\"][\"height\"]\n                    ):\n                        image = image.resize(\n                            (\n                                int(self.preprocessing[\"resize\"][\"width\"]),\n                                int(self.preprocessing[\"resize\"][\"height\"]),\n                            )\n                        )\n                        dimensions = image.size\n\n                # Create buffer\n                buffered = io.BytesIO()\n                image.save(buffered, format=\"PNG\")\n                # Base64 encode image\n                img_str = base64.b64encode(buffered.getvalue())\n                img_str = img_str.decode(\"ascii\")\n                # Post to API and return response\n                resp = requests.post(\n                    self.api_url,\n                    data=img_str,\n                    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                )\n\n                image_dims = {\n                    \"width\": str(original_dimensions[0]),\n                    \"height\": str(original_dimensions[1]),\n                }\n            elif isinstance(image_path, np.ndarray):\n                # Performing inference on a OpenCV2 frame\n                retval, buffer = cv2.imencode(\".jpg\", image_path)\n                # Currently cv2.imencode does not properly return shape\n                dimensions = buffer.shape\n                img_str = base64.b64encode(buffer)  # type: ignore[arg-type]\n                img_str = img_str.decode(\"ascii\")\n                resp = requests.post(\n                    self.api_url,\n                    data=img_str,\n                    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                )\n                # Replace with dimensions variable once\n                # cv2.imencode shape solution is found\n                image_dims = {\"width\": \"0\", \"height\": \"0\"}\n            else:\n                raise ValueError(\"image_path must be a string or a numpy array.\")\n        else:\n            # Create API URL for hosted image (slightly different)\n            self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n            image_dims = {\"width\": \"0\", \"height\": \"0\"}\n            # POST to the API\n            resp = requests.post(self.api_url)\n\n        resp.raise_for_status()\n        # Return a prediction group if JSON data\n        if self.format == \"json\":\n            resp_json = resp.json()\n\n            if should_resize and original_dimensions is not None:\n                new_preds = []\n                for p in resp_json[\"predictions\"]:\n                    p[\"x\"] = int(p[\"x\"] * (int(original_dimensions[0]) / int(self.preprocessing[\"resize\"][\"width\"])))\n                    p[\"y\"] = int(p[\"y\"] * (int(original_dimensions[1]) / int(self.preprocessing[\"resize\"][\"height\"])))\n                    p[\"width\"] = int(\n                        p[\"width\"] * (int(original_dimensions[0]) / int(self.preprocessing[\"resize\"][\"width\"]))\n                    )\n                    p[\"height\"] = int(\n                        p[\"height\"] * (int(original_dimensions[1]) / int(self.preprocessing[\"resize\"][\"height\"]))\n                    )\n\n                    new_preds.append(p)\n\n                resp_json[\"predictions\"] = new_preds\n\n            return PredictionGroup.create_prediction_group(\n                resp_json,\n                image_path=image_path,\n                prediction_type=OBJECT_DETECTION_MODEL,\n                image_dims=image_dims,\n                colors=self.colors,\n            )\n        # Returns base64 encoded Data\n        elif self.format == \"image\":\n            return resp.content\n\n    def webcam(\n        self,\n        webcam_id=0,\n        inference_engine_url=\"https://detect.roboflow.com/\",\n        within_jupyter=False,\n        confidence=40,\n        overlap=30,\n        stroke=1,\n        labels=False,\n        web_cam_res=(416, 416),\n    ):\n        \"\"\"\n        Infers detections based on webcam feed from specified model.\n\n        Args:\n            webcam_id (int): Webcam ID (default 0)\n            inference_engine_url (str): Inference engine address to use (default https://detect.roboflow.com)\n            within_jupyter (bool): Whether or not to display the webcam within Jupyter notebook (default True)\n            confidence (int): Confidence threshold for detections\n            overlap (int): Overlap threshold for detections\n            stroke (int): Stroke width for bounding box\n            labels (bool): Whether to show labels on bounding box\n        \"\"\"  # noqa: E501 // docs\n        import cv2\n\n        os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n\n        # Generate url before predicting\n        self.__generate_url(\n            confidence=confidence,\n            overlap=overlap,\n            stroke=stroke,\n            labels=labels,\n            inference_engine_url=inference_engine_url,\n        )\n\n        def plot_one_box(x, img, color=None, label=None, line_thickness=None, colors=None):\n            # Plots one bounding box on image img\n\n            self.colors = {} if colors is None else colors\n\n            if label in self.colors and label is not None:\n                color = self.colors[label]\n                color = color.lstrip(\"#\")\n                color = tuple(int(color[i : i + 2], 16) for i in (0, 2, 4))\n            else:\n                color = [random.randint(0, 255) for _ in range(3)]\n\n            tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n\n            c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n\n            cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n            if label:\n                tf = max(tl - 1, 1)  # font thickness\n                t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n                c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n                cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n                cv2.putText(\n                    img,\n                    label,\n                    (c1[0], c1[1] - 2),\n                    0,\n                    tl / 3,\n                    [225, 255, 255],\n                    thickness=tf,\n                    lineType=cv2.LINE_AA,\n                )\n\n        cap = cv2.VideoCapture(webcam_id)\n\n        if cap is None or not cap.isOpened():\n            raise (Exception(\"No webcam available at webcam_id \" + str(webcam_id)))\n\n        cap.set(cv2.CAP_PROP_FRAME_WIDTH, web_cam_res[0])\n        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, web_cam_res[1])\n\n        if within_jupyter:\n            os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n            print_warn_for_wrong_dependencies_versions([(\"IPython\", \"&gt;=\", \"7.0.0\")])\n            print_warn_for_wrong_dependencies_versions([(\"ipywidgets\", \"&gt;=\", \"7.0.0\")])\n\n            import threading\n\n            import ipywidgets as widgets\n            from IPython.display import Image as IPythonImage\n            from IPython.display import display\n\n            display_handle = display(\"loading Roboflow model...\", display_id=True)\n\n            # Stop button\n            # ================\n            stopButton = widgets.ToggleButton(\n                value=False,\n                description=\"Stop Inference\",\n                disabled=False,\n                button_style=\"danger\",  # 'success', 'info', 'warning', 'danger' or ''\n                tooltip=\"Description\",\n                icon=\"square\",  # (FontAwesome names without the `fa-` prefix)\n            )\n\n        else:\n            cv2.namedWindow(\"Roboflow Webcam Inference\", cv2.WINDOW_NORMAL)\n            cv2.startWindowThread()\n\n            stopButton = None\n\n        def view(button):\n            while True:\n                if stopButton is not None:\n                    if stopButton.value is True:\n                        break\n                else:\n                    if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                        break\n\n                _, frame = cap.read()\n                frame = cv2.resize(frame, web_cam_res)\n\n                frame = cv2.flip(frame, 1)  # if your camera reverses your image\n\n                _, frame_upload = cv2.imencode(\".jpeg\", frame)\n                img_str = base64.b64encode(frame_upload)  # type: ignore[arg-type]\n                img_str = img_str.decode(\"ascii\")\n\n                # post frame to the Roboflow API\n                r = requests.post(\n                    self.api_url,\n                    data=img_str,\n                    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                )\n\n                json = r.json()\n\n                predictions = json[\"predictions\"]\n\n                formatted_predictions = []\n                classes = []\n\n                for pred in predictions:\n                    formatted_pred = [\n                        pred[\"x\"],\n                        pred[\"y\"],\n                        pred[\"x\"],\n                        pred[\"y\"],\n                        pred[\"confidence\"],\n                    ]\n\n                    # convert to top-left x/y from center\n                    formatted_pred[0] = int(formatted_pred[0] - pred[\"width\"] / 2)\n                    formatted_pred[1] = int(formatted_pred[1] - pred[\"height\"] / 2)\n                    formatted_pred[2] = int(formatted_pred[2] + pred[\"width\"] / 2)\n                    formatted_pred[3] = int(formatted_pred[3] + pred[\"height\"] / 2)\n\n                    formatted_predictions.append(formatted_pred)\n                    classes.append(pred[\"class\"])\n\n                    plot_one_box(\n                        formatted_pred,\n                        frame,\n                        label=pred[\"class\"],\n                        line_thickness=2,\n                        colors=self.colors,\n                    )\n\n                _, frame_display = cv2.imencode(\".jpeg\", frame)\n\n                if within_jupyter:\n                    display_handle.update(IPythonImage(data=frame_display.tobytes()))\n                else:\n                    cv2.imshow(\"Roboflow Webcam Inference\", frame)\n                    if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                        cap.release()\n                        break\n\n            cap.release()\n            if not within_jupyter:\n                cv2.destroyWindow(\"Roboflow Webcam Inference\")\n                cv2.destroyAllWindows()\n                cv2.waitKey(1)\n\n            return\n\n        if within_jupyter:\n            display(stopButton)\n            thread = threading.Thread(target=view, args=(stopButton,))\n            thread.start()\n        else:\n            view(stopButton)\n\n    def __exception_check(self, image_path_check=None):\n        # Check if Image path exists exception check\n        # (for both hosted URL and local image)\n        if image_path_check is not None:\n            if not os.path.exists(image_path_check) and not check_image_url(image_path_check):\n                raise Exception(\"Image does not exist at \" + image_path_check + \"!\")\n\n    def __generate_url(\n        self,\n        local=None,\n        classes=None,\n        overlap=None,\n        confidence=None,\n        stroke=None,\n        labels=None,\n        format=None,\n        inference_engine_url=None,\n    ):\n        \"\"\"\n        Generate the URL to run inference on.\n        \"\"\"\n        # Reassign parameters if any parameters are changed\n        if local is not None:\n            if not local:\n                self.base_url = OBJECT_DETECTION_URL + \"/\"\n            else:\n                self.base_url = \"http://localhost:9001/\"\n\n        if inference_engine_url is not None:\n            self.base_url = inference_engine_url\n\n        # Change any variables that the user wants to change\n        if classes is not None:\n            self.classes = classes\n        if overlap is not None:\n            self.overlap = overlap\n        if confidence is not None:\n            self.confidence = confidence\n        if stroke is not None:\n            self.stroke = stroke\n        if labels is not None:\n            self.labels = labels\n        if format is not None:\n            self.format = format\n\n        # Create the new API URL\n        splitted = self.id.rsplit(\"/\")\n        without_workspace = splitted[1]\n\n        self.api_url = \"\".join(\n            [\n                self.base_url + without_workspace + \"/\" + str(self.version),\n                \"?api_key=\" + self.__api_key,\n                \"&amp;name=YOUR_IMAGE.jpg\",\n                \"&amp;overlap=\" + str(self.overlap),\n                \"&amp;confidence=\" + str(self.confidence),\n                \"&amp;stroke=\" + str(self.stroke),\n                \"&amp;labels=\" + str(self.labels).lower(),\n                \"&amp;format=\" + self.format,\n            ]\n        )\n        # add classes parameter to api\n        if self.classes is not None:\n            self.api_url += \"&amp;classes=\" + self.classes\n\n    def __str__(self):\n        # Create the new API URL\n        splitted = self.id.rsplit(\"/\")\n        without_workspace = splitted[1]\n\n        json_value = {\n            \"id\": without_workspace + \"/\" + str(self.version),\n            \"name\": self.name,\n            \"version\": self.version,\n            \"classes\": self.classes,\n            \"overlap\": self.overlap,\n            \"confidence\": self.confidence,\n            \"stroke\": self.stroke,\n            \"labels\": self.labels,\n            \"format\": self.format,\n            \"base_url\": self.base_url,\n        }\n\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.__generate_url","title":"<code>__generate_url(local=None, classes=None, overlap=None, confidence=None, stroke=None, labels=None, format=None, inference_engine_url=None)</code>","text":"<p>Generate the URL to run inference on.</p> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def __generate_url(\n    self,\n    local=None,\n    classes=None,\n    overlap=None,\n    confidence=None,\n    stroke=None,\n    labels=None,\n    format=None,\n    inference_engine_url=None,\n):\n    \"\"\"\n    Generate the URL to run inference on.\n    \"\"\"\n    # Reassign parameters if any parameters are changed\n    if local is not None:\n        if not local:\n            self.base_url = OBJECT_DETECTION_URL + \"/\"\n        else:\n            self.base_url = \"http://localhost:9001/\"\n\n    if inference_engine_url is not None:\n        self.base_url = inference_engine_url\n\n    # Change any variables that the user wants to change\n    if classes is not None:\n        self.classes = classes\n    if overlap is not None:\n        self.overlap = overlap\n    if confidence is not None:\n        self.confidence = confidence\n    if stroke is not None:\n        self.stroke = stroke\n    if labels is not None:\n        self.labels = labels\n    if format is not None:\n        self.format = format\n\n    # Create the new API URL\n    splitted = self.id.rsplit(\"/\")\n    without_workspace = splitted[1]\n\n    self.api_url = \"\".join(\n        [\n            self.base_url + without_workspace + \"/\" + str(self.version),\n            \"?api_key=\" + self.__api_key,\n            \"&amp;name=YOUR_IMAGE.jpg\",\n            \"&amp;overlap=\" + str(self.overlap),\n            \"&amp;confidence=\" + str(self.confidence),\n            \"&amp;stroke=\" + str(self.stroke),\n            \"&amp;labels=\" + str(self.labels).lower(),\n            \"&amp;format=\" + self.format,\n        ]\n    )\n    # add classes parameter to api\n    if self.classes is not None:\n        self.api_url += \"&amp;classes=\" + self.classes\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.__init__","title":"<code>__init__(api_key, id, name=None, version=None, local=None, classes=None, overlap=30, confidence=40, stroke=1, labels=False, format='json', colors=None, preprocessing=None)</code>","text":"<p>Create a ObjectDetectionModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your API key (obtained via your workspace API settings page).</p> required <code>name</code> <code>str</code> <p>The url-safe version of the dataset name. You can find it in the web UI by looking at         the URL on the main project view or by clicking the \"Get curl command\" button in the train         results section of your dataset version after training your model.</p> <code>None</code> <code>local</code> <code>str</code> <p>Address of the local server address if running a local Roboflow deployment server.         Ex. http://localhost:9001/</p> <code>None</code> <code>version</code> <code>str</code> <p>The version number identifying the version of your dataset.</p> <code>None</code> <code>classes</code> <code>str</code> <p>Restrict the predictions to only those of certain classes. Provide as a comma-separated string.</p> <code>None</code> <code>overlap</code> <code>int</code> <p>The maximum percentage (on a scale of 0-100) that bounding box predictions of the same class are         allowed to overlap before being combined into a single box.</p> <code>30</code> <code>confidence</code> <code>int</code> <p>A threshold for the returned predictions on a scale of 0-100. A lower number will return             more predictions. A higher number will return fewer high-certainty predictions.</p> <code>40</code> <code>stroke</code> <code>int</code> <p>The width (in pixels) of the bounding box displayed around predictions (only has an effect when         format is image).</p> <code>1</code> <code>labels</code> <code>bool</code> <p>Whether or not to display text labels on the predictions (only has an effect when format is         image).</p> <code>False</code> <code>format</code> <code>str</code> <p>The format of the output.         - 'json': returns an array of JSON predictions (See response format tab).         - 'image': returns an image with annotated predictions as a binary blob with a Content-Type                     of image/jpeg.</p> <code>'json'</code> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def __init__(\n    self,\n    api_key,\n    id,\n    name=None,\n    version=None,\n    local=None,\n    classes=None,\n    overlap=30,\n    confidence=40,\n    stroke=1,\n    labels=False,\n    format=\"json\",\n    colors=None,\n    preprocessing=None,\n):\n    \"\"\"\n    Create a ObjectDetectionModel object through which you can run inference.\n\n    Args:\n        api_key (str): Your API key (obtained via your workspace API settings page).\n        name (str): The url-safe version of the dataset name. You can find it in the web UI by looking at\n                    the URL on the main project view or by clicking the \"Get curl command\" button in the train\n                    results section of your dataset version after training your model.\n        local (str): Address of the local server address if running a local Roboflow deployment server.\n                    Ex. http://localhost:9001/\n        version (str): The version number identifying the version of your dataset.\n        classes (str): Restrict the predictions to only those of certain classes. Provide as a comma-separated string.\n        overlap (int): The maximum percentage (on a scale of 0-100) that bounding box predictions of the same class are\n                    allowed to overlap before being combined into a single box.\n        confidence (int): A threshold for the returned predictions on a scale of 0-100. A lower number will return\n                        more predictions. A higher number will return fewer high-certainty predictions.\n        stroke (int): The width (in pixels) of the bounding box displayed around predictions (only has an effect when\n                    format is image).\n        labels (bool): Whether or not to display text labels on the predictions (only has an effect when format is\n                    image).\n        format (str): The format of the output.\n                    - 'json': returns an array of JSON predictions (See response format tab).\n                    - 'image': returns an image with annotated predictions as a binary blob with a Content-Type\n                                of image/jpeg.\n    \"\"\"  # noqa: E501 // docs\n    # Instantiate different API URL parameters\n    # To be moved to predict\n    super().__init__(api_key, id)\n    self.__api_key = api_key\n    self.id = id\n    self.name = name\n    self.version = version or self.version\n    self.classes = classes\n    self.overlap = overlap\n    self.confidence = confidence\n    self.stroke = stroke\n    self.labels = labels\n    self.format = format\n    self.colors = {} if colors is None else colors\n    self.preprocessing = {} if preprocessing is None else preprocessing\n\n    # local needs to be passed from Project\n    if local is None:\n        self.base_url = OBJECT_DETECTION_URL + \"/\"\n    else:\n        print(\"initalizing local object detection model hosted at :\" + local)\n        self.base_url = local\n\n    # If dataset slug not none, instantiate API URL\n    if name is not None and version is not None:\n        self.__generate_url()\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.load_model","title":"<code>load_model(name, version, local=None, classes=None, overlap=None, confidence=None, stroke=None, labels=None, format=None)</code>","text":"<p>Loads a Model from on a model endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The url-safe version of the dataset name</p> required <code>version</code> <code>str</code> <p>The version number identifying the version of your dataset.</p> required <code>local</code> <code>bool</code> <p>Whether the model is hosted locally or on Roboflow</p> <code>None</code> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def load_model(\n    self,\n    name,\n    version,\n    local=None,\n    classes=None,\n    overlap=None,\n    confidence=None,\n    stroke=None,\n    labels=None,\n    format=None,\n):\n    \"\"\"\n    Loads a Model from on a model endpoint.\n\n    Args:\n        name (str): The url-safe version of the dataset name\n        version (str): The version number identifying the version of your dataset.\n        local (bool): Whether the model is hosted locally or on Roboflow\n    \"\"\"\n    # To load a model manually, they must specify a dataset slug\n    self.name = name\n    self.version = version\n    # Generate URL based on parameters\n    self.__generate_url(\n        local=local,\n        classes=classes,\n        overlap=overlap,\n        confidence=confidence,\n        stroke=stroke,\n        labels=labels,\n        format=format,\n    )\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.predict","title":"<code>predict(image_path, hosted=False, format=None, classes=None, overlap=30, confidence=40, stroke=1, labels=False)</code>","text":"<p>Infers detections based on image from specified model and image path.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>hosted</code> <code>bool</code> <p>whether the image you're providing is hosted on Roboflow</p> <code>False</code> <code>format</code> <code>str</code> <p>The format of the output.</p> <code>None</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def predict(  # type: ignore[override]\n    self,\n    image_path,\n    hosted=False,\n    format=None,\n    classes=None,\n    overlap=30,\n    confidence=40,\n    stroke=1,\n    labels=False,\n):\n    \"\"\"\n    Infers detections based on image from specified model and image path.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        hosted (bool): whether the image you're providing is hosted on Roboflow\n        format (str): The format of the output.\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"\n    # Generate url before predicting\n    self.__generate_url(\n        format=format,\n        classes=classes,\n        overlap=overlap,\n        confidence=confidence,\n        stroke=stroke,\n        labels=labels,\n    )\n\n    # Check if image exists at specified path or URL or is an array\n    if hasattr(image_path, \"__len__\") is True:\n        pass\n    else:\n        self.__exception_check(image_path_check=image_path)\n\n    original_dimensions = None\n    should_resize = False\n    # If image is local image\n    if not hosted:\n        import cv2\n        import numpy as np\n\n        should_resize = (\n            \"resize\" in self.preprocessing.keys() and \"Stretch\" in self.preprocessing[\"resize\"][\"format\"]\n        )\n\n        if isinstance(image_path, str):\n            image = Image.open(image_path).convert(\"RGB\")\n            dimensions = image.size\n            original_dimensions = copy.deepcopy(dimensions)\n\n            # Here we resize the image to the preprocessing settings\n            # before sending it over the wire\n            if should_resize:\n                if dimensions[0] &gt; int(self.preprocessing[\"resize\"][\"width\"]) or dimensions[1] &gt; int(\n                    self.preprocessing[\"resize\"][\"height\"]\n                ):\n                    image = image.resize(\n                        (\n                            int(self.preprocessing[\"resize\"][\"width\"]),\n                            int(self.preprocessing[\"resize\"][\"height\"]),\n                        )\n                    )\n                    dimensions = image.size\n\n            # Create buffer\n            buffered = io.BytesIO()\n            image.save(buffered, format=\"PNG\")\n            # Base64 encode image\n            img_str = base64.b64encode(buffered.getvalue())\n            img_str = img_str.decode(\"ascii\")\n            # Post to API and return response\n            resp = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n\n            image_dims = {\n                \"width\": str(original_dimensions[0]),\n                \"height\": str(original_dimensions[1]),\n            }\n        elif isinstance(image_path, np.ndarray):\n            # Performing inference on a OpenCV2 frame\n            retval, buffer = cv2.imencode(\".jpg\", image_path)\n            # Currently cv2.imencode does not properly return shape\n            dimensions = buffer.shape\n            img_str = base64.b64encode(buffer)  # type: ignore[arg-type]\n            img_str = img_str.decode(\"ascii\")\n            resp = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n            # Replace with dimensions variable once\n            # cv2.imencode shape solution is found\n            image_dims = {\"width\": \"0\", \"height\": \"0\"}\n        else:\n            raise ValueError(\"image_path must be a string or a numpy array.\")\n    else:\n        # Create API URL for hosted image (slightly different)\n        self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n        image_dims = {\"width\": \"0\", \"height\": \"0\"}\n        # POST to the API\n        resp = requests.post(self.api_url)\n\n    resp.raise_for_status()\n    # Return a prediction group if JSON data\n    if self.format == \"json\":\n        resp_json = resp.json()\n\n        if should_resize and original_dimensions is not None:\n            new_preds = []\n            for p in resp_json[\"predictions\"]:\n                p[\"x\"] = int(p[\"x\"] * (int(original_dimensions[0]) / int(self.preprocessing[\"resize\"][\"width\"])))\n                p[\"y\"] = int(p[\"y\"] * (int(original_dimensions[1]) / int(self.preprocessing[\"resize\"][\"height\"])))\n                p[\"width\"] = int(\n                    p[\"width\"] * (int(original_dimensions[0]) / int(self.preprocessing[\"resize\"][\"width\"]))\n                )\n                p[\"height\"] = int(\n                    p[\"height\"] * (int(original_dimensions[1]) / int(self.preprocessing[\"resize\"][\"height\"]))\n                )\n\n                new_preds.append(p)\n\n            resp_json[\"predictions\"] = new_preds\n\n        return PredictionGroup.create_prediction_group(\n            resp_json,\n            image_path=image_path,\n            prediction_type=OBJECT_DETECTION_MODEL,\n            image_dims=image_dims,\n            colors=self.colors,\n        )\n    # Returns base64 encoded Data\n    elif self.format == \"image\":\n        return resp.content\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.webcam","title":"<code>webcam(webcam_id=0, inference_engine_url='https://detect.roboflow.com/', within_jupyter=False, confidence=40, overlap=30, stroke=1, labels=False, web_cam_res=(416, 416))</code>","text":"<p>Infers detections based on webcam feed from specified model.</p> <p>Parameters:</p> Name Type Description Default <code>webcam_id</code> <code>int</code> <p>Webcam ID (default 0)</p> <code>0</code> <code>inference_engine_url</code> <code>str</code> <p>Inference engine address to use (default https://detect.roboflow.com)</p> <code>'https://detect.roboflow.com/'</code> <code>within_jupyter</code> <code>bool</code> <p>Whether or not to display the webcam within Jupyter notebook (default True)</p> <code>False</code> <code>confidence</code> <code>int</code> <p>Confidence threshold for detections</p> <code>40</code> <code>overlap</code> <code>int</code> <p>Overlap threshold for detections</p> <code>30</code> <code>stroke</code> <code>int</code> <p>Stroke width for bounding box</p> <code>1</code> <code>labels</code> <code>bool</code> <p>Whether to show labels on bounding box</p> <code>False</code> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def webcam(\n    self,\n    webcam_id=0,\n    inference_engine_url=\"https://detect.roboflow.com/\",\n    within_jupyter=False,\n    confidence=40,\n    overlap=30,\n    stroke=1,\n    labels=False,\n    web_cam_res=(416, 416),\n):\n    \"\"\"\n    Infers detections based on webcam feed from specified model.\n\n    Args:\n        webcam_id (int): Webcam ID (default 0)\n        inference_engine_url (str): Inference engine address to use (default https://detect.roboflow.com)\n        within_jupyter (bool): Whether or not to display the webcam within Jupyter notebook (default True)\n        confidence (int): Confidence threshold for detections\n        overlap (int): Overlap threshold for detections\n        stroke (int): Stroke width for bounding box\n        labels (bool): Whether to show labels on bounding box\n    \"\"\"  # noqa: E501 // docs\n    import cv2\n\n    os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n\n    # Generate url before predicting\n    self.__generate_url(\n        confidence=confidence,\n        overlap=overlap,\n        stroke=stroke,\n        labels=labels,\n        inference_engine_url=inference_engine_url,\n    )\n\n    def plot_one_box(x, img, color=None, label=None, line_thickness=None, colors=None):\n        # Plots one bounding box on image img\n\n        self.colors = {} if colors is None else colors\n\n        if label in self.colors and label is not None:\n            color = self.colors[label]\n            color = color.lstrip(\"#\")\n            color = tuple(int(color[i : i + 2], 16) for i in (0, 2, 4))\n        else:\n            color = [random.randint(0, 255) for _ in range(3)]\n\n        tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n\n        c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n\n        cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n        if label:\n            tf = max(tl - 1, 1)  # font thickness\n            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n            c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n            cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n            cv2.putText(\n                img,\n                label,\n                (c1[0], c1[1] - 2),\n                0,\n                tl / 3,\n                [225, 255, 255],\n                thickness=tf,\n                lineType=cv2.LINE_AA,\n            )\n\n    cap = cv2.VideoCapture(webcam_id)\n\n    if cap is None or not cap.isOpened():\n        raise (Exception(\"No webcam available at webcam_id \" + str(webcam_id)))\n\n    cap.set(cv2.CAP_PROP_FRAME_WIDTH, web_cam_res[0])\n    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, web_cam_res[1])\n\n    if within_jupyter:\n        os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n        print_warn_for_wrong_dependencies_versions([(\"IPython\", \"&gt;=\", \"7.0.0\")])\n        print_warn_for_wrong_dependencies_versions([(\"ipywidgets\", \"&gt;=\", \"7.0.0\")])\n\n        import threading\n\n        import ipywidgets as widgets\n        from IPython.display import Image as IPythonImage\n        from IPython.display import display\n\n        display_handle = display(\"loading Roboflow model...\", display_id=True)\n\n        # Stop button\n        # ================\n        stopButton = widgets.ToggleButton(\n            value=False,\n            description=\"Stop Inference\",\n            disabled=False,\n            button_style=\"danger\",  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip=\"Description\",\n            icon=\"square\",  # (FontAwesome names without the `fa-` prefix)\n        )\n\n    else:\n        cv2.namedWindow(\"Roboflow Webcam Inference\", cv2.WINDOW_NORMAL)\n        cv2.startWindowThread()\n\n        stopButton = None\n\n    def view(button):\n        while True:\n            if stopButton is not None:\n                if stopButton.value is True:\n                    break\n            else:\n                if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                    break\n\n            _, frame = cap.read()\n            frame = cv2.resize(frame, web_cam_res)\n\n            frame = cv2.flip(frame, 1)  # if your camera reverses your image\n\n            _, frame_upload = cv2.imencode(\".jpeg\", frame)\n            img_str = base64.b64encode(frame_upload)  # type: ignore[arg-type]\n            img_str = img_str.decode(\"ascii\")\n\n            # post frame to the Roboflow API\n            r = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n\n            json = r.json()\n\n            predictions = json[\"predictions\"]\n\n            formatted_predictions = []\n            classes = []\n\n            for pred in predictions:\n                formatted_pred = [\n                    pred[\"x\"],\n                    pred[\"y\"],\n                    pred[\"x\"],\n                    pred[\"y\"],\n                    pred[\"confidence\"],\n                ]\n\n                # convert to top-left x/y from center\n                formatted_pred[0] = int(formatted_pred[0] - pred[\"width\"] / 2)\n                formatted_pred[1] = int(formatted_pred[1] - pred[\"height\"] / 2)\n                formatted_pred[2] = int(formatted_pred[2] + pred[\"width\"] / 2)\n                formatted_pred[3] = int(formatted_pred[3] + pred[\"height\"] / 2)\n\n                formatted_predictions.append(formatted_pred)\n                classes.append(pred[\"class\"])\n\n                plot_one_box(\n                    formatted_pred,\n                    frame,\n                    label=pred[\"class\"],\n                    line_thickness=2,\n                    colors=self.colors,\n                )\n\n            _, frame_display = cv2.imencode(\".jpeg\", frame)\n\n            if within_jupyter:\n                display_handle.update(IPythonImage(data=frame_display.tobytes()))\n            else:\n                cv2.imshow(\"Roboflow Webcam Inference\", frame)\n                if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                    cap.release()\n                    break\n\n        cap.release()\n        if not within_jupyter:\n            cv2.destroyWindow(\"Roboflow Webcam Inference\")\n            cv2.destroyAllWindows()\n            cv2.waitKey(1)\n\n        return\n\n    if within_jupyter:\n        display(stopButton)\n        thread = threading.Thread(target=view, args=(stopButton,))\n        thread.start()\n    else:\n        view(stopButton)\n</code></pre>"},{"location":"models/semantic-segmentation/","title":"Semantic Segmentation","text":""},{"location":"models/semantic-segmentation/#roboflow.models.semantic_segmentation.SemanticSegmentationModel","title":"<code>SemanticSegmentationModel</code>","text":"<p>               Bases: <code>InferenceModel</code></p> <p>Run inference on a semantic segmentation model hosted on Roboflow or served through Roboflow Inference.</p> Source code in <code>roboflow/models/semantic_segmentation.py</code> <pre><code>class SemanticSegmentationModel(InferenceModel):\n    \"\"\"\n    Run inference on a semantic segmentation model hosted on Roboflow or served through Roboflow Inference.\n    \"\"\"  # noqa: E501 // docs\n\n    def __init__(self, api_key: str, version_id: str):\n        \"\"\"\n        Create a SemanticSegmentationModel object through which you can run inference.\n\n        Args:\n            api_key (str): private roboflow api key\n            version_id (str): the workspace/project id\n        \"\"\"  # noqa: E501 // docs\n        super().__init__(api_key, version_id)\n        self.api_url = f\"{SEMANTIC_SEGMENTATION_URL}/{self.dataset_id}/{self.version}\"\n\n    def predict(self, image_path: str, confidence: int = 50):  # type: ignore[override]\n        \"\"\"\n        Infers detections based on image from a specified model and image path.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"  # noqa: E501 // docs\n        return super().predict(\n            image_path,\n            confidence=confidence,\n            prediction_type=SEMANTIC_SEGMENTATION_MODEL,\n        )\n\n    def __str__(self):\n        return f\"&lt;{type(self).__name__} id={self.id}, api_url={self.api_url}&gt;\"\n</code></pre>"},{"location":"models/semantic-segmentation/#roboflow.models.semantic_segmentation.SemanticSegmentationModel.__init__","title":"<code>__init__(api_key, version_id)</code>","text":"<p>Create a SemanticSegmentationModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>version_id</code> <code>str</code> <p>the workspace/project id</p> required Source code in <code>roboflow/models/semantic_segmentation.py</code> <pre><code>def __init__(self, api_key: str, version_id: str):\n    \"\"\"\n    Create a SemanticSegmentationModel object through which you can run inference.\n\n    Args:\n        api_key (str): private roboflow api key\n        version_id (str): the workspace/project id\n    \"\"\"  # noqa: E501 // docs\n    super().__init__(api_key, version_id)\n    self.api_url = f\"{SEMANTIC_SEGMENTATION_URL}/{self.dataset_id}/{self.version}\"\n</code></pre>"},{"location":"models/semantic-segmentation/#roboflow.models.semantic_segmentation.SemanticSegmentationModel.predict","title":"<code>predict(image_path, confidence=50)</code>","text":"<p>Infers detections based on image from a specified model and image path.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>confidence</code> <code>int</code> <p>confidence threshold for predictions, on a scale from 0-100</p> <code>50</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/semantic_segmentation.py</code> <pre><code>def predict(self, image_path: str, confidence: int = 50):  # type: ignore[override]\n    \"\"\"\n    Infers detections based on image from a specified model and image path.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"  # noqa: E501 // docs\n    return super().predict(\n        image_path,\n        confidence=confidence,\n        prediction_type=SEMANTIC_SEGMENTATION_MODEL,\n    )\n</code></pre>"}]}